{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\RLproject\\lib\\site-packages\\sonnet\\python\\modules\\util.py:63: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\utils\\utils.py:328: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\agents\\dqn_agent.py:292: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\agents\\dqn_agent.py:307: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\RLproject\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\RLproject\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\agents\\dqn_agent.py:326: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\agents\\dqn_agent.py:296: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\agents\\dqn_agent.py:298: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "\n",
      "########## Evaluation ##########\n",
      "Timestep: 1 Average reward is -0.2654\n",
      "\n",
      "########## Evaluation ##########\n",
      "Timestep: 136 Average reward is -0.6396\n",
      "WARNING:tensorflow:From C:\\Users\\Ben\\rlcard\\rlcard\\agents\\dqn_agent.py:409: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 271, loss: 0.6868118643760681\n",
      "########## Evaluation ##########\n",
      "Timestep: 271 Average reward is -0.6076\n",
      "INFO - Step 402, loss: 0.8737920522689819\n",
      "########## Evaluation ##########\n",
      "Timestep: 402 Average reward is -0.5777\n",
      "INFO - Step 537, loss: 0.7740795612335205\n",
      "########## Evaluation ##########\n",
      "Timestep: 537 Average reward is -0.5691\n",
      "INFO - Step 681, loss: 0.8075450658798218\n",
      "########## Evaluation ##########\n",
      "Timestep: 681 Average reward is -0.4811\n",
      "INFO - Step 824, loss: 0.83228337764739996\n",
      "########## Evaluation ##########\n",
      "Timestep: 824 Average reward is -0.4269\n",
      "INFO - Step 958, loss: 0.7200493812561035\n",
      "########## Evaluation ##########\n",
      "Timestep: 958 Average reward is -0.3435\n",
      "INFO - Step 1093, loss: 0.6173027753829956\n",
      "########## Evaluation ##########\n",
      "Timestep: 1093 Average reward is -0.2652\n",
      "INFO - Step 1200, loss: 0.7142327427864075\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 1221, loss: 0.7705737352371216\n",
      "########## Evaluation ##########\n",
      "Timestep: 1221 Average reward is -0.1776\n",
      "INFO - Step 1350, loss: 0.56490606069564825\n",
      "########## Evaluation ##########\n",
      "Timestep: 1350 Average reward is -0.1549\n",
      "INFO - Step 1487, loss: 0.56018710136413574\n",
      "########## Evaluation ##########\n",
      "Timestep: 1487 Average reward is -0.1557\n",
      "INFO - Step 1614, loss: 0.45490190386772156\n",
      "########## Evaluation ##########\n",
      "Timestep: 1614 Average reward is -0.1797\n",
      "INFO - Step 1756, loss: 0.63159072399139465\n",
      "########## Evaluation ##########\n",
      "Timestep: 1756 Average reward is -0.1626\n",
      "INFO - Step 1891, loss: 0.59821093082427987\n",
      "########## Evaluation ##########\n",
      "Timestep: 1891 Average reward is -0.1614\n",
      "INFO - Step 2029, loss: 0.51359009742736827\n",
      "########## Evaluation ##########\n",
      "Timestep: 2029 Average reward is -0.1708\n",
      "INFO - Step 2165, loss: 0.62550151348114014\n",
      "########## Evaluation ##########\n",
      "Timestep: 2165 Average reward is -0.1742\n",
      "INFO - Step 2200, loss: 0.60439127683639534\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 2291, loss: 0.58893871307373054\n",
      "########## Evaluation ##########\n",
      "Timestep: 2291 Average reward is -0.1402\n",
      "INFO - Step 2424, loss: 0.52305823564529426\n",
      "########## Evaluation ##########\n",
      "Timestep: 2424 Average reward is -0.1574\n",
      "INFO - Step 2567, loss: 0.54745310544967654\n",
      "########## Evaluation ##########\n",
      "Timestep: 2567 Average reward is -0.1375\n",
      "INFO - Step 2698, loss: 0.82131564617156984\n",
      "########## Evaluation ##########\n",
      "Timestep: 2698 Average reward is -0.1266\n",
      "INFO - Step 2841, loss: 0.51900607347488463\n",
      "########## Evaluation ##########\n",
      "Timestep: 2841 Average reward is -0.1149\n",
      "INFO - Step 2977, loss: 0.50474399328231816\n",
      "########## Evaluation ##########\n",
      "Timestep: 2977 Average reward is -0.1185\n",
      "INFO - Step 3108, loss: 0.53115880489349376\n",
      "########## Evaluation ##########\n",
      "Timestep: 3108 Average reward is -0.1362\n",
      "INFO - Step 3200, loss: 0.56472361087799076\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 3242, loss: 0.65040576457977386\n",
      "########## Evaluation ##########\n",
      "Timestep: 3242 Average reward is -0.1073\n",
      "INFO - Step 3376, loss: 0.52002036571502695\n",
      "########## Evaluation ##########\n",
      "Timestep: 3376 Average reward is -0.0956\n",
      "INFO - Step 3519, loss: 0.40818974375724796\n",
      "########## Evaluation ##########\n",
      "Timestep: 3519 Average reward is -0.0767\n",
      "INFO - Step 3659, loss: 0.42511388659477234\n",
      "########## Evaluation ##########\n",
      "Timestep: 3659 Average reward is -0.1033\n",
      "INFO - Step 3795, loss: 0.49172335863113403\n",
      "########## Evaluation ##########\n",
      "Timestep: 3795 Average reward is -0.1028\n",
      "INFO - Step 3935, loss: 0.45644211769104004\n",
      "########## Evaluation ##########\n",
      "Timestep: 3935 Average reward is -0.0822\n",
      "INFO - Step 4075, loss: 0.57953375577926644\n",
      "########## Evaluation ##########\n",
      "Timestep: 4075 Average reward is -0.0914\n",
      "INFO - Step 4200, loss: 0.38987588882446293\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 4208, loss: 0.6088395118713379\n",
      "########## Evaluation ##########\n",
      "Timestep: 4208 Average reward is -0.0761\n",
      "INFO - Step 4347, loss: 0.56687974929809575\n",
      "########## Evaluation ##########\n",
      "Timestep: 4347 Average reward is -0.0878\n",
      "INFO - Step 4486, loss: 0.40436577796936035\n",
      "########## Evaluation ##########\n",
      "Timestep: 4486 Average reward is -0.0974\n",
      "INFO - Step 4618, loss: 0.49228838086128235\n",
      "########## Evaluation ##########\n",
      "Timestep: 4618 Average reward is -0.0929\n",
      "INFO - Step 4757, loss: 0.48552840948104866\n",
      "########## Evaluation ##########\n",
      "Timestep: 4757 Average reward is -0.0826\n",
      "INFO - Step 4890, loss: 0.50844782590866094\n",
      "########## Evaluation ##########\n",
      "Timestep: 4890 Average reward is -0.0622\n",
      "INFO - Step 5034, loss: 0.63805705308914184\n",
      "########## Evaluation ##########\n",
      "Timestep: 5034 Average reward is -0.0858\n",
      "INFO - Step 5180, loss: 0.62448734045028697\n",
      "########## Evaluation ##########\n",
      "Timestep: 5180 Average reward is -0.0883\n",
      "INFO - Step 5200, loss: 0.56578624248504646\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 5315, loss: 0.64123910665512084\n",
      "########## Evaluation ##########\n",
      "Timestep: 5315 Average reward is -0.096\n",
      "INFO - Step 5452, loss: 0.52769291400909427\n",
      "########## Evaluation ##########\n",
      "Timestep: 5452 Average reward is -0.0764\n",
      "INFO - Step 5582, loss: 0.47070866823196416\n",
      "########## Evaluation ##########\n",
      "Timestep: 5582 Average reward is -0.08\n",
      "INFO - Step 5712, loss: 0.61501526832580573\n",
      "########## Evaluation ##########\n",
      "Timestep: 5712 Average reward is -0.0691\n",
      "INFO - Step 5846, loss: 0.42580163478851326\n",
      "########## Evaluation ##########\n",
      "Timestep: 5846 Average reward is -0.0724\n",
      "INFO - Step 5982, loss: 0.46356037259101875\n",
      "########## Evaluation ##########\n",
      "Timestep: 5982 Average reward is -0.0835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 6122, loss: 0.47987440228462224\n",
      "########## Evaluation ##########\n",
      "Timestep: 6122 Average reward is -0.0696\n",
      "INFO - Step 6200, loss: 0.54132503271102963\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 6261, loss: 0.47613316774368286\n",
      "########## Evaluation ##########\n",
      "Timestep: 6261 Average reward is -0.0741\n",
      "INFO - Step 6393, loss: 0.46913129091262823\n",
      "########## Evaluation ##########\n",
      "Timestep: 6393 Average reward is -0.0855\n",
      "INFO - Step 6526, loss: 0.57319259643554693\n",
      "########## Evaluation ##########\n",
      "Timestep: 6526 Average reward is -0.0616\n",
      "INFO - Step 6669, loss: 0.53154265880584723\n",
      "########## Evaluation ##########\n",
      "Timestep: 6669 Average reward is -0.0828\n",
      "INFO - Step 6799, loss: 0.36658540368080145\n",
      "########## Evaluation ##########\n",
      "Timestep: 6799 Average reward is -0.0707\n",
      "INFO - Step 6921, loss: 0.62187141180038456\n",
      "########## Evaluation ##########\n",
      "Timestep: 6921 Average reward is -0.0701\n",
      "INFO - Step 7060, loss: 0.55895626544952395\n",
      "########## Evaluation ##########\n",
      "Timestep: 7060 Average reward is -0.0886\n",
      "INFO - Step 7194, loss: 0.52061223983764654\n",
      "########## Evaluation ##########\n",
      "Timestep: 7194 Average reward is -0.0732\n",
      "INFO - Step 7200, loss: 0.45699512958526615\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 7334, loss: 0.60162591934204117\n",
      "########## Evaluation ##########\n",
      "Timestep: 7334 Average reward is -0.0805\n",
      "INFO - Step 7461, loss: 0.55343675613403324\n",
      "########## Evaluation ##########\n",
      "Timestep: 7461 Average reward is -0.0858\n",
      "INFO - Step 7609, loss: 0.48614159226417543\n",
      "########## Evaluation ##########\n",
      "Timestep: 7609 Average reward is -0.0715\n",
      "INFO - Step 7745, loss: 0.47645574808120736\n",
      "########## Evaluation ##########\n",
      "Timestep: 7745 Average reward is -0.0683\n",
      "INFO - Step 7880, loss: 0.60777342319488534\n",
      "########## Evaluation ##########\n",
      "Timestep: 7880 Average reward is -0.0733\n",
      "INFO - Step 8028, loss: 0.73903101682662964\n",
      "########## Evaluation ##########\n",
      "Timestep: 8028 Average reward is -0.0804\n",
      "INFO - Step 8168, loss: 0.72936320304870674\n",
      "########## Evaluation ##########\n",
      "Timestep: 8168 Average reward is -0.0826\n",
      "INFO - Step 8200, loss: 0.54302549362182623\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 8304, loss: 0.45327478647232056\n",
      "########## Evaluation ##########\n",
      "Timestep: 8304 Average reward is -0.0647\n",
      "INFO - Step 8446, loss: 0.53253316879272465\n",
      "########## Evaluation ##########\n",
      "Timestep: 8446 Average reward is -0.0699\n",
      "INFO - Step 8584, loss: 0.49354457855224615\n",
      "########## Evaluation ##########\n",
      "Timestep: 8584 Average reward is -0.071\n",
      "INFO - Step 8723, loss: 0.86895328760147155\n",
      "########## Evaluation ##########\n",
      "Timestep: 8723 Average reward is -0.0931\n",
      "INFO - Step 8874, loss: 0.47098317742347726\n",
      "########## Evaluation ##########\n",
      "Timestep: 8874 Average reward is -0.0778\n",
      "INFO - Step 9022, loss: 0.47190591692924545\n",
      "########## Evaluation ##########\n",
      "Timestep: 9022 Average reward is -0.076\n",
      "INFO - Step 9157, loss: 0.35538855195045474\n",
      "########## Evaluation ##########\n",
      "Timestep: 9157 Average reward is -0.0803\n",
      "INFO - Step 9200, loss: 0.54293739795684814\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 9289, loss: 0.60179007053375244\n",
      "########## Evaluation ##########\n",
      "Timestep: 9289 Average reward is -0.0898\n",
      "INFO - Step 9419, loss: 0.69905978441238496\n",
      "########## Evaluation ##########\n",
      "Timestep: 9419 Average reward is -0.0904\n",
      "INFO - Step 9555, loss: 0.49542176723480225\n",
      "########## Evaluation ##########\n",
      "Timestep: 9555 Average reward is -0.0711\n",
      "INFO - Step 9692, loss: 0.64039766788482673\n",
      "########## Evaluation ##########\n",
      "Timestep: 9692 Average reward is -0.0781\n",
      "INFO - Step 9825, loss: 0.59462231397628783\n",
      "########## Evaluation ##########\n",
      "Timestep: 9825 Average reward is -0.0714\n",
      "INFO - Step 9959, loss: 0.50006806850433357\n",
      "########## Evaluation ##########\n",
      "Timestep: 9959 Average reward is -0.0517\n",
      "INFO - Step 10100, loss: 0.48692432045936584\n",
      "########## Evaluation ##########\n",
      "Timestep: 10100 Average reward is -0.0821\n",
      "INFO - Step 10200, loss: 0.49998444318771363\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 10243, loss: 0.61205101013183594\n",
      "########## Evaluation ##########\n",
      "Timestep: 10243 Average reward is -0.0733\n",
      "INFO - Step 10394, loss: 0.54774230718612673\n",
      "########## Evaluation ##########\n",
      "Timestep: 10394 Average reward is -0.0818\n",
      "INFO - Step 10534, loss: 0.53647816181182866\n",
      "########## Evaluation ##########\n",
      "Timestep: 10534 Average reward is -0.0446\n",
      "INFO - Step 10673, loss: 0.51968091726303144\n",
      "########## Evaluation ##########\n",
      "Timestep: 10673 Average reward is -0.0858\n",
      "INFO - Step 10816, loss: 0.41389879584312444\n",
      "########## Evaluation ##########\n",
      "Timestep: 10816 Average reward is -0.0749\n",
      "INFO - Step 10967, loss: 0.52976435422897345\n",
      "########## Evaluation ##########\n",
      "Timestep: 10967 Average reward is -0.0815\n",
      "INFO - Step 11101, loss: 0.75686782598495487\n",
      "########## Evaluation ##########\n",
      "Timestep: 11101 Average reward is -0.0787\n",
      "INFO - Step 11200, loss: 0.45571202039718635\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 11232, loss: 0.35798940062522897\n",
      "########## Evaluation ##########\n",
      "Timestep: 11232 Average reward is -0.0802\n",
      "INFO - Step 11373, loss: 0.50612437725067146\n",
      "########## Evaluation ##########\n",
      "Timestep: 11373 Average reward is -0.0774\n",
      "INFO - Step 11528, loss: 0.50704741477966313\n",
      "########## Evaluation ##########\n",
      "Timestep: 11528 Average reward is -0.0655\n",
      "INFO - Step 11670, loss: 0.72767668962478644\n",
      "########## Evaluation ##########\n",
      "Timestep: 11670 Average reward is -0.0764\n",
      "INFO - Step 11804, loss: 0.38141182065010076\n",
      "########## Evaluation ##########\n",
      "Timestep: 11804 Average reward is -0.0779\n",
      "INFO - Step 11937, loss: 0.39961844682693483\n",
      "########## Evaluation ##########\n",
      "Timestep: 11937 Average reward is -0.0687\n",
      "INFO - Step 12077, loss: 0.40238118171691895\n",
      "########## Evaluation ##########\n",
      "Timestep: 12077 Average reward is -0.0657\n",
      "INFO - Step 12200, loss: 0.62740743160247856\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 12220, loss: 0.58336257934570315\n",
      "########## Evaluation ##########\n",
      "Timestep: 12220 Average reward is -0.0605\n",
      "INFO - Step 12352, loss: 0.43871718645095825\n",
      "########## Evaluation ##########\n",
      "Timestep: 12352 Average reward is -0.0602\n",
      "INFO - Step 12500, loss: 0.53063476085662847\n",
      "########## Evaluation ##########\n",
      "Timestep: 12500 Average reward is -0.0892\n",
      "INFO - Step 12645, loss: 0.47296094894409187\n",
      "########## Evaluation ##########\n",
      "Timestep: 12645 Average reward is -0.0614\n",
      "INFO - Step 12775, loss: 0.61396557092666633\n",
      "########## Evaluation ##########\n",
      "Timestep: 12775 Average reward is -0.0776\n",
      "INFO - Step 12908, loss: 0.52023506164550784\n",
      "########## Evaluation ##########\n",
      "Timestep: 12908 Average reward is -0.0614\n",
      "INFO - Step 13057, loss: 0.51594293117523195\n",
      "########## Evaluation ##########\n",
      "Timestep: 13057 Average reward is -0.0613\n",
      "INFO - Step 13196, loss: 0.52986919879913334\n",
      "########## Evaluation ##########\n",
      "Timestep: 13196 Average reward is -0.0808\n",
      "INFO - Step 13200, loss: 0.39633733034133916\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 13337, loss: 0.44696909189224243\n",
      "########## Evaluation ##########\n",
      "Timestep: 13337 Average reward is -0.0661\n",
      "INFO - Step 13486, loss: 0.42939311265945435\n",
      "########## Evaluation ##########\n",
      "Timestep: 13486 Average reward is -0.0793\n",
      "INFO - Step 13633, loss: 0.39957809448242195\n",
      "########## Evaluation ##########\n",
      "Timestep: 13633 Average reward is -0.069\n",
      "INFO - Step 13769, loss: 0.59215092658996583\n",
      "########## Evaluation ##########\n",
      "Timestep: 13769 Average reward is -0.0731\n",
      "INFO - Step 13916, loss: 0.66267657279968266\n",
      "########## Evaluation ##########\n",
      "Timestep: 13916 Average reward is -0.0737\n",
      "INFO - Step 14051, loss: 0.50760722160339366\n",
      "########## Evaluation ##########\n",
      "Timestep: 14051 Average reward is -0.0724\n",
      "INFO - Step 14183, loss: 0.64643561840057373\n",
      "########## Evaluation ##########\n",
      "Timestep: 14183 Average reward is -0.0612\n",
      "INFO - Step 14200, loss: 0.62128233909606937\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 14328, loss: 0.49728256464004517\n",
      "########## Evaluation ##########\n",
      "Timestep: 14328 Average reward is -0.0803\n",
      "INFO - Step 14476, loss: 0.45618060231208885\n",
      "########## Evaluation ##########\n",
      "Timestep: 14476 Average reward is -0.0601\n",
      "INFO - Step 14626, loss: 0.25495618581771856\n",
      "########## Evaluation ##########\n",
      "Timestep: 14626 Average reward is -0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 14758, loss: 0.51538145542144786\n",
      "########## Evaluation ##########\n",
      "Timestep: 14758 Average reward is -0.0645\n",
      "INFO - Step 14892, loss: 0.48918437957763675\n",
      "########## Evaluation ##########\n",
      "Timestep: 14892 Average reward is -0.072\n",
      "INFO - Step 15038, loss: 0.49480485916137695\n",
      "########## Evaluation ##########\n",
      "Timestep: 15038 Average reward is -0.0728\n",
      "INFO - Step 15179, loss: 0.40406340360641483\n",
      "########## Evaluation ##########\n",
      "Timestep: 15179 Average reward is -0.0736\n",
      "INFO - Step 15200, loss: 0.58654731512069716\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 15329, loss: 0.60085463523864753\n",
      "########## Evaluation ##########\n",
      "Timestep: 15329 Average reward is -0.0633\n",
      "INFO - Step 15476, loss: 0.50157791376113896\n",
      "########## Evaluation ##########\n",
      "Timestep: 15476 Average reward is -0.0667\n",
      "INFO - Step 15622, loss: 0.73205351829528817\n",
      "########## Evaluation ##########\n",
      "Timestep: 15622 Average reward is -0.0807\n",
      "INFO - Step 15774, loss: 0.48099109530448914\n",
      "########## Evaluation ##########\n",
      "Timestep: 15774 Average reward is -0.0678\n",
      "INFO - Step 15922, loss: 0.70421665906906133\n",
      "########## Evaluation ##########\n",
      "Timestep: 15922 Average reward is -0.0761\n",
      "INFO - Step 16068, loss: 0.64594960212707527\n",
      "########## Evaluation ##########\n",
      "Timestep: 16068 Average reward is -0.0533\n",
      "INFO - Step 16200, loss: 0.60978740453720097\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 16203, loss: 0.5771573781967163\n",
      "########## Evaluation ##########\n",
      "Timestep: 16203 Average reward is -0.079\n",
      "INFO - Step 16339, loss: 0.60100805759429935\n",
      "########## Evaluation ##########\n",
      "Timestep: 16339 Average reward is -0.0668\n",
      "INFO - Step 16480, loss: 0.48833844065666256\n",
      "########## Evaluation ##########\n",
      "Timestep: 16480 Average reward is -0.0622\n",
      "INFO - Step 16610, loss: 0.45765995979309084\n",
      "########## Evaluation ##########\n",
      "Timestep: 16610 Average reward is -0.0589\n",
      "INFO - Step 16751, loss: 0.54089343547821047\n",
      "########## Evaluation ##########\n",
      "Timestep: 16751 Average reward is -0.0659\n",
      "INFO - Step 16893, loss: 0.60500282049179084\n",
      "########## Evaluation ##########\n",
      "Timestep: 16893 Average reward is -0.0647\n",
      "INFO - Step 17036, loss: 0.42019245028495795\n",
      "########## Evaluation ##########\n",
      "Timestep: 17036 Average reward is -0.0817\n",
      "INFO - Step 17179, loss: 0.46709004044532776\n",
      "########## Evaluation ##########\n",
      "Timestep: 17179 Average reward is -0.0632\n",
      "INFO - Step 17200, loss: 0.87312543392181496\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 17319, loss: 0.76756334304809573\n",
      "########## Evaluation ##########\n",
      "Timestep: 17319 Average reward is -0.0784\n",
      "INFO - Step 17448, loss: 0.58821392059326174\n",
      "########## Evaluation ##########\n",
      "Timestep: 17448 Average reward is -0.0704\n",
      "INFO - Step 17592, loss: 0.37621259689331055\n",
      "########## Evaluation ##########\n",
      "Timestep: 17592 Average reward is -0.0718\n",
      "INFO - Step 17733, loss: 0.68170964717864994\n",
      "########## Evaluation ##########\n",
      "Timestep: 17733 Average reward is -0.0682\n",
      "INFO - Step 17893, loss: 0.51440542936325076\n",
      "########## Evaluation ##########\n",
      "Timestep: 17893 Average reward is -0.0602\n",
      "INFO - Step 18024, loss: 0.70174932479858455\n",
      "########## Evaluation ##########\n",
      "Timestep: 18024 Average reward is -0.0809\n",
      "INFO - Step 18170, loss: 0.56421661376953124\n",
      "########## Evaluation ##########\n",
      "Timestep: 18170 Average reward is -0.0821\n",
      "INFO - Step 18200, loss: 0.50737899541854864\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 18310, loss: 0.70661711692810066\n",
      "########## Evaluation ##########\n",
      "Timestep: 18310 Average reward is -0.0745\n",
      "INFO - Step 18457, loss: 0.52466797828674326\n",
      "########## Evaluation ##########\n",
      "Timestep: 18457 Average reward is -0.0718\n",
      "INFO - Step 18599, loss: 0.52935445308685313\n",
      "########## Evaluation ##########\n",
      "Timestep: 18599 Average reward is -0.0476\n",
      "INFO - Step 18739, loss: 0.56125462055206314\n",
      "########## Evaluation ##########\n",
      "Timestep: 18739 Average reward is -0.0753\n",
      "INFO - Step 18889, loss: 0.43856886029243475\n",
      "########## Evaluation ##########\n",
      "Timestep: 18889 Average reward is -0.0722\n",
      "INFO - Step 19030, loss: 0.57783734798431486\n",
      "########## Evaluation ##########\n",
      "Timestep: 19030 Average reward is -0.0604\n",
      "INFO - Step 19173, loss: 0.52067017555236823\n",
      "########## Evaluation ##########\n",
      "Timestep: 19173 Average reward is -0.0778\n",
      "INFO - Step 19200, loss: 0.60005939006805425\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 19316, loss: 0.59461605548858643\n",
      "########## Evaluation ##########\n",
      "Timestep: 19316 Average reward is -0.0573\n",
      "INFO - Step 19460, loss: 0.49018663167953493\n",
      "########## Evaluation ##########\n",
      "Timestep: 19460 Average reward is -0.0659\n",
      "INFO - Step 19591, loss: 0.51267790794372567\n",
      "########## Evaluation ##########\n",
      "Timestep: 19591 Average reward is -0.0572\n",
      "INFO - Step 19727, loss: 0.54283893108367927\n",
      "########## Evaluation ##########\n",
      "Timestep: 19727 Average reward is -0.0683\n",
      "INFO - Step 19881, loss: 0.38636910915374756\n",
      "########## Evaluation ##########\n",
      "Timestep: 19881 Average reward is -0.063\n",
      "INFO - Step 20013, loss: 0.50860208272933966\n",
      "########## Evaluation ##########\n",
      "Timestep: 20013 Average reward is -0.0541\n",
      "INFO - Step 20154, loss: 0.72563505172729495\n",
      "########## Evaluation ##########\n",
      "Timestep: 20154 Average reward is -0.0518\n",
      "INFO - Step 20200, loss: 0.57464206218719486\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 20299, loss: 0.52212685346603393\n",
      "########## Evaluation ##########\n",
      "Timestep: 20299 Average reward is -0.0665\n",
      "INFO - Step 20447, loss: 0.69516795873641977\n",
      "########## Evaluation ##########\n",
      "Timestep: 20447 Average reward is -0.0572\n",
      "INFO - Step 20597, loss: 0.59720450639724737\n",
      "########## Evaluation ##########\n",
      "Timestep: 20597 Average reward is -0.0749\n",
      "INFO - Step 20733, loss: 0.55280005931854257\n",
      "########## Evaluation ##########\n",
      "Timestep: 20733 Average reward is -0.067\n",
      "INFO - Step 20872, loss: 0.49860048294067383\n",
      "########## Evaluation ##########\n",
      "Timestep: 20872 Average reward is -0.0781\n",
      "INFO - Step 21008, loss: 0.56131839752197275\n",
      "########## Evaluation ##########\n",
      "Timestep: 21008 Average reward is -0.0705\n",
      "INFO - Step 21144, loss: 0.46764606237411537\n",
      "########## Evaluation ##########\n",
      "Timestep: 21144 Average reward is -0.0721\n",
      "INFO - Step 21200, loss: 0.59894007444381714\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 21281, loss: 0.53014361858367927\n",
      "########## Evaluation ##########\n",
      "Timestep: 21281 Average reward is -0.0671\n",
      "INFO - Step 21426, loss: 0.56835860013961795\n",
      "########## Evaluation ##########\n",
      "Timestep: 21426 Average reward is -0.0895\n",
      "INFO - Step 21574, loss: 0.46305987238883977\n",
      "########## Evaluation ##########\n",
      "Timestep: 21574 Average reward is -0.0699\n",
      "INFO - Step 21715, loss: 0.52023458480834964\n",
      "########## Evaluation ##########\n",
      "Timestep: 21715 Average reward is -0.0803\n",
      "INFO - Step 21862, loss: 0.24281302094459534\n",
      "########## Evaluation ##########\n",
      "Timestep: 21862 Average reward is -0.0653\n",
      "INFO - Step 22013, loss: 0.37252625823020935\n",
      "########## Evaluation ##########\n",
      "Timestep: 22013 Average reward is -0.0767\n",
      "INFO - Step 22155, loss: 0.77242940664291383\n",
      "########## Evaluation ##########\n",
      "Timestep: 22155 Average reward is -0.0613\n",
      "INFO - Step 22200, loss: 0.61182749271392827\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 22295, loss: 0.64178442955017096\n",
      "########## Evaluation ##########\n",
      "Timestep: 22295 Average reward is -0.082\n",
      "INFO - Step 22442, loss: 0.58675062656402595\n",
      "########## Evaluation ##########\n",
      "Timestep: 22442 Average reward is -0.0642\n",
      "INFO - Step 22584, loss: 0.56347221136093146\n",
      "########## Evaluation ##########\n",
      "Timestep: 22584 Average reward is -0.0682\n",
      "INFO - Step 22727, loss: 0.48202189803123474\n",
      "########## Evaluation ##########\n",
      "Timestep: 22727 Average reward is -0.0693\n",
      "INFO - Step 22873, loss: 0.60371190309524544\n",
      "########## Evaluation ##########\n",
      "Timestep: 22873 Average reward is -0.0763\n",
      "INFO - Step 23017, loss: 0.64232707023620644\n",
      "########## Evaluation ##########\n",
      "Timestep: 23017 Average reward is -0.0546\n",
      "INFO - Step 23160, loss: 0.46354934573173523\n",
      "########## Evaluation ##########\n",
      "Timestep: 23160 Average reward is -0.06\n",
      "INFO - Step 23200, loss: 0.37100267410278323\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 23309, loss: 0.55585223436355593\n",
      "########## Evaluation ##########\n",
      "Timestep: 23309 Average reward is -0.0727\n",
      "INFO - Step 23461, loss: 0.56710278987884524\n",
      "########## Evaluation ##########\n",
      "Timestep: 23461 Average reward is -0.0677\n",
      "INFO - Step 23614, loss: 0.58752423524856576\n",
      "########## Evaluation ##########\n",
      "Timestep: 23614 Average reward is -0.068\n",
      "INFO - Step 23764, loss: 0.56276810169219977\n",
      "########## Evaluation ##########\n",
      "Timestep: 23764 Average reward is -0.0478\n",
      "INFO - Step 23903, loss: 0.50975227355957037\n",
      "########## Evaluation ##########\n",
      "Timestep: 23903 Average reward is -0.0651\n",
      "INFO - Step 24048, loss: 0.72598779201507575\n",
      "########## Evaluation ##########\n",
      "Timestep: 24048 Average reward is -0.0768\n",
      "INFO - Step 24195, loss: 0.42807155847549447\n",
      "########## Evaluation ##########\n",
      "Timestep: 24195 Average reward is -0.0723\n",
      "INFO - Step 24200, loss: 0.49263599514961246\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 24340, loss: 0.82554334402084356\n",
      "########## Evaluation ##########\n",
      "Timestep: 24340 Average reward is -0.0734\n",
      "INFO - Step 24480, loss: 0.55504524707794194\n",
      "########## Evaluation ##########\n",
      "Timestep: 24480 Average reward is -0.0639\n",
      "INFO - Step 24619, loss: 0.59617471694946297\n",
      "########## Evaluation ##########\n",
      "Timestep: 24619 Average reward is -0.0899\n",
      "INFO - Step 24759, loss: 0.50261759757995636\n",
      "########## Evaluation ##########\n",
      "Timestep: 24759 Average reward is -0.0451\n",
      "INFO - Step 24901, loss: 0.66420352458953867\n",
      "########## Evaluation ##########\n",
      "Timestep: 24901 Average reward is -0.0615\n",
      "INFO - Step 25045, loss: 0.46506831049919136\n",
      "########## Evaluation ##########\n",
      "Timestep: 25045 Average reward is -0.0713\n",
      "INFO - Step 25191, loss: 0.81143271923065195\n",
      "########## Evaluation ##########\n",
      "Timestep: 25191 Average reward is -0.058\n",
      "INFO - Step 25200, loss: 0.63126587867736826\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 25336, loss: 0.69955128431320195\n",
      "########## Evaluation ##########\n",
      "Timestep: 25336 Average reward is -0.0895\n",
      "INFO - Step 25477, loss: 0.52631390094757086\n",
      "########## Evaluation ##########\n",
      "Timestep: 25477 Average reward is -0.0576\n",
      "INFO - Step 25612, loss: 0.43325686454772956\n",
      "########## Evaluation ##########\n",
      "Timestep: 25612 Average reward is -0.0816\n",
      "INFO - Step 25766, loss: 0.51242375373840335\n",
      "########## Evaluation ##########\n",
      "Timestep: 25766 Average reward is -0.0567\n",
      "INFO - Step 25909, loss: 0.50085413455963135\n",
      "########## Evaluation ##########\n",
      "Timestep: 25909 Average reward is -0.078\n",
      "INFO - Step 26056, loss: 0.63396835327148447\n",
      "########## Evaluation ##########\n",
      "Timestep: 26056 Average reward is -0.0506\n",
      "INFO - Step 26200, loss: 0.50827753543853766\n",
      "########## Evaluation ##########\n",
      "Timestep: 26200 Average reward is -0.0803\n",
      "\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 26346, loss: 0.47260171175003053\n",
      "########## Evaluation ##########\n",
      "Timestep: 26346 Average reward is -0.0649\n",
      "INFO - Step 26491, loss: 0.48241490125656135\n",
      "########## Evaluation ##########\n",
      "Timestep: 26491 Average reward is -0.0639\n",
      "INFO - Step 26637, loss: 0.49408209323883057\n",
      "########## Evaluation ##########\n",
      "Timestep: 26637 Average reward is -0.0734\n",
      "INFO - Step 26791, loss: 0.62378877401351935\n",
      "########## Evaluation ##########\n",
      "Timestep: 26791 Average reward is -0.0709\n",
      "INFO - Step 26947, loss: 0.59221696853637754\n",
      "########## Evaluation ##########\n",
      "Timestep: 26947 Average reward is -0.0678\n",
      "INFO - Step 27092, loss: 0.48812752962112427\n",
      "########## Evaluation ##########\n",
      "Timestep: 27092 Average reward is -0.0713\n",
      "INFO - Step 27200, loss: 0.66899025440216063\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 27231, loss: 0.52650803327560424\n",
      "########## Evaluation ##########\n",
      "Timestep: 27231 Average reward is -0.0564\n",
      "INFO - Step 27378, loss: 0.44739422202110295\n",
      "########## Evaluation ##########\n",
      "Timestep: 27378 Average reward is -0.0577\n",
      "INFO - Step 27523, loss: 0.52346789836883547\n",
      "########## Evaluation ##########\n",
      "Timestep: 27523 Average reward is -0.0785\n",
      "INFO - Step 27674, loss: 0.69267535209655763\n",
      "########## Evaluation ##########\n",
      "Timestep: 27674 Average reward is -0.067\n",
      "INFO - Step 27818, loss: 0.46656847000122076\n",
      "########## Evaluation ##########\n",
      "Timestep: 27818 Average reward is -0.0636\n",
      "INFO - Step 27966, loss: 0.40702983736991884\n",
      "########## Evaluation ##########\n",
      "Timestep: 27966 Average reward is -0.0623\n",
      "INFO - Step 28114, loss: 0.62956488132476813\n",
      "########## Evaluation ##########\n",
      "Timestep: 28114 Average reward is -0.0744\n",
      "INFO - Step 28200, loss: 0.44251292943954474\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 28265, loss: 0.53433489799499514\n",
      "########## Evaluation ##########\n",
      "Timestep: 28265 Average reward is -0.0725\n",
      "INFO - Step 28405, loss: 0.74936598539352425\n",
      "########## Evaluation ##########\n",
      "Timestep: 28405 Average reward is -0.064\n",
      "INFO - Step 28555, loss: 0.47647929191589355\n",
      "########## Evaluation ##########\n",
      "Timestep: 28555 Average reward is -0.0649\n",
      "INFO - Step 28697, loss: 0.56622362136840826\n",
      "########## Evaluation ##########\n",
      "Timestep: 28697 Average reward is -0.0666\n",
      "INFO - Step 28843, loss: 0.36940017342567444\n",
      "########## Evaluation ##########\n",
      "Timestep: 28843 Average reward is -0.0639\n",
      "INFO - Step 28986, loss: 0.51696550846099855\n",
      "########## Evaluation ##########\n",
      "Timestep: 28986 Average reward is -0.0676\n",
      "INFO - Step 29141, loss: 0.60274374485015873\n",
      "########## Evaluation ##########\n",
      "Timestep: 29141 Average reward is -0.0593\n",
      "INFO - Step 29200, loss: 0.69609057903289826\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 29289, loss: 0.53645873069763184\n",
      "########## Evaluation ##########\n",
      "Timestep: 29289 Average reward is -0.0662\n",
      "INFO - Step 29441, loss: 0.55544441938400274\n",
      "########## Evaluation ##########\n",
      "Timestep: 29441 Average reward is -0.0739\n",
      "INFO - Step 29583, loss: 0.48076590895652775\n",
      "########## Evaluation ##########\n",
      "Timestep: 29583 Average reward is -0.0703\n",
      "INFO - Step 29626, loss: 0.59896212816238484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 29737, loss: 0.39924341440200806\n",
      "########## Evaluation ##########\n",
      "Timestep: 29737 Average reward is -0.0901\n",
      "INFO - Step 29887, loss: 0.61211824417114265\n",
      "########## Evaluation ##########\n",
      "Timestep: 29887 Average reward is -0.0601\n",
      "INFO - Step 30027, loss: 0.54617989063262946\n",
      "########## Evaluation ##########\n",
      "Timestep: 30027 Average reward is -0.0738\n",
      "INFO - Step 30162, loss: 0.50404405593872073\n",
      "########## Evaluation ##########\n",
      "Timestep: 30162 Average reward is -0.081\n",
      "INFO - Step 30200, loss: 0.45176714658737187\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 30305, loss: 0.61537456512451173\n",
      "########## Evaluation ##########\n",
      "Timestep: 30305 Average reward is -0.0839\n",
      "INFO - Step 30457, loss: 0.40182745456695557\n",
      "########## Evaluation ##########\n",
      "Timestep: 30457 Average reward is -0.0554\n",
      "INFO - Step 30610, loss: 0.45347458124160767\n",
      "########## Evaluation ##########\n",
      "Timestep: 30610 Average reward is -0.0766\n",
      "INFO - Step 30753, loss: 0.32254457473754883\n",
      "########## Evaluation ##########\n",
      "Timestep: 30753 Average reward is -0.0621\n",
      "INFO - Step 30906, loss: 0.48723736405372625\n",
      "########## Evaluation ##########\n",
      "Timestep: 30906 Average reward is -0.069\n",
      "INFO - Step 31059, loss: 0.67810189723968516\n",
      "########## Evaluation ##########\n",
      "Timestep: 31059 Average reward is -0.0693\n",
      "INFO - Step 31100, loss: 0.41635036468505866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 31200, loss: 0.53237211704254153\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 31214, loss: 0.37848860025405884\n",
      "########## Evaluation ##########\n",
      "Timestep: 31214 Average reward is -0.0648\n",
      "INFO - Step 31363, loss: 0.62139081954956056\n",
      "########## Evaluation ##########\n",
      "Timestep: 31363 Average reward is -0.0643\n",
      "INFO - Step 31512, loss: 0.64104110002517754\n",
      "########## Evaluation ##########\n",
      "Timestep: 31512 Average reward is -0.0626\n",
      "INFO - Step 31657, loss: 0.51619052886962897\n",
      "########## Evaluation ##########\n",
      "Timestep: 31657 Average reward is -0.0667\n",
      "INFO - Step 31800, loss: 0.54419606924057014\n",
      "########## Evaluation ##########\n",
      "Timestep: 31800 Average reward is -0.0851\n",
      "INFO - Step 31940, loss: 0.85574197769165046\n",
      "########## Evaluation ##########\n",
      "Timestep: 31940 Average reward is -0.0724\n",
      "INFO - Step 32084, loss: 0.58445584774017335\n",
      "########## Evaluation ##########\n",
      "Timestep: 32084 Average reward is -0.071\n",
      "INFO - Step 32200, loss: 0.52224397659301764\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 32228, loss: 0.70385891199111945\n",
      "########## Evaluation ##########\n",
      "Timestep: 32228 Average reward is -0.0823\n",
      "INFO - Step 32392, loss: 0.41413682699203497\n",
      "########## Evaluation ##########\n",
      "Timestep: 32392 Average reward is -0.0698\n",
      "INFO - Step 32543, loss: 0.48857268691062935\n",
      "########## Evaluation ##########\n",
      "Timestep: 32543 Average reward is -0.0728\n",
      "INFO - Step 32581, loss: 0.50548350811004644"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 32692, loss: 0.45442640781402594\n",
      "########## Evaluation ##########\n",
      "Timestep: 32692 Average reward is -0.0717\n",
      "INFO - Step 32831, loss: 0.83650630712509163\n",
      "########## Evaluation ##########\n",
      "Timestep: 32831 Average reward is -0.0884\n",
      "INFO - Step 32974, loss: 0.42782503366470337\n",
      "########## Evaluation ##########\n",
      "Timestep: 32974 Average reward is -0.055\n",
      "INFO - Step 33122, loss: 0.57120454311370856\n",
      "########## Evaluation ##########\n",
      "Timestep: 33122 Average reward is -0.0651\n",
      "INFO - Step 33200, loss: 0.59919673204422854\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 33278, loss: 0.57561528682708745\n",
      "########## Evaluation ##########\n",
      "Timestep: 33278 Average reward is -0.0665\n",
      "INFO - Step 33432, loss: 0.53216552734375336\n",
      "########## Evaluation ##########\n",
      "Timestep: 33432 Average reward is -0.0531\n",
      "INFO - Step 33588, loss: 0.67718791961669926\n",
      "########## Evaluation ##########\n",
      "Timestep: 33588 Average reward is -0.0769\n",
      "INFO - Step 33736, loss: 0.47817635536193855\n",
      "########## Evaluation ##########\n",
      "Timestep: 33736 Average reward is -0.0811\n",
      "INFO - Step 33875, loss: 0.61574292182922363\n",
      "########## Evaluation ##########\n",
      "Timestep: 33875 Average reward is -0.0816\n",
      "INFO - Step 34022, loss: 0.60116457939147957\n",
      "########## Evaluation ##########\n",
      "Timestep: 34022 Average reward is -0.0674\n",
      "INFO - Step 34065, loss: 0.73670047521591193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 34165, loss: 0.67277073860168463\n",
      "########## Evaluation ##########\n",
      "Timestep: 34165 Average reward is -0.0718\n",
      "INFO - Step 34200, loss: 0.57087355852127086\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 34315, loss: 0.49557781219482427\n",
      "########## Evaluation ##########\n",
      "Timestep: 34315 Average reward is -0.068\n",
      "INFO - Step 34467, loss: 0.32243880629539496\n",
      "########## Evaluation ##########\n",
      "Timestep: 34467 Average reward is -0.0489\n",
      "INFO - Step 34615, loss: 0.45913153886795044\n",
      "########## Evaluation ##########\n",
      "Timestep: 34615 Average reward is -0.0633\n",
      "INFO - Step 34766, loss: 0.46434372663497925\n",
      "########## Evaluation ##########\n",
      "Timestep: 34766 Average reward is -0.0632\n",
      "INFO - Step 34918, loss: 0.41724789142608647\n",
      "########## Evaluation ##########\n",
      "Timestep: 34918 Average reward is -0.0556\n",
      "INFO - Step 35066, loss: 0.46598148345947266\n",
      "########## Evaluation ##########\n",
      "Timestep: 35066 Average reward is -0.0683\n",
      "INFO - Step 35200, loss: 0.51527041196823125\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 35224, loss: 0.41371244192123413\n",
      "########## Evaluation ##########\n",
      "Timestep: 35224 Average reward is -0.0638\n",
      "INFO - Step 35387, loss: 0.42697370052337646\n",
      "########## Evaluation ##########\n",
      "Timestep: 35387 Average reward is -0.0787\n",
      "INFO - Step 35535, loss: 0.45672643184661865\n",
      "########## Evaluation ##########\n",
      "Timestep: 35535 Average reward is -0.0765\n",
      "INFO - Step 35579, loss: 0.54705429077148444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 35694, loss: 0.51074838638305666\n",
      "########## Evaluation ##########\n",
      "Timestep: 35694 Average reward is -0.0862\n",
      "INFO - Step 35849, loss: 0.52979099750518874\n",
      "########## Evaluation ##########\n",
      "Timestep: 35849 Average reward is -0.0554\n",
      "INFO - Step 35993, loss: 0.70528107881546024\n",
      "########## Evaluation ##########\n",
      "Timestep: 35993 Average reward is -0.0861\n",
      "INFO - Step 36139, loss: 0.38691934943199166\n",
      "########## Evaluation ##########\n",
      "Timestep: 36139 Average reward is -0.0794\n",
      "INFO - Step 36200, loss: 0.41941392421722415\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 36281, loss: 0.36578825116157534\n",
      "########## Evaluation ##########\n",
      "Timestep: 36281 Average reward is -0.0743\n",
      "INFO - Step 36435, loss: 0.40710750222206116\n",
      "########## Evaluation ##########\n",
      "Timestep: 36435 Average reward is -0.0752\n",
      "INFO - Step 36588, loss: 0.52710109949111945\n",
      "########## Evaluation ##########\n",
      "Timestep: 36588 Average reward is -0.0679\n",
      "INFO - Step 36749, loss: 0.46179252862930324\n",
      "########## Evaluation ##########\n",
      "Timestep: 36749 Average reward is -0.0707\n",
      "INFO - Step 36894, loss: 0.67935812473297126\n",
      "########## Evaluation ##########\n",
      "Timestep: 36894 Average reward is -0.0892\n",
      "INFO - Step 37051, loss: 0.45329111814498983\n",
      "########## Evaluation ##########\n",
      "Timestep: 37051 Average reward is -0.076\n",
      "INFO - Step 37088, loss: 0.43422374129295356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 37200, loss: 0.51358270645141653\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 37202, loss: 0.49736011028289795\n",
      "########## Evaluation ##########\n",
      "Timestep: 37202 Average reward is -0.0572\n",
      "INFO - Step 37356, loss: 0.61005085706710824\n",
      "########## Evaluation ##########\n",
      "Timestep: 37356 Average reward is -0.065\n",
      "INFO - Step 37518, loss: 0.47030049562454224\n",
      "########## Evaluation ##########\n",
      "Timestep: 37518 Average reward is -0.0735\n",
      "INFO - Step 37680, loss: 0.43668019771575933\n",
      "########## Evaluation ##########\n",
      "Timestep: 37680 Average reward is -0.0739\n",
      "INFO - Step 37822, loss: 0.57733607292175293\n",
      "########## Evaluation ##########\n",
      "Timestep: 37822 Average reward is -0.0881\n",
      "INFO - Step 37971, loss: 0.60991132259368903\n",
      "########## Evaluation ##########\n",
      "Timestep: 37971 Average reward is -0.0733\n",
      "INFO - Step 38113, loss: 0.56148946285247825\n",
      "########## Evaluation ##########\n",
      "Timestep: 38113 Average reward is -0.0796\n",
      "INFO - Step 38200, loss: 0.44805687665939337\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 38263, loss: 0.36532723903656006\n",
      "########## Evaluation ##########\n",
      "Timestep: 38263 Average reward is -0.0677\n",
      "INFO - Step 38402, loss: 0.43285968899726874\n",
      "########## Evaluation ##########\n",
      "Timestep: 38402 Average reward is -0.0895\n",
      "INFO - Step 38549, loss: 0.70710688829422896\n",
      "########## Evaluation ##########\n",
      "Timestep: 38549 Average reward is -0.0985\n",
      "INFO - Step 38586, loss: 0.50746685266494753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 38701, loss: 0.61737501621246345\n",
      "########## Evaluation ##########\n",
      "Timestep: 38701 Average reward is -0.0683\n",
      "INFO - Step 38845, loss: 0.52108782529830934\n",
      "########## Evaluation ##########\n",
      "Timestep: 38845 Average reward is -0.0761\n",
      "INFO - Step 38997, loss: 0.50418734550476075\n",
      "########## Evaluation ##########\n",
      "Timestep: 38997 Average reward is -0.0747\n",
      "INFO - Step 39159, loss: 0.35631418228149414\n",
      "########## Evaluation ##########\n",
      "Timestep: 39159 Average reward is -0.073\n",
      "INFO - Step 39200, loss: 0.33775323629379274\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 39302, loss: 0.50175571441650394\n",
      "########## Evaluation ##########\n",
      "Timestep: 39302 Average reward is -0.0721\n",
      "INFO - Step 39457, loss: 0.67837738990783696\n",
      "########## Evaluation ##########\n",
      "Timestep: 39457 Average reward is -0.0768\n",
      "INFO - Step 39613, loss: 0.56199514865875246\n",
      "########## Evaluation ##########\n",
      "Timestep: 39613 Average reward is -0.0781\n",
      "INFO - Step 39770, loss: 0.31935530900955276\n",
      "########## Evaluation ##########\n",
      "Timestep: 39770 Average reward is -0.0763\n",
      "INFO - Step 39926, loss: 0.47597467899322516\n",
      "########## Evaluation ##########\n",
      "Timestep: 39926 Average reward is -0.0921\n",
      "INFO - Step 40083, loss: 0.33887481689453125\n",
      "########## Evaluation ##########\n",
      "Timestep: 40083 Average reward is -0.0832\n",
      "INFO - Step 40121, loss: 0.36483746767044077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 40200, loss: 0.68344533443450933\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 40245, loss: 0.59689295291900635\n",
      "########## Evaluation ##########\n",
      "Timestep: 40245 Average reward is -0.0675\n",
      "INFO - Step 40406, loss: 0.65015482902526864\n",
      "########## Evaluation ##########\n",
      "Timestep: 40406 Average reward is -0.0777\n",
      "INFO - Step 40559, loss: 0.57537007331848143\n",
      "########## Evaluation ##########\n",
      "Timestep: 40559 Average reward is -0.0686\n",
      "INFO - Step 40721, loss: 0.61839246749877937\n",
      "########## Evaluation ##########\n",
      "Timestep: 40721 Average reward is -0.0745\n",
      "INFO - Step 40882, loss: 0.57593649625778215\n",
      "########## Evaluation ##########\n",
      "Timestep: 40882 Average reward is -0.0824\n",
      "INFO - Step 41045, loss: 0.54354250431060793\n",
      "########## Evaluation ##########\n",
      "Timestep: 41045 Average reward is -0.0655\n",
      "INFO - Step 41197, loss: 0.57647901773452767\n",
      "########## Evaluation ##########\n",
      "Timestep: 41197 Average reward is -0.0687\n",
      "INFO - Step 41200, loss: 0.75384527444839487\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 41351, loss: 0.27658897638320923\n",
      "########## Evaluation ##########\n",
      "Timestep: 41351 Average reward is -0.0748\n",
      "INFO - Step 41506, loss: 0.46655791997909546\n",
      "########## Evaluation ##########\n",
      "Timestep: 41506 Average reward is -0.0855\n",
      "INFO - Step 41662, loss: 0.41611802577972416\n",
      "########## Evaluation ##########\n",
      "Timestep: 41662 Average reward is -0.0797\n",
      "INFO - Step 41706, loss: 0.46971559524536133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 41810, loss: 0.54612791538238534\n",
      "########## Evaluation ##########\n",
      "Timestep: 41810 Average reward is -0.0575\n",
      "INFO - Step 41968, loss: 0.79375988245010385\n",
      "########## Evaluation ##########\n",
      "Timestep: 41968 Average reward is -0.0729\n",
      "INFO - Step 42120, loss: 0.45555317401885986\n",
      "########## Evaluation ##########\n",
      "Timestep: 42120 Average reward is -0.0637\n",
      "INFO - Step 42200, loss: 0.51154047250747687\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 42266, loss: 0.41631448268890387\n",
      "########## Evaluation ##########\n",
      "Timestep: 42266 Average reward is -0.0844\n",
      "INFO - Step 42419, loss: 0.43850654363632215\n",
      "########## Evaluation ##########\n",
      "Timestep: 42419 Average reward is -0.0694\n",
      "INFO - Step 42566, loss: 0.60010790824890143\n",
      "########## Evaluation ##########\n",
      "Timestep: 42566 Average reward is -0.0813\n",
      "INFO - Step 42708, loss: 0.40317225456237793\n",
      "########## Evaluation ##########\n",
      "Timestep: 42708 Average reward is -0.072\n",
      "INFO - Step 42872, loss: 0.46815827488899236\n",
      "########## Evaluation ##########\n",
      "Timestep: 42872 Average reward is -0.0697\n",
      "INFO - Step 43010, loss: 0.57502746582031253\n",
      "########## Evaluation ##########\n",
      "Timestep: 43010 Average reward is -0.0741\n",
      "INFO - Step 43167, loss: 0.42251157760620117\n",
      "########## Evaluation ##########\n",
      "Timestep: 43167 Average reward is -0.0737\n",
      "INFO - Step 43200, loss: 0.57212871313095096\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 43201, loss: 0.731124758720398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 43320, loss: 0.65227222442626957\n",
      "########## Evaluation ##########\n",
      "Timestep: 43320 Average reward is -0.0656\n",
      "INFO - Step 43479, loss: 0.48463618755340576\n",
      "########## Evaluation ##########\n",
      "Timestep: 43479 Average reward is -0.0714\n",
      "INFO - Step 43630, loss: 0.52927422523498543\n",
      "########## Evaluation ##########\n",
      "Timestep: 43630 Average reward is -0.0887\n",
      "INFO - Step 43770, loss: 0.48171326518058777\n",
      "########## Evaluation ##########\n",
      "Timestep: 43770 Average reward is -0.0723\n",
      "INFO - Step 43918, loss: 0.35033148527145386\n",
      "########## Evaluation ##########\n",
      "Timestep: 43918 Average reward is -0.0812\n",
      "INFO - Step 44063, loss: 0.62593376636505133\n",
      "########## Evaluation ##########\n",
      "Timestep: 44063 Average reward is -0.0848\n",
      "INFO - Step 44200, loss: 0.69362461566925056\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 44216, loss: 0.34486937522888184\n",
      "########## Evaluation ##########\n",
      "Timestep: 44216 Average reward is -0.0888\n",
      "INFO - Step 44363, loss: 0.47208201885223394\n",
      "########## Evaluation ##########\n",
      "Timestep: 44363 Average reward is -0.0821\n",
      "INFO - Step 44509, loss: 0.54063570499420173\n",
      "########## Evaluation ##########\n",
      "Timestep: 44509 Average reward is -0.0851\n",
      "INFO - Step 44652, loss: 0.50194042921066284\n",
      "########## Evaluation ##########\n",
      "Timestep: 44652 Average reward is -0.0641\n",
      "INFO - Step 44698, loss: 0.58762252330780036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 44797, loss: 0.42218354344367983\n",
      "########## Evaluation ##########\n",
      "Timestep: 44797 Average reward is -0.0745\n",
      "INFO - Step 44947, loss: 0.61738461256027224\n",
      "########## Evaluation ##########\n",
      "Timestep: 44947 Average reward is -0.0651\n",
      "INFO - Step 45112, loss: 0.51112604141235354\n",
      "########## Evaluation ##########\n",
      "Timestep: 45112 Average reward is -0.0713\n",
      "INFO - Step 45200, loss: 0.53731113672256473\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 45265, loss: 0.62564212083816537\n",
      "########## Evaluation ##########\n",
      "Timestep: 45265 Average reward is -0.0678\n",
      "INFO - Step 45410, loss: 0.46670442819595337\n",
      "########## Evaluation ##########\n",
      "Timestep: 45410 Average reward is -0.0867\n",
      "INFO - Step 45558, loss: 0.55996501445770263\n",
      "########## Evaluation ##########\n",
      "Timestep: 45558 Average reward is -0.0848\n",
      "INFO - Step 45713, loss: 0.51534605026245126\n",
      "########## Evaluation ##########\n",
      "Timestep: 45713 Average reward is -0.0803\n",
      "INFO - Step 45882, loss: 0.62662965059280485\n",
      "########## Evaluation ##########\n",
      "Timestep: 45882 Average reward is -0.0804\n",
      "INFO - Step 46027, loss: 0.44329693913459785\n",
      "########## Evaluation ##########\n",
      "Timestep: 46027 Average reward is -0.0565\n",
      "INFO - Step 46174, loss: 0.34313279390335083\n",
      "########## Evaluation ##########\n",
      "Timestep: 46174 Average reward is -0.0664\n",
      "INFO - Step 46200, loss: 0.56677049398422245\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 46201, loss: 0.5125762224197388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 46318, loss: 0.71933114528656016\n",
      "########## Evaluation ##########\n",
      "Timestep: 46318 Average reward is -0.0619\n",
      "INFO - Step 46458, loss: 0.56147873401641856\n",
      "########## Evaluation ##########\n",
      "Timestep: 46458 Average reward is -0.0754\n",
      "INFO - Step 46616, loss: 0.48810493946075446\n",
      "########## Evaluation ##########\n",
      "Timestep: 46616 Average reward is -0.09\n",
      "INFO - Step 46781, loss: 0.42096412181854255\n",
      "########## Evaluation ##########\n",
      "Timestep: 46781 Average reward is -0.0765\n",
      "INFO - Step 46929, loss: 0.31620338559150696\n",
      "########## Evaluation ##########\n",
      "Timestep: 46929 Average reward is -0.0628\n",
      "INFO - Step 47078, loss: 0.54018604755401615\n",
      "########## Evaluation ##########\n",
      "Timestep: 47078 Average reward is -0.0853\n",
      "INFO - Step 47200, loss: 0.53655982017517095\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 47233, loss: 0.52449154853820827\n",
      "########## Evaluation ##########\n",
      "Timestep: 47233 Average reward is -0.0746\n",
      "INFO - Step 47381, loss: 0.57123839855194096\n",
      "########## Evaluation ##########\n",
      "Timestep: 47381 Average reward is -0.0594\n",
      "INFO - Step 47523, loss: 0.45239529013633733\n",
      "########## Evaluation ##########\n",
      "Timestep: 47523 Average reward is -0.0847\n",
      "INFO - Step 47671, loss: 0.43655043840408325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Evaluation ##########\n",
      "Timestep: 47671 Average reward is -0.0556\n",
      "INFO - Step 47822, loss: 0.70582014322280885\n",
      "########## Evaluation ##########\n",
      "Timestep: 47822 Average reward is -0.0678\n",
      "INFO - Step 47963, loss: 0.48740687966346743\n",
      "########## Evaluation ##########\n",
      "Timestep: 47963 Average reward is -0.0762\n",
      "INFO - Step 48119, loss: 0.60123550891876225\n",
      "########## Evaluation ##########\n",
      "Timestep: 48119 Average reward is -0.0731\n",
      "INFO - Step 48200, loss: 0.52684819698333743\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 48273, loss: 0.44803404808044434\n",
      "########## Evaluation ##########\n",
      "Timestep: 48273 Average reward is -0.0661\n",
      "INFO - Step 48427, loss: 0.68514865636825565\n",
      "########## Evaluation ##########\n",
      "Timestep: 48427 Average reward is -0.082\n",
      "INFO - Step 48576, loss: 0.49073106050491333\n",
      "########## Evaluation ##########\n",
      "Timestep: 48576 Average reward is -0.0686\n",
      "INFO - Step 48735, loss: 0.58656877279281627\n",
      "########## Evaluation ##########\n",
      "Timestep: 48735 Average reward is -0.0543\n",
      "INFO - Step 48890, loss: 0.53067934513092043\n",
      "########## Evaluation ##########\n",
      "Timestep: 48890 Average reward is -0.0754\n",
      "INFO - Step 49044, loss: 0.48539876937866215\n",
      "########## Evaluation ##########\n",
      "Timestep: 49044 Average reward is -0.0797\n",
      "INFO - Step 49196, loss: 0.50382679700851443\n",
      "########## Evaluation ##########\n",
      "Timestep: 49196 Average reward is -0.0884\n",
      "INFO - Step 49200, loss: 0.5344406366348267\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 49219, loss: 0.44121500849723816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 49346, loss: 0.47545579075813293\n",
      "########## Evaluation ##########\n",
      "Timestep: 49346 Average reward is -0.0547\n",
      "INFO - Step 49506, loss: 0.52098608016967774\n",
      "########## Evaluation ##########\n",
      "Timestep: 49506 Average reward is -0.082\n",
      "INFO - Step 49680, loss: 0.41028088331222534\n",
      "########## Evaluation ##########\n",
      "Timestep: 49680 Average reward is -0.0871\n",
      "INFO - Step 49828, loss: 0.45583245158195496\n",
      "########## Evaluation ##########\n",
      "Timestep: 49828 Average reward is -0.0655\n",
      "INFO - Step 49983, loss: 0.45487830042839056\n",
      "########## Evaluation ##########\n",
      "Timestep: 49983 Average reward is -0.0767\n",
      "INFO - Step 50125, loss: 0.55446201562881473\n",
      "########## Evaluation ##########\n",
      "Timestep: 50125 Average reward is -0.076\n",
      "INFO - Step 50200, loss: 0.45906475186347967\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 50284, loss: 0.50547218322753914\n",
      "########## Evaluation ##########\n",
      "Timestep: 50284 Average reward is -0.0664\n",
      "INFO - Step 50441, loss: 0.41249433159828186\n",
      "########## Evaluation ##########\n",
      "Timestep: 50441 Average reward is -0.0575\n",
      "INFO - Step 50589, loss: 0.36242276430130005\n",
      "########## Evaluation ##########\n",
      "Timestep: 50589 Average reward is -0.0728\n",
      "INFO - Step 50765, loss: 0.52022725343704223\n",
      "########## Evaluation ##########\n",
      "Timestep: 50765 Average reward is -0.0638\n",
      "INFO - Step 50797, loss: 0.44179695844650277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 50933, loss: 0.38909596204757696\n",
      "########## Evaluation ##########\n",
      "Timestep: 50933 Average reward is -0.0644\n",
      "INFO - Step 51090, loss: 0.48691427707672125\n",
      "########## Evaluation ##########\n",
      "Timestep: 51090 Average reward is -0.0513\n",
      "INFO - Step 51200, loss: 0.45956331491470337\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 51252, loss: 0.47554129362106323\n",
      "########## Evaluation ##########\n",
      "Timestep: 51252 Average reward is -0.0703\n",
      "INFO - Step 51407, loss: 0.44139015674591064\n",
      "########## Evaluation ##########\n",
      "Timestep: 51407 Average reward is -0.0912\n",
      "INFO - Step 51564, loss: 0.63308340311050425\n",
      "########## Evaluation ##########\n",
      "Timestep: 51564 Average reward is -0.0873\n",
      "INFO - Step 51716, loss: 0.59666162729263313\n",
      "########## Evaluation ##########\n",
      "Timestep: 51716 Average reward is -0.0687\n",
      "INFO - Step 51874, loss: 0.37962824106216433\n",
      "########## Evaluation ##########\n",
      "Timestep: 51874 Average reward is -0.0963\n",
      "INFO - Step 52029, loss: 0.56662356853485116\n",
      "########## Evaluation ##########\n",
      "Timestep: 52029 Average reward is -0.073\n",
      "INFO - Step 52180, loss: 0.49046373367309576\n",
      "########## Evaluation ##########\n",
      "Timestep: 52180 Average reward is -0.0852\n",
      "INFO - Step 52200, loss: 0.53623181581497195\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 52327, loss: 0.35927784442901614\n",
      "########## Evaluation ##########\n",
      "Timestep: 52327 Average reward is -0.0652\n",
      "INFO - Step 52352, loss: 0.38552564382553156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 52483, loss: 0.42803514003753664\n",
      "########## Evaluation ##########\n",
      "Timestep: 52483 Average reward is -0.064\n",
      "INFO - Step 52642, loss: 0.46423882246017456\n",
      "########## Evaluation ##########\n",
      "Timestep: 52642 Average reward is -0.0755\n",
      "INFO - Step 52788, loss: 0.57255589962005626\n",
      "########## Evaluation ##########\n",
      "Timestep: 52788 Average reward is -0.0803\n",
      "INFO - Step 52947, loss: 0.59641176462173464\n",
      "########## Evaluation ##########\n",
      "Timestep: 52947 Average reward is -0.0785\n",
      "INFO - Step 53088, loss: 0.41326314210891724\n",
      "########## Evaluation ##########\n",
      "Timestep: 53088 Average reward is -0.0822\n",
      "INFO - Step 53200, loss: 0.49909603595733643\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 53243, loss: 0.64551883935928347\n",
      "########## Evaluation ##########\n",
      "Timestep: 53243 Average reward is -0.0796\n",
      "INFO - Step 53384, loss: 0.44991201162338257\n",
      "########## Evaluation ##########\n",
      "Timestep: 53384 Average reward is -0.0738\n",
      "INFO - Step 53545, loss: 0.47619229555130005\n",
      "########## Evaluation ##########\n",
      "Timestep: 53545 Average reward is -0.0673\n",
      "INFO - Step 53706, loss: 0.35384392738342285\n",
      "########## Evaluation ##########\n",
      "Timestep: 53706 Average reward is -0.0706\n",
      "INFO - Step 53866, loss: 0.55139458179473887\n",
      "########## Evaluation ##########\n",
      "Timestep: 53866 Average reward is -0.0696\n",
      "INFO - Step 53906, loss: 0.65034091472625735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 54017, loss: 0.65050077438354496\n",
      "########## Evaluation ##########\n",
      "Timestep: 54017 Average reward is -0.0554\n",
      "INFO - Step 54167, loss: 0.33909809589385986\n",
      "########## Evaluation ##########\n",
      "Timestep: 54167 Average reward is -0.0736\n",
      "INFO - Step 54200, loss: 0.40866822004318247\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 54316, loss: 0.49826192855834966\n",
      "########## Evaluation ##########\n",
      "Timestep: 54316 Average reward is -0.0745\n",
      "INFO - Step 54490, loss: 0.57759845256805423\n",
      "########## Evaluation ##########\n",
      "Timestep: 54490 Average reward is -0.0811\n",
      "INFO - Step 54639, loss: 0.37913012504577637\n",
      "########## Evaluation ##########\n",
      "Timestep: 54639 Average reward is -0.0759\n",
      "INFO - Step 54802, loss: 0.43950706720352173\n",
      "########## Evaluation ##########\n",
      "Timestep: 54802 Average reward is -0.0872\n",
      "INFO - Step 54947, loss: 0.53630435466766363\n",
      "########## Evaluation ##########\n",
      "Timestep: 54947 Average reward is -0.0669\n",
      "INFO - Step 55099, loss: 0.41539391875267037\n",
      "########## Evaluation ##########\n",
      "Timestep: 55099 Average reward is -0.073\n",
      "INFO - Step 55200, loss: 0.46621674299240114\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 55258, loss: 0.56049454212188724\n",
      "########## Evaluation ##########\n",
      "Timestep: 55258 Average reward is -0.0824\n",
      "INFO - Step 55396, loss: 0.76057547330856326\n",
      "########## Evaluation ##########\n",
      "Timestep: 55396 Average reward is -0.0675\n",
      "INFO - Step 55436, loss: 0.68848073482513433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 55550, loss: 0.47420614957809456\n",
      "########## Evaluation ##########\n",
      "Timestep: 55550 Average reward is -0.076\n",
      "INFO - Step 55712, loss: 0.35920304059982377\n",
      "########## Evaluation ##########\n",
      "Timestep: 55712 Average reward is -0.0755\n",
      "INFO - Step 55853, loss: 0.54141664505004885\n",
      "########## Evaluation ##########\n",
      "Timestep: 55853 Average reward is -0.0787\n",
      "INFO - Step 56018, loss: 0.44307869672775275\n",
      "########## Evaluation ##########\n",
      "Timestep: 56018 Average reward is -0.0746\n",
      "INFO - Step 56173, loss: 0.52665084600448614\n",
      "########## Evaluation ##########\n",
      "Timestep: 56173 Average reward is -0.0767\n",
      "INFO - Step 56200, loss: 0.50100111961364757\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 56327, loss: 0.43206003308296204\n",
      "########## Evaluation ##########\n",
      "Timestep: 56327 Average reward is -0.0931\n",
      "INFO - Step 56485, loss: 0.36028045415878296\n",
      "########## Evaluation ##########\n",
      "Timestep: 56485 Average reward is -0.0724\n",
      "INFO - Step 56648, loss: 0.38745051622390747\n",
      "########## Evaluation ##########\n",
      "Timestep: 56648 Average reward is -0.0893\n",
      "INFO - Step 56804, loss: 0.40994262695312576\n",
      "########## Evaluation ##########\n",
      "Timestep: 56804 Average reward is -0.0788\n",
      "INFO - Step 56950, loss: 0.83360219001770026\n",
      "########## Evaluation ##########\n",
      "Timestep: 56950 Average reward is -0.0614\n",
      "INFO - Step 56988, loss: 0.48964539170265275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 57101, loss: 0.53190112113952643\n",
      "########## Evaluation ##########\n",
      "Timestep: 57101 Average reward is -0.0767\n",
      "INFO - Step 57200, loss: 0.51963466405868534\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 57258, loss: 0.53008919954299933\n",
      "########## Evaluation ##########\n",
      "Timestep: 57258 Average reward is -0.0624\n",
      "INFO - Step 57409, loss: 0.43970298767089844\n",
      "########## Evaluation ##########\n",
      "Timestep: 57409 Average reward is -0.072\n",
      "INFO - Step 57568, loss: 0.58224898576736453\n",
      "########## Evaluation ##########\n",
      "Timestep: 57568 Average reward is -0.0659\n",
      "INFO - Step 57728, loss: 0.53704839944839485\n",
      "########## Evaluation ##########\n",
      "Timestep: 57728 Average reward is -0.0597\n",
      "INFO - Step 57884, loss: 0.53368282318115236\n",
      "########## Evaluation ##########\n",
      "Timestep: 57884 Average reward is -0.0683\n",
      "INFO - Step 58037, loss: 0.42325466871261597\n",
      "########## Evaluation ##########\n",
      "Timestep: 58037 Average reward is -0.0727\n",
      "INFO - Step 58191, loss: 0.44610711932182313\n",
      "########## Evaluation ##########\n",
      "Timestep: 58191 Average reward is -0.0723\n",
      "INFO - Step 58200, loss: 0.46439716219902043\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 58351, loss: 0.69262516498565677\n",
      "########## Evaluation ##########\n",
      "Timestep: 58351 Average reward is -0.0851\n",
      "INFO - Step 58516, loss: 0.64428532123565674\n",
      "########## Evaluation ##########\n",
      "Timestep: 58516 Average reward is -0.0438\n",
      "INFO - Step 58559, loss: 0.52664095163345346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 58668, loss: 0.44015106558799744\n",
      "########## Evaluation ##########\n",
      "Timestep: 58668 Average reward is -0.0771\n",
      "INFO - Step 58818, loss: 0.47718429565429694\n",
      "########## Evaluation ##########\n",
      "Timestep: 58818 Average reward is -0.0701\n",
      "INFO - Step 58962, loss: 0.50922501087188727\n",
      "########## Evaluation ##########\n",
      "Timestep: 58962 Average reward is -0.0629\n",
      "INFO - Step 59111, loss: 0.56874006986618046\n",
      "########## Evaluation ##########\n",
      "Timestep: 59111 Average reward is -0.0604\n",
      "INFO - Step 59200, loss: 0.50728344917297365\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 59270, loss: 0.54465258121490485\n",
      "########## Evaluation ##########\n",
      "Timestep: 59270 Average reward is -0.0748\n",
      "INFO - Step 59431, loss: 0.45368400216102687\n",
      "########## Evaluation ##########\n",
      "Timestep: 59431 Average reward is -0.065\n",
      "INFO - Step 59579, loss: 0.46290487051010136\n",
      "########## Evaluation ##########\n",
      "Timestep: 59579 Average reward is -0.0681\n",
      "INFO - Step 59729, loss: 0.58386331796646126\n",
      "########## Evaluation ##########\n",
      "Timestep: 59729 Average reward is -0.0825\n",
      "INFO - Step 59884, loss: 0.37062370777130127\n",
      "########## Evaluation ##########\n",
      "Timestep: 59884 Average reward is -0.0585\n",
      "INFO - Step 60055, loss: 0.47830042243003845\n",
      "########## Evaluation ##########\n",
      "Timestep: 60055 Average reward is -0.0638\n",
      "INFO - Step 60098, loss: 0.65504157543182377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 60200, loss: 0.75787067413330085\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 60206, loss: 0.3064471185207367\n",
      "########## Evaluation ##########\n",
      "Timestep: 60206 Average reward is -0.0927\n",
      "INFO - Step 60357, loss: 0.40485149621963557\n",
      "########## Evaluation ##########\n",
      "Timestep: 60357 Average reward is -0.0752\n",
      "INFO - Step 60510, loss: 0.29247671365737915\n",
      "########## Evaluation ##########\n",
      "Timestep: 60510 Average reward is -0.0945\n",
      "INFO - Step 60667, loss: 0.48497736454010017\n",
      "########## Evaluation ##########\n",
      "Timestep: 60667 Average reward is -0.0657\n",
      "INFO - Step 60818, loss: 0.55542135238647467\n",
      "########## Evaluation ##########\n",
      "Timestep: 60818 Average reward is -0.067\n",
      "INFO - Step 60979, loss: 0.56259810924530034\n",
      "########## Evaluation ##########\n",
      "Timestep: 60979 Average reward is -0.0739\n",
      "INFO - Step 61145, loss: 0.38661205768585205\n",
      "########## Evaluation ##########\n",
      "Timestep: 61145 Average reward is -0.0704\n",
      "INFO - Step 61200, loss: 0.43417724967002874\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 61303, loss: 0.42931181192398077\n",
      "########## Evaluation ##########\n",
      "Timestep: 61303 Average reward is -0.0789\n",
      "INFO - Step 61459, loss: 0.28477263450622567\n",
      "########## Evaluation ##########\n",
      "Timestep: 61459 Average reward is -0.0634\n",
      "INFO - Step 61614, loss: 0.49740582704544073\n",
      "########## Evaluation ##########\n",
      "Timestep: 61614 Average reward is -0.0921\n",
      "INFO - Step 61660, loss: 0.64562386274337776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 61782, loss: 0.47345459461212163\n",
      "########## Evaluation ##########\n",
      "Timestep: 61782 Average reward is -0.0864\n",
      "INFO - Step 61930, loss: 0.53247463703155526\n",
      "########## Evaluation ##########\n",
      "Timestep: 61930 Average reward is -0.0696\n",
      "INFO - Step 62087, loss: 0.55963563919067384\n",
      "########## Evaluation ##########\n",
      "Timestep: 62087 Average reward is -0.0812\n",
      "INFO - Step 62200, loss: 0.45922699570655824\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 62237, loss: 0.60313481092453535\n",
      "########## Evaluation ##########\n",
      "Timestep: 62237 Average reward is -0.0704\n",
      "INFO - Step 62407, loss: 0.66523820161819466\n",
      "########## Evaluation ##########\n",
      "Timestep: 62407 Average reward is -0.0487\n",
      "INFO - Step 62559, loss: 0.40160217881202793\n",
      "########## Evaluation ##########\n",
      "Timestep: 62559 Average reward is -0.0705\n",
      "INFO - Step 62713, loss: 0.47055840492248535\n",
      "########## Evaluation ##########\n",
      "Timestep: 62713 Average reward is -0.0852\n",
      "INFO - Step 62865, loss: 0.42218029499053955\n",
      "########## Evaluation ##########\n",
      "Timestep: 62865 Average reward is -0.0757\n",
      "INFO - Step 63015, loss: 0.44437184929847724\n",
      "########## Evaluation ##########\n",
      "Timestep: 63015 Average reward is -0.0697\n",
      "INFO - Step 63161, loss: 0.42178332805633545\n",
      "########## Evaluation ##########\n",
      "Timestep: 63161 Average reward is -0.0658\n",
      "INFO - Step 63193, loss: 0.48825582861900334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 63200, loss: 0.49465543031692505\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 63314, loss: 0.55354529619216926\n",
      "########## Evaluation ##########\n",
      "Timestep: 63314 Average reward is -0.0586\n",
      "INFO - Step 63467, loss: 0.56601554155349736\n",
      "########## Evaluation ##########\n",
      "Timestep: 63467 Average reward is -0.082\n",
      "INFO - Step 63619, loss: 0.42693373560905457\n",
      "########## Evaluation ##########\n",
      "Timestep: 63619 Average reward is -0.0831\n",
      "INFO - Step 63776, loss: 0.60481995344161997\n",
      "########## Evaluation ##########\n",
      "Timestep: 63776 Average reward is -0.0776\n",
      "INFO - Step 63945, loss: 0.83554708957672124\n",
      "########## Evaluation ##########\n",
      "Timestep: 63945 Average reward is -0.0663\n",
      "INFO - Step 64090, loss: 0.43757027387619026\n",
      "########## Evaluation ##########\n",
      "Timestep: 64090 Average reward is -0.0749\n",
      "INFO - Step 64200, loss: 0.40073668956756596\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 64246, loss: 0.48361694812774665\n",
      "########## Evaluation ##########\n",
      "Timestep: 64246 Average reward is -0.0726\n",
      "INFO - Step 64399, loss: 0.54296350479125985\n",
      "########## Evaluation ##########\n",
      "Timestep: 64399 Average reward is -0.0669\n",
      "INFO - Step 64560, loss: 0.60759699344635016\n",
      "########## Evaluation ##########\n",
      "Timestep: 64560 Average reward is -0.0573\n",
      "INFO - Step 64730, loss: 0.53442251682281495\n",
      "########## Evaluation ##########\n",
      "Timestep: 64730 Average reward is -0.0796\n",
      "INFO - Step 64770, loss: 0.67048555612564097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 64885, loss: 0.30784177780151367\n",
      "########## Evaluation ##########\n",
      "Timestep: 64885 Average reward is -0.0585\n",
      "INFO - Step 65031, loss: 0.43238979578018196\n",
      "########## Evaluation ##########\n",
      "Timestep: 65031 Average reward is -0.0743\n",
      "INFO - Step 65187, loss: 0.52871149778366094\n",
      "########## Evaluation ##########\n",
      "Timestep: 65187 Average reward is -0.0517\n",
      "INFO - Step 65200, loss: 0.60495269298553473\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 65341, loss: 0.58081173896789555\n",
      "########## Evaluation ##########\n",
      "Timestep: 65341 Average reward is -0.0654\n",
      "INFO - Step 65483, loss: 0.52499711513519293\n",
      "########## Evaluation ##########\n",
      "Timestep: 65483 Average reward is -0.0822\n",
      "INFO - Step 65637, loss: 0.47436010837554933\n",
      "########## Evaluation ##########\n",
      "Timestep: 65637 Average reward is -0.0752\n",
      "INFO - Step 65798, loss: 0.54660093784332284\n",
      "########## Evaluation ##########\n",
      "Timestep: 65798 Average reward is -0.0646\n",
      "INFO - Step 65949, loss: 0.31455582380294837\n",
      "########## Evaluation ##########\n",
      "Timestep: 65949 Average reward is -0.0634\n",
      "INFO - Step 66104, loss: 0.33565199375152594\n",
      "########## Evaluation ##########\n",
      "Timestep: 66104 Average reward is -0.0697\n",
      "INFO - Step 66200, loss: 0.72877287864685067\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 66249, loss: 0.54443073272705083\n",
      "########## Evaluation ##########\n",
      "Timestep: 66249 Average reward is -0.0833\n",
      "INFO - Step 66291, loss: 0.34510111808776855"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 66406, loss: 0.62977164983749397\n",
      "########## Evaluation ##########\n",
      "Timestep: 66406 Average reward is -0.0708\n",
      "INFO - Step 66551, loss: 0.50515490770339976\n",
      "########## Evaluation ##########\n",
      "Timestep: 66551 Average reward is -0.0715\n",
      "INFO - Step 66690, loss: 0.40353655815124515\n",
      "########## Evaluation ##########\n",
      "Timestep: 66690 Average reward is -0.0793\n",
      "INFO - Step 66842, loss: 0.47500500082969666\n",
      "########## Evaluation ##########\n",
      "Timestep: 66842 Average reward is -0.0683\n",
      "INFO - Step 66997, loss: 0.41104179620742835\n",
      "########## Evaluation ##########\n",
      "Timestep: 66997 Average reward is -0.051\n",
      "INFO - Step 67155, loss: 0.56698167324066164\n",
      "########## Evaluation ##########\n",
      "Timestep: 67155 Average reward is -0.0591\n",
      "INFO - Step 67200, loss: 0.46541625261306765\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 67318, loss: 0.40734261274337775\n",
      "########## Evaluation ##########\n",
      "Timestep: 67318 Average reward is -0.0677\n",
      "INFO - Step 67468, loss: 0.45678368210792544\n",
      "########## Evaluation ##########\n",
      "Timestep: 67468 Average reward is -0.0591\n",
      "INFO - Step 67632, loss: 0.51804733276367193\n",
      "########## Evaluation ##########\n",
      "Timestep: 67632 Average reward is -0.0802\n",
      "INFO - Step 67777, loss: 0.32748001813888556\n",
      "########## Evaluation ##########\n",
      "Timestep: 67777 Average reward is -0.0637\n",
      "INFO - Step 67804, loss: 0.27494484186172485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 67927, loss: 0.64913702011108474\n",
      "########## Evaluation ##########\n",
      "Timestep: 67927 Average reward is -0.0686\n",
      "INFO - Step 68088, loss: 0.40895625948905945\n",
      "########## Evaluation ##########\n",
      "Timestep: 68088 Average reward is -0.064\n",
      "INFO - Step 68200, loss: 0.55513209104537966\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 68248, loss: 0.35845118761062626\n",
      "########## Evaluation ##########\n",
      "Timestep: 68248 Average reward is -0.0664\n",
      "INFO - Step 68405, loss: 0.43231099843978884\n",
      "########## Evaluation ##########\n",
      "Timestep: 68405 Average reward is -0.0798\n",
      "INFO - Step 68548, loss: 0.47371941804885864\n",
      "########## Evaluation ##########\n",
      "Timestep: 68548 Average reward is -0.0632\n",
      "INFO - Step 68704, loss: 0.46396651864051826\n",
      "########## Evaluation ##########\n",
      "Timestep: 68704 Average reward is -0.085\n",
      "INFO - Step 68867, loss: 0.45777744054794317\n",
      "########## Evaluation ##########\n",
      "Timestep: 68867 Average reward is -0.0508\n",
      "INFO - Step 69036, loss: 0.41163825988769535\n",
      "########## Evaluation ##########\n",
      "Timestep: 69036 Average reward is -0.07\n",
      "INFO - Step 69185, loss: 0.60630613565444956\n",
      "########## Evaluation ##########\n",
      "Timestep: 69185 Average reward is -0.0636\n",
      "INFO - Step 69200, loss: 0.43753752112388617\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 69344, loss: 0.49645891785621643\n",
      "########## Evaluation ##########\n",
      "Timestep: 69344 Average reward is -0.0816\n",
      "INFO - Step 69380, loss: 0.49342384934425354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 69491, loss: 0.53026843070983896\n",
      "########## Evaluation ##########\n",
      "Timestep: 69491 Average reward is -0.0773\n",
      "INFO - Step 69649, loss: 0.57983267307281496\n",
      "########## Evaluation ##########\n",
      "Timestep: 69649 Average reward is -0.0603\n",
      "INFO - Step 69807, loss: 0.52336061000823976\n",
      "########## Evaluation ##########\n",
      "Timestep: 69807 Average reward is -0.0609\n",
      "INFO - Step 69958, loss: 0.45117539167404175\n",
      "########## Evaluation ##########\n",
      "Timestep: 69958 Average reward is -0.0723\n",
      "INFO - Step 70117, loss: 0.60269856452941956\n",
      "########## Evaluation ##########\n",
      "Timestep: 70117 Average reward is -0.0486\n",
      "INFO - Step 70200, loss: 0.64851200580596926\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 70272, loss: 0.63841968774795536\n",
      "########## Evaluation ##########\n",
      "Timestep: 70272 Average reward is -0.0454\n",
      "INFO - Step 70420, loss: 0.52659690380096443\n",
      "########## Evaluation ##########\n",
      "Timestep: 70420 Average reward is -0.066\n",
      "INFO - Step 70587, loss: 0.55693542957305915\n",
      "########## Evaluation ##########\n",
      "Timestep: 70587 Average reward is -0.0653\n",
      "INFO - Step 70741, loss: 0.36475753784179694\n",
      "########## Evaluation ##########\n",
      "Timestep: 70741 Average reward is -0.0653\n",
      "INFO - Step 70896, loss: 0.36300468444824226\n",
      "########## Evaluation ##########\n",
      "Timestep: 70896 Average reward is -0.0624\n",
      "INFO - Step 70938, loss: 0.53439092636108456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 71045, loss: 0.54890668392181424\n",
      "########## Evaluation ##########\n",
      "Timestep: 71045 Average reward is -0.0781\n",
      "INFO - Step 71193, loss: 0.43616813421249397\n",
      "########## Evaluation ##########\n",
      "Timestep: 71193 Average reward is -0.0633\n",
      "INFO - Step 71200, loss: 0.53606724739074715\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 71352, loss: 0.44255805015563965\n",
      "########## Evaluation ##########\n",
      "Timestep: 71352 Average reward is -0.0643\n",
      "INFO - Step 71509, loss: 0.49652987718582153\n",
      "########## Evaluation ##########\n",
      "Timestep: 71509 Average reward is -0.0564\n",
      "INFO - Step 71666, loss: 0.48906353116035464\n",
      "########## Evaluation ##########\n",
      "Timestep: 71666 Average reward is -0.0625\n",
      "INFO - Step 71818, loss: 0.58443927764892583\n",
      "########## Evaluation ##########\n",
      "Timestep: 71818 Average reward is -0.0659\n",
      "INFO - Step 71975, loss: 0.42648535966873177\n",
      "########## Evaluation ##########\n",
      "Timestep: 71975 Average reward is -0.0644\n",
      "INFO - Step 72127, loss: 0.46798053383827215\n",
      "########## Evaluation ##########\n",
      "Timestep: 72127 Average reward is -0.0632\n",
      "INFO - Step 72200, loss: 0.67317414283752446\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 72283, loss: 0.43915456533432007\n",
      "########## Evaluation ##########\n",
      "Timestep: 72283 Average reward is -0.0756\n",
      "INFO - Step 72433, loss: 0.42065301537513733\n",
      "########## Evaluation ##########\n",
      "Timestep: 72433 Average reward is -0.0675\n",
      "INFO - Step 72474, loss: 0.41840052604675293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 72589, loss: 0.58621323108673134\n",
      "########## Evaluation ##########\n",
      "Timestep: 72589 Average reward is -0.0617\n",
      "INFO - Step 72738, loss: 0.58287680149078376\n",
      "########## Evaluation ##########\n",
      "Timestep: 72738 Average reward is -0.0696\n",
      "INFO - Step 72902, loss: 0.45365327596664434\n",
      "########## Evaluation ##########\n",
      "Timestep: 72902 Average reward is -0.063\n",
      "INFO - Step 73040, loss: 0.55458271503448493\n",
      "########## Evaluation ##########\n",
      "Timestep: 73040 Average reward is -0.0676\n",
      "INFO - Step 73200, loss: 0.55158638954162616\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 73206, loss: 0.40522861480712895\n",
      "########## Evaluation ##########\n",
      "Timestep: 73206 Average reward is -0.0819\n",
      "INFO - Step 73359, loss: 0.63661950826644955\n",
      "########## Evaluation ##########\n",
      "Timestep: 73359 Average reward is -0.0626\n",
      "INFO - Step 73501, loss: 0.51846098899841315\n",
      "########## Evaluation ##########\n",
      "Timestep: 73501 Average reward is -0.0631\n",
      "INFO - Step 73656, loss: 0.50694036483764653\n",
      "########## Evaluation ##########\n",
      "Timestep: 73656 Average reward is -0.054\n",
      "INFO - Step 73799, loss: 0.56857228279113774\n",
      "########## Evaluation ##########\n",
      "Timestep: 73799 Average reward is -0.069\n",
      "INFO - Step 73960, loss: 0.48133951425552375\n",
      "########## Evaluation ##########\n",
      "Timestep: 73960 Average reward is -0.0658\n",
      "INFO - Step 73996, loss: 0.36919027566909795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 74119, loss: 0.50637137889862064\n",
      "########## Evaluation ##########\n",
      "Timestep: 74119 Average reward is -0.0604\n",
      "INFO - Step 74200, loss: 0.39041590690612793\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 74257, loss: 0.41646993160247845\n",
      "########## Evaluation ##########\n",
      "Timestep: 74257 Average reward is -0.0621\n",
      "INFO - Step 74419, loss: 0.35439485311508186\n",
      "########## Evaluation ##########\n",
      "Timestep: 74419 Average reward is -0.061\n",
      "INFO - Step 74580, loss: 0.56191104650497445\n",
      "########## Evaluation ##########\n",
      "Timestep: 74580 Average reward is -0.0575\n",
      "INFO - Step 74725, loss: 0.57701694965362557\n",
      "########## Evaluation ##########\n",
      "Timestep: 74725 Average reward is -0.063\n",
      "INFO - Step 74873, loss: 0.52950263023376465\n",
      "########## Evaluation ##########\n",
      "Timestep: 74873 Average reward is -0.0665\n",
      "INFO - Step 75020, loss: 0.55392187833786015\n",
      "########## Evaluation ##########\n",
      "Timestep: 75020 Average reward is -0.0601\n",
      "INFO - Step 75181, loss: 0.49302610754966736\n",
      "########## Evaluation ##########\n",
      "Timestep: 75181 Average reward is -0.0648\n",
      "INFO - Step 75200, loss: 0.30489549040794375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 75332, loss: 0.69192802906036383\n",
      "########## Evaluation ##########\n",
      "Timestep: 75332 Average reward is -0.0626\n",
      "INFO - Step 75484, loss: 0.41837802529335024\n",
      "########## Evaluation ##########\n",
      "Timestep: 75484 Average reward is -0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 75641, loss: 0.69654941558837893\n",
      "########## Evaluation ##########\n",
      "Timestep: 75641 Average reward is -0.0653\n",
      "INFO - Step 75801, loss: 0.58188569545745856\n",
      "########## Evaluation ##########\n",
      "Timestep: 75801 Average reward is -0.0577\n",
      "INFO - Step 75949, loss: 0.47878539562225346\n",
      "########## Evaluation ##########\n",
      "Timestep: 75949 Average reward is -0.0683\n",
      "INFO - Step 76114, loss: 0.47921508550643927\n",
      "########## Evaluation ##########\n",
      "Timestep: 76114 Average reward is -0.0785\n",
      "INFO - Step 76200, loss: 0.48422998189926157\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 76264, loss: 0.51012593507766725\n",
      "########## Evaluation ##########\n",
      "Timestep: 76264 Average reward is -0.0616\n",
      "INFO - Step 76409, loss: 0.49580091238021856\n",
      "########## Evaluation ##########\n",
      "Timestep: 76409 Average reward is -0.0531\n",
      "INFO - Step 76560, loss: 0.28515833616256714\n",
      "########## Evaluation ##########\n",
      "Timestep: 76560 Average reward is -0.0635\n",
      "INFO - Step 76725, loss: 0.53621709346771244\n",
      "########## Evaluation ##########\n",
      "Timestep: 76725 Average reward is -0.0502\n",
      "INFO - Step 76880, loss: 0.38838496804237366\n",
      "########## Evaluation ##########\n",
      "Timestep: 76880 Average reward is -0.0693\n",
      "INFO - Step 77034, loss: 0.43155488371849066\n",
      "########## Evaluation ##########\n",
      "Timestep: 77034 Average reward is -0.0692\n",
      "INFO - Step 77074, loss: 0.49325048923492436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 77193, loss: 0.43464851379394534\n",
      "########## Evaluation ##########\n",
      "Timestep: 77193 Average reward is -0.0652\n",
      "INFO - Step 77200, loss: 0.55804193019866946\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 77340, loss: 0.57760548591613774\n",
      "########## Evaluation ##########\n",
      "Timestep: 77340 Average reward is -0.072\n",
      "INFO - Step 77491, loss: 0.49040150642395026\n",
      "########## Evaluation ##########\n",
      "Timestep: 77491 Average reward is -0.054\n",
      "INFO - Step 77642, loss: 0.69123804569244385\n",
      "########## Evaluation ##########\n",
      "Timestep: 77642 Average reward is -0.0802\n",
      "INFO - Step 77784, loss: 0.33961454033851624\n",
      "########## Evaluation ##########\n",
      "Timestep: 77784 Average reward is -0.0654\n",
      "INFO - Step 77941, loss: 0.42905211448669434\n",
      "########## Evaluation ##########\n",
      "Timestep: 77941 Average reward is -0.0619\n",
      "INFO - Step 78091, loss: 0.53051519393920937\n",
      "########## Evaluation ##########\n",
      "Timestep: 78091 Average reward is -0.0532\n",
      "INFO - Step 78200, loss: 0.48724848031997684\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 78245, loss: 0.44656264781951904\n",
      "########## Evaluation ##########\n",
      "Timestep: 78245 Average reward is -0.062\n",
      "INFO - Step 78396, loss: 0.55568826198577886\n",
      "########## Evaluation ##########\n",
      "Timestep: 78396 Average reward is -0.0691\n",
      "INFO - Step 78536, loss: 0.59818339347839366\n",
      "########## Evaluation ##########\n",
      "Timestep: 78536 Average reward is -0.067\n",
      "INFO - Step 78576, loss: 0.39939847588539124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 78683, loss: 0.71927702426910476\n",
      "########## Evaluation ##########\n",
      "Timestep: 78683 Average reward is -0.0643\n",
      "INFO - Step 78834, loss: 0.58005046844482427\n",
      "########## Evaluation ##########\n",
      "Timestep: 78834 Average reward is -0.0614\n",
      "INFO - Step 78980, loss: 0.58266580104827884\n",
      "########## Evaluation ##########\n",
      "Timestep: 78980 Average reward is -0.0662\n",
      "INFO - Step 79132, loss: 0.49236622452735934\n",
      "########## Evaluation ##########\n",
      "Timestep: 79132 Average reward is -0.0511\n",
      "INFO - Step 79200, loss: 0.56763291358947757\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 79285, loss: 0.43288943171501165\n",
      "########## Evaluation ##########\n",
      "Timestep: 79285 Average reward is -0.0767\n",
      "INFO - Step 79438, loss: 0.51267898082733155\n",
      "########## Evaluation ##########\n",
      "Timestep: 79438 Average reward is -0.0664\n",
      "INFO - Step 79605, loss: 0.26425683498382576\n",
      "########## Evaluation ##########\n",
      "Timestep: 79605 Average reward is -0.0564\n",
      "INFO - Step 79767, loss: 0.40540564060211183\n",
      "########## Evaluation ##########\n",
      "Timestep: 79767 Average reward is -0.0541\n",
      "INFO - Step 79914, loss: 0.34559792280197144\n",
      "########## Evaluation ##########\n",
      "Timestep: 79914 Average reward is -0.0732\n",
      "INFO - Step 80053, loss: 0.59367167949676513\n",
      "########## Evaluation ##########\n",
      "Timestep: 80053 Average reward is -0.068\n",
      "INFO - Step 80091, loss: 0.48252114653587343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 80200, loss: 0.39794278144836426\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 80221, loss: 0.41682136058807373\n",
      "########## Evaluation ##########\n",
      "Timestep: 80221 Average reward is -0.0395\n",
      "INFO - Step 80371, loss: 0.33524119853973394\n",
      "########## Evaluation ##########\n",
      "Timestep: 80371 Average reward is -0.0668\n",
      "INFO - Step 80515, loss: 0.50624406337738043\n",
      "########## Evaluation ##########\n",
      "Timestep: 80515 Average reward is -0.0555\n",
      "INFO - Step 80670, loss: 0.54013496637344366\n",
      "########## Evaluation ##########\n",
      "Timestep: 80670 Average reward is -0.0628\n",
      "INFO - Step 80827, loss: 0.66880929470062267\n",
      "########## Evaluation ##########\n",
      "Timestep: 80827 Average reward is -0.0708\n",
      "INFO - Step 80981, loss: 0.28581961989402776\n",
      "########## Evaluation ##########\n",
      "Timestep: 80981 Average reward is -0.0555\n",
      "INFO - Step 81121, loss: 0.46450299024581913\n",
      "########## Evaluation ##########\n",
      "Timestep: 81121 Average reward is -0.0535\n",
      "INFO - Step 81200, loss: 0.50226926803588873\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 81273, loss: 0.61462712287902836\n",
      "########## Evaluation ##########\n",
      "Timestep: 81273 Average reward is -0.053\n",
      "INFO - Step 81428, loss: 0.50222182273864756\n",
      "########## Evaluation ##########\n",
      "Timestep: 81428 Average reward is -0.0512\n",
      "INFO - Step 81569, loss: 0.40703073143959045\n",
      "########## Evaluation ##########\n",
      "Timestep: 81569 Average reward is -0.0692\n",
      "INFO - Step 81613, loss: 0.53543061017990115"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 81705, loss: 0.48607933521270756\n",
      "########## Evaluation ##########\n",
      "Timestep: 81705 Average reward is -0.0794\n",
      "INFO - Step 81859, loss: 0.56200039386749274\n",
      "########## Evaluation ##########\n",
      "Timestep: 81859 Average reward is -0.0604\n",
      "INFO - Step 82011, loss: 0.39098989963531494\n",
      "########## Evaluation ##########\n",
      "Timestep: 82011 Average reward is -0.0605\n",
      "INFO - Step 82156, loss: 0.52569282054901124\n",
      "########## Evaluation ##########\n",
      "Timestep: 82156 Average reward is -0.0651\n",
      "INFO - Step 82200, loss: 0.43222352862358093\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 82333, loss: 0.42065834999084474\n",
      "########## Evaluation ##########\n",
      "Timestep: 82333 Average reward is -0.0746\n",
      "INFO - Step 82474, loss: 0.30332586169242863\n",
      "########## Evaluation ##########\n",
      "Timestep: 82474 Average reward is -0.0606\n",
      "INFO - Step 82628, loss: 0.37467432022094727\n",
      "########## Evaluation ##########\n",
      "Timestep: 82628 Average reward is -0.0605\n",
      "INFO - Step 82779, loss: 0.58087992668151866\n",
      "########## Evaluation ##########\n",
      "Timestep: 82779 Average reward is -0.0684\n",
      "INFO - Step 82930, loss: 0.37240517139434814\n",
      "########## Evaluation ##########\n",
      "Timestep: 82930 Average reward is -0.0558\n",
      "INFO - Step 83080, loss: 0.45981144905090336\n",
      "########## Evaluation ##########\n",
      "Timestep: 83080 Average reward is -0.0823\n",
      "INFO - Step 83116, loss: 0.38960024714469917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 83200, loss: 0.51887458562850955\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 83226, loss: 0.51239293813705443\n",
      "########## Evaluation ##########\n",
      "Timestep: 83226 Average reward is -0.0685\n",
      "INFO - Step 83387, loss: 0.44383835792541504\n",
      "########## Evaluation ##########\n",
      "Timestep: 83387 Average reward is -0.0661\n",
      "INFO - Step 83550, loss: 0.41342419385910034\n",
      "########## Evaluation ##########\n",
      "Timestep: 83550 Average reward is -0.0632\n",
      "INFO - Step 83715, loss: 0.32969671487808236\n",
      "########## Evaluation ##########\n",
      "Timestep: 83715 Average reward is -0.0551\n",
      "INFO - Step 83870, loss: 0.54911303520202645\n",
      "########## Evaluation ##########\n",
      "Timestep: 83870 Average reward is -0.06\n",
      "INFO - Step 84022, loss: 0.59840381145477373\n",
      "########## Evaluation ##########\n",
      "Timestep: 84022 Average reward is -0.0655\n",
      "INFO - Step 84166, loss: 0.39526742696762085\n",
      "########## Evaluation ##########\n",
      "Timestep: 84166 Average reward is -0.0605\n",
      "INFO - Step 84200, loss: 0.49681580066680917\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 84308, loss: 0.57674586772918794\n",
      "########## Evaluation ##########\n",
      "Timestep: 84308 Average reward is -0.0545\n",
      "INFO - Step 84457, loss: 0.66171741485595786\n",
      "########## Evaluation ##########\n",
      "Timestep: 84457 Average reward is -0.0665\n",
      "INFO - Step 84612, loss: 0.49217629432678226\n",
      "########## Evaluation ##########\n",
      "Timestep: 84612 Average reward is -0.0646\n",
      "INFO - Step 84649, loss: 0.43307319283485417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 84770, loss: 0.55067074298858644\n",
      "########## Evaluation ##########\n",
      "Timestep: 84770 Average reward is -0.0648\n",
      "INFO - Step 84929, loss: 0.28390440344810486\n",
      "########## Evaluation ##########\n",
      "Timestep: 84929 Average reward is -0.0733\n",
      "INFO - Step 85085, loss: 0.34538221359252935\n",
      "########## Evaluation ##########\n",
      "Timestep: 85085 Average reward is -0.0645\n",
      "INFO - Step 85200, loss: 0.49645400047302246\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 85246, loss: 0.49633875489234924\n",
      "########## Evaluation ##########\n",
      "Timestep: 85246 Average reward is -0.057\n",
      "INFO - Step 85407, loss: 0.52779984474182135\n",
      "########## Evaluation ##########\n",
      "Timestep: 85407 Average reward is -0.0593\n",
      "INFO - Step 85565, loss: 0.39939704537391663\n",
      "########## Evaluation ##########\n",
      "Timestep: 85565 Average reward is -0.0631\n",
      "INFO - Step 85716, loss: 0.53914821147918726\n",
      "########## Evaluation ##########\n",
      "Timestep: 85716 Average reward is -0.0709\n",
      "INFO - Step 85868, loss: 0.51809674501419077\n",
      "########## Evaluation ##########\n",
      "Timestep: 85868 Average reward is -0.05\n",
      "INFO - Step 86010, loss: 0.80732351541519177\n",
      "########## Evaluation ##########\n",
      "Timestep: 86010 Average reward is -0.0674\n",
      "INFO - Step 86162, loss: 0.41557610034942627\n",
      "########## Evaluation ##########\n",
      "Timestep: 86162 Average reward is -0.0606\n",
      "INFO - Step 86193, loss: 0.44726011157035833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 86200, loss: 0.59056913852691657\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 86308, loss: 0.62272703647613533\n",
      "########## Evaluation ##########\n",
      "Timestep: 86308 Average reward is -0.0729\n",
      "INFO - Step 86454, loss: 0.48763698339462287\n",
      "########## Evaluation ##########\n",
      "Timestep: 86454 Average reward is -0.0484\n",
      "INFO - Step 86611, loss: 0.34255349636077886\n",
      "########## Evaluation ##########\n",
      "Timestep: 86611 Average reward is -0.069\n",
      "INFO - Step 86762, loss: 0.42316347360610966\n",
      "########## Evaluation ##########\n",
      "Timestep: 86762 Average reward is -0.0657\n",
      "INFO - Step 86917, loss: 0.50572657585144043\n",
      "########## Evaluation ##########\n",
      "Timestep: 86917 Average reward is -0.0575\n",
      "INFO - Step 87085, loss: 0.51798546314239595\n",
      "########## Evaluation ##########\n",
      "Timestep: 87085 Average reward is -0.0733\n",
      "INFO - Step 87200, loss: 0.48549062013626157\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 87231, loss: 0.43946015834808354\n",
      "########## Evaluation ##########\n",
      "Timestep: 87231 Average reward is -0.0667\n",
      "INFO - Step 87383, loss: 0.46368655562400824\n",
      "########## Evaluation ##########\n",
      "Timestep: 87383 Average reward is -0.0698\n",
      "INFO - Step 87521, loss: 0.52636033296585084\n",
      "########## Evaluation ##########\n",
      "Timestep: 87521 Average reward is -0.0553\n",
      "INFO - Step 87680, loss: 0.65852946043014536\n",
      "########## Evaluation ##########\n",
      "Timestep: 87680 Average reward is -0.0635\n",
      "INFO - Step 87727, loss: 0.40248006582260135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 87831, loss: 0.31310042738914497\n",
      "########## Evaluation ##########\n",
      "Timestep: 87831 Average reward is -0.0682\n",
      "INFO - Step 87982, loss: 0.38433846831321716\n",
      "########## Evaluation ##########\n",
      "Timestep: 87982 Average reward is -0.0755\n",
      "INFO - Step 88132, loss: 0.42378208041191134\n",
      "########## Evaluation ##########\n",
      "Timestep: 88132 Average reward is -0.0525\n",
      "INFO - Step 88200, loss: 0.50453436374664316\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 88292, loss: 0.57295560836791997\n",
      "########## Evaluation ##########\n",
      "Timestep: 88292 Average reward is -0.063\n",
      "INFO - Step 88437, loss: 0.40682575106620793\n",
      "########## Evaluation ##########\n",
      "Timestep: 88437 Average reward is -0.0523\n",
      "INFO - Step 88589, loss: 0.37865206599235535\n",
      "########## Evaluation ##########\n",
      "Timestep: 88589 Average reward is -0.0633\n",
      "INFO - Step 88739, loss: 0.74836087226867686\n",
      "########## Evaluation ##########\n",
      "Timestep: 88739 Average reward is -0.0542\n",
      "INFO - Step 88886, loss: 0.38599017262458876\n",
      "########## Evaluation ##########\n",
      "Timestep: 88886 Average reward is -0.0616\n",
      "INFO - Step 89042, loss: 0.56863993406295785\n",
      "########## Evaluation ##########\n",
      "Timestep: 89042 Average reward is -0.0595\n",
      "INFO - Step 89200, loss: 0.45206570625305176\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 89203, loss: 0.32438188791275024\n",
      "########## Evaluation ##########\n",
      "Timestep: 89203 Average reward is -0.0589\n",
      "INFO - Step 89243, loss: 0.32567748427391056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 89359, loss: 0.53978639841079716\n",
      "########## Evaluation ##########\n",
      "Timestep: 89359 Average reward is -0.0697\n",
      "INFO - Step 89508, loss: 0.55918371677398687\n",
      "########## Evaluation ##########\n",
      "Timestep: 89508 Average reward is -0.068\n",
      "INFO - Step 89669, loss: 0.55986434221267736\n",
      "########## Evaluation ##########\n",
      "Timestep: 89669 Average reward is -0.0612\n",
      "INFO - Step 89827, loss: 0.41316789388656616\n",
      "########## Evaluation ##########\n",
      "Timestep: 89827 Average reward is -0.0708\n",
      "INFO - Step 89983, loss: 0.48120242357254037\n",
      "########## Evaluation ##########\n",
      "Timestep: 89983 Average reward is -0.0544\n",
      "INFO - Step 90124, loss: 0.42863786220550537\n",
      "########## Evaluation ##########\n",
      "Timestep: 90124 Average reward is -0.0719\n",
      "INFO - Step 90200, loss: 0.39806210994720463\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 90269, loss: 0.39977893233299255\n",
      "########## Evaluation ##########\n",
      "Timestep: 90269 Average reward is -0.0544\n",
      "INFO - Step 90415, loss: 0.56101977825164854\n",
      "########## Evaluation ##########\n",
      "Timestep: 90415 Average reward is -0.0675\n",
      "INFO - Step 90571, loss: 0.45287463068962097\n",
      "########## Evaluation ##########\n",
      "Timestep: 90571 Average reward is -0.0648\n",
      "INFO - Step 90724, loss: 0.61052703857421884\n",
      "########## Evaluation ##########\n",
      "Timestep: 90724 Average reward is -0.0543\n",
      "INFO - Step 90766, loss: 0.48781004548072815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 90864, loss: 0.41780167818069465\n",
      "########## Evaluation ##########\n",
      "Timestep: 90864 Average reward is -0.0445\n",
      "INFO - Step 91007, loss: 0.52893304824829163\n",
      "########## Evaluation ##########\n",
      "Timestep: 91007 Average reward is -0.0712\n",
      "INFO - Step 91147, loss: 0.29306530952453613\n",
      "########## Evaluation ##########\n",
      "Timestep: 91147 Average reward is -0.0592\n",
      "INFO - Step 91200, loss: 0.49501892924308777\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 91296, loss: 0.44720214605331427\n",
      "########## Evaluation ##########\n",
      "Timestep: 91296 Average reward is -0.0536\n",
      "INFO - Step 91438, loss: 0.44284182786941536\n",
      "########## Evaluation ##########\n",
      "Timestep: 91438 Average reward is -0.0658\n",
      "INFO - Step 91584, loss: 0.41030311584472656\n",
      "########## Evaluation ##########\n",
      "Timestep: 91584 Average reward is -0.0551\n",
      "INFO - Step 91738, loss: 0.59477245807647723\n",
      "########## Evaluation ##########\n",
      "Timestep: 91738 Average reward is -0.0479\n",
      "INFO - Step 91892, loss: 0.38130551576614383\n",
      "########## Evaluation ##########\n",
      "Timestep: 91892 Average reward is -0.0732\n",
      "INFO - Step 92052, loss: 0.40507394075393677\n",
      "########## Evaluation ##########\n",
      "Timestep: 92052 Average reward is -0.0757\n",
      "INFO - Step 92200, loss: 0.28605765104293823\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 92208, loss: 0.65450805425643924\n",
      "########## Evaluation ##########\n",
      "Timestep: 92208 Average reward is -0.0754\n",
      "INFO - Step 92254, loss: 0.45639368891716003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 92361, loss: 0.49807739257812525\n",
      "########## Evaluation ##########\n",
      "Timestep: 92361 Average reward is -0.0732\n",
      "INFO - Step 92517, loss: 0.55878168344497685\n",
      "########## Evaluation ##########\n",
      "Timestep: 92517 Average reward is -0.0641\n",
      "INFO - Step 92672, loss: 0.71982353925704965\n",
      "########## Evaluation ##########\n",
      "Timestep: 92672 Average reward is -0.0865\n",
      "INFO - Step 92826, loss: 0.63611471652984624\n",
      "########## Evaluation ##########\n",
      "Timestep: 92826 Average reward is -0.0594\n",
      "INFO - Step 92969, loss: 0.55108910799026496\n",
      "########## Evaluation ##########\n",
      "Timestep: 92969 Average reward is -0.0713\n",
      "INFO - Step 93130, loss: 0.69838333129882815\n",
      "########## Evaluation ##########\n",
      "Timestep: 93130 Average reward is -0.0764\n",
      "INFO - Step 93200, loss: 0.53027266263961796\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 93286, loss: 0.48835915327072144\n",
      "########## Evaluation ##########\n",
      "Timestep: 93286 Average reward is -0.071\n",
      "INFO - Step 93444, loss: 0.43024227023124695\n",
      "########## Evaluation ##########\n",
      "Timestep: 93444 Average reward is -0.0637\n",
      "INFO - Step 93614, loss: 0.42677763104438787\n",
      "########## Evaluation ##########\n",
      "Timestep: 93614 Average reward is -0.0663\n",
      "INFO - Step 93773, loss: 0.52258443832397463\n",
      "########## Evaluation ##########\n",
      "Timestep: 93773 Average reward is -0.064\n",
      "INFO - Step 93817, loss: 0.64040422439575236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 93912, loss: 0.36953112483024597\n",
      "########## Evaluation ##########\n",
      "Timestep: 93912 Average reward is -0.0715\n",
      "INFO - Step 94069, loss: 0.49530112743377686\n",
      "########## Evaluation ##########\n",
      "Timestep: 94069 Average reward is -0.0749\n",
      "INFO - Step 94200, loss: 0.43220525979995736\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 94220, loss: 0.63826262950897225\n",
      "########## Evaluation ##########\n",
      "Timestep: 94220 Average reward is -0.0786\n",
      "INFO - Step 94375, loss: 0.48552858829498297\n",
      "########## Evaluation ##########\n",
      "Timestep: 94375 Average reward is -0.0659\n",
      "INFO - Step 94529, loss: 0.45444628596305847\n",
      "########## Evaluation ##########\n",
      "Timestep: 94529 Average reward is -0.0793\n",
      "INFO - Step 94678, loss: 0.43033501505851746\n",
      "########## Evaluation ##########\n",
      "Timestep: 94678 Average reward is -0.0621\n",
      "INFO - Step 94832, loss: 0.39325350522994995\n",
      "########## Evaluation ##########\n",
      "Timestep: 94832 Average reward is -0.0724\n",
      "INFO - Step 94982, loss: 0.37634688615798955\n",
      "########## Evaluation ##########\n",
      "Timestep: 94982 Average reward is -0.0655\n",
      "INFO - Step 95131, loss: 0.37801119685173035\n",
      "########## Evaluation ##########\n",
      "Timestep: 95131 Average reward is -0.0658\n",
      "INFO - Step 95200, loss: 0.54260718822479257\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 95285, loss: 0.54542684555053714\n",
      "########## Evaluation ##########\n",
      "Timestep: 95285 Average reward is -0.0586\n",
      "INFO - Step 95324, loss: 0.46284765005111694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 95442, loss: 0.42690998315811163\n",
      "########## Evaluation ##########\n",
      "Timestep: 95442 Average reward is -0.0653\n",
      "INFO - Step 95594, loss: 0.43023529648780825\n",
      "########## Evaluation ##########\n",
      "Timestep: 95594 Average reward is -0.0503\n",
      "INFO - Step 95751, loss: 0.42527011036872864\n",
      "########## Evaluation ##########\n",
      "Timestep: 95751 Average reward is -0.0725\n",
      "INFO - Step 95908, loss: 0.52351570129394537\n",
      "########## Evaluation ##########\n",
      "Timestep: 95908 Average reward is -0.0581\n",
      "INFO - Step 96067, loss: 0.59701281785964973\n",
      "########## Evaluation ##########\n",
      "Timestep: 96067 Average reward is -0.0792\n",
      "INFO - Step 96200, loss: 0.44005766510963444\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 96208, loss: 0.35331162810325624\n",
      "########## Evaluation ##########\n",
      "Timestep: 96208 Average reward is -0.0532\n",
      "INFO - Step 96343, loss: 0.27983814477920537\n",
      "########## Evaluation ##########\n",
      "Timestep: 96343 Average reward is -0.0599\n",
      "INFO - Step 96494, loss: 0.61692047119140625\n",
      "########## Evaluation ##########\n",
      "Timestep: 96494 Average reward is -0.0764\n",
      "INFO - Step 96642, loss: 0.34267053008079535\n",
      "########## Evaluation ##########\n",
      "Timestep: 96642 Average reward is -0.0735\n",
      "INFO - Step 96793, loss: 0.50182479619979864\n",
      "########## Evaluation ##########\n",
      "Timestep: 96793 Average reward is -0.0739\n",
      "INFO - Step 96835, loss: 0.49601262807846077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 96942, loss: 0.49266147613525397\n",
      "########## Evaluation ##########\n",
      "Timestep: 96942 Average reward is -0.0627\n",
      "INFO - Step 97105, loss: 0.49486690759658813\n",
      "########## Evaluation ##########\n",
      "Timestep: 97105 Average reward is -0.0568\n",
      "INFO - Step 97200, loss: 0.71657067537307743\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 97241, loss: 0.37820780277252296\n",
      "########## Evaluation ##########\n",
      "Timestep: 97241 Average reward is -0.0672\n",
      "INFO - Step 97389, loss: 0.61773484945297245\n",
      "########## Evaluation ##########\n",
      "Timestep: 97389 Average reward is -0.0591\n",
      "INFO - Step 97531, loss: 0.45162174105644226\n",
      "########## Evaluation ##########\n",
      "Timestep: 97531 Average reward is -0.0588\n",
      "INFO - Step 97682, loss: 0.42552331089973454\n",
      "########## Evaluation ##########\n",
      "Timestep: 97682 Average reward is -0.0787\n",
      "INFO - Step 97845, loss: 0.47078275680541996\n",
      "########## Evaluation ##########\n",
      "Timestep: 97845 Average reward is -0.0704\n",
      "INFO - Step 98000, loss: 0.44425547122955326\n",
      "########## Evaluation ##########\n",
      "Timestep: 98000 Average reward is -0.0743\n",
      "INFO - Step 98146, loss: 0.47941324114799534\n",
      "########## Evaluation ##########\n",
      "Timestep: 98146 Average reward is -0.0812\n",
      "INFO - Step 98200, loss: 0.55996191501617437\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 98297, loss: 0.54097497463226325\n",
      "########## Evaluation ##########\n",
      "Timestep: 98297 Average reward is -0.073\n",
      "INFO - Step 98335, loss: 0.46452111005783085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 98447, loss: 0.50544238090515145\n",
      "########## Evaluation ##########\n",
      "Timestep: 98447 Average reward is -0.0617\n",
      "INFO - Step 98597, loss: 0.71602845191955576\n",
      "########## Evaluation ##########\n",
      "Timestep: 98597 Average reward is -0.0632\n",
      "INFO - Step 98737, loss: 0.65194821357727057\n",
      "########## Evaluation ##########\n",
      "Timestep: 98737 Average reward is -0.0876\n",
      "INFO - Step 98888, loss: 0.47258692979812625\n",
      "########## Evaluation ##########\n",
      "Timestep: 98888 Average reward is -0.0654\n",
      "INFO - Step 99047, loss: 0.61627292633056644\n",
      "########## Evaluation ##########\n",
      "Timestep: 99047 Average reward is -0.0556\n",
      "INFO - Step 99195, loss: 0.67595940828323365\n",
      "########## Evaluation ##########\n",
      "Timestep: 99195 Average reward is -0.0614\n",
      "INFO - Step 99200, loss: 0.41375872492790225\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 99348, loss: 0.44663399457931526\n",
      "########## Evaluation ##########\n",
      "Timestep: 99348 Average reward is -0.075\n",
      "INFO - Step 99502, loss: 0.57343888282775884\n",
      "########## Evaluation ##########\n",
      "Timestep: 99502 Average reward is -0.0537\n",
      "INFO - Step 99663, loss: 0.52326130867004497\n",
      "########## Evaluation ##########\n",
      "Timestep: 99663 Average reward is -0.0487\n",
      "INFO - Step 99830, loss: 0.61195200681686413\n",
      "########## Evaluation ##########\n",
      "Timestep: 99830 Average reward is -0.0694\n",
      "INFO - Step 99873, loss: 0.40833267569541936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 99981, loss: 0.62409949302673343\n",
      "########## Evaluation ##########\n",
      "Timestep: 99981 Average reward is -0.059\n",
      "INFO - Step 100128, loss: 0.67097961902618414\n",
      "########## Evaluation ##########\n",
      "Timestep: 100128 Average reward is -0.0674\n",
      "INFO - Step 100200, loss: 0.49552902579307556\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 100290, loss: 0.48025894165039064\n",
      "########## Evaluation ##########\n",
      "Timestep: 100290 Average reward is -0.0569\n",
      "INFO - Step 100447, loss: 0.56907486915588383\n",
      "########## Evaluation ##########\n",
      "Timestep: 100447 Average reward is -0.055\n",
      "INFO - Step 100595, loss: 0.37417906522750854\n",
      "########## Evaluation ##########\n",
      "Timestep: 100595 Average reward is -0.0763\n",
      "INFO - Step 100736, loss: 0.54786968231201173\n",
      "########## Evaluation ##########\n",
      "Timestep: 100736 Average reward is -0.0626\n",
      "INFO - Step 100881, loss: 0.50215309858322144\n",
      "########## Evaluation ##########\n",
      "Timestep: 100881 Average reward is -0.0776\n",
      "INFO - Step 101036, loss: 0.42896711826324463\n",
      "########## Evaluation ##########\n",
      "Timestep: 101036 Average reward is -0.0658\n",
      "INFO - Step 101193, loss: 0.65070432424545295\n",
      "########## Evaluation ##########\n",
      "Timestep: 101193 Average reward is -0.0867\n",
      "INFO - Step 101200, loss: 0.62758111953735355\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 101347, loss: 0.53096294403076175\n",
      "########## Evaluation ##########\n",
      "Timestep: 101347 Average reward is -0.0657\n",
      "INFO - Step 101386, loss: 0.41625422239303597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 101506, loss: 0.46422761678695685\n",
      "########## Evaluation ##########\n",
      "Timestep: 101506 Average reward is -0.0573\n",
      "INFO - Step 101654, loss: 0.56588143110275276\n",
      "########## Evaluation ##########\n",
      "Timestep: 101654 Average reward is -0.0587\n",
      "INFO - Step 101819, loss: 0.58403384685516365\n",
      "########## Evaluation ##########\n",
      "Timestep: 101819 Average reward is -0.0511\n",
      "INFO - Step 101969, loss: 0.43220713734626776\n",
      "########## Evaluation ##########\n",
      "Timestep: 101969 Average reward is -0.065\n",
      "INFO - Step 102118, loss: 0.35144466161727905\n",
      "########## Evaluation ##########\n",
      "Timestep: 102118 Average reward is -0.0773\n",
      "INFO - Step 102200, loss: 0.53107476234436044\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 102276, loss: 0.46764886379241943\n",
      "########## Evaluation ##########\n",
      "Timestep: 102276 Average reward is -0.0535\n",
      "INFO - Step 102430, loss: 0.58862870931625373\n",
      "########## Evaluation ##########\n",
      "Timestep: 102430 Average reward is -0.0493\n",
      "INFO - Step 102582, loss: 0.48066776990890503\n",
      "########## Evaluation ##########\n",
      "Timestep: 102582 Average reward is -0.0566\n",
      "INFO - Step 102728, loss: 0.48916825652122596\n",
      "########## Evaluation ##########\n",
      "Timestep: 102728 Average reward is -0.0567\n",
      "INFO - Step 102875, loss: 0.48044958710670473\n",
      "########## Evaluation ##########\n",
      "Timestep: 102875 Average reward is -0.067\n",
      "INFO - Step 102915, loss: 0.55015170574188234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 103021, loss: 0.70034885406494147\n",
      "########## Evaluation ##########\n",
      "Timestep: 103021 Average reward is -0.0711\n",
      "INFO - Step 103178, loss: 0.50178349018096925\n",
      "########## Evaluation ##########\n",
      "Timestep: 103178 Average reward is -0.0582\n",
      "INFO - Step 103200, loss: 0.61462664604187017\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 103332, loss: 0.68516898155212456\n",
      "########## Evaluation ##########\n",
      "Timestep: 103332 Average reward is -0.0617\n",
      "INFO - Step 103472, loss: 0.51884555816650396\n",
      "########## Evaluation ##########\n",
      "Timestep: 103472 Average reward is -0.0672\n",
      "INFO - Step 103617, loss: 0.38815921545028687\n",
      "########## Evaluation ##########\n",
      "Timestep: 103617 Average reward is -0.054\n",
      "INFO - Step 103770, loss: 0.59827518463134773\n",
      "########## Evaluation ##########\n",
      "Timestep: 103770 Average reward is -0.0664\n",
      "INFO - Step 103909, loss: 0.33277896046638494\n",
      "########## Evaluation ##########\n",
      "Timestep: 103909 Average reward is -0.0534\n",
      "INFO - Step 104047, loss: 0.47663056850433356\n",
      "########## Evaluation ##########\n",
      "Timestep: 104047 Average reward is -0.0716\n",
      "INFO - Step 104192, loss: 0.32793480157852173\n",
      "########## Evaluation ##########\n",
      "Timestep: 104192 Average reward is -0.0565\n",
      "INFO - Step 104200, loss: 0.60409283638000495\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 104337, loss: 0.49357366561889657\n",
      "########## Evaluation ##########\n",
      "Timestep: 104337 Average reward is -0.0672\n",
      "INFO - Step 104357, loss: 0.29083105921745344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 104506, loss: 0.50473719835281376\n",
      "########## Evaluation ##########\n",
      "Timestep: 104506 Average reward is -0.0729\n",
      "INFO - Step 104654, loss: 0.32093226909637456\n",
      "########## Evaluation ##########\n",
      "Timestep: 104654 Average reward is -0.0783\n",
      "INFO - Step 104800, loss: 0.54288589954376224\n",
      "########## Evaluation ##########\n",
      "Timestep: 104800 Average reward is -0.0741\n",
      "INFO - Step 104949, loss: 0.48433017730712894\n",
      "########## Evaluation ##########\n",
      "Timestep: 104949 Average reward is -0.0584\n",
      "INFO - Step 105111, loss: 0.42743065953254786\n",
      "########## Evaluation ##########\n",
      "Timestep: 105111 Average reward is -0.0741\n",
      "INFO - Step 105200, loss: 0.52029615640640266\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 105258, loss: 0.52769267559051514\n",
      "########## Evaluation ##########\n",
      "Timestep: 105258 Average reward is -0.065\n",
      "INFO - Step 105404, loss: 0.53209179639816286\n",
      "########## Evaluation ##########\n",
      "Timestep: 105404 Average reward is -0.0747\n",
      "INFO - Step 105564, loss: 0.63457393646240236\n",
      "########## Evaluation ##########\n",
      "Timestep: 105564 Average reward is -0.0681\n",
      "INFO - Step 105723, loss: 0.45023491978645325\n",
      "########## Evaluation ##########\n",
      "Timestep: 105723 Average reward is -0.0597\n",
      "INFO - Step 105888, loss: 0.46420592069625854\n",
      "########## Evaluation ##########\n",
      "Timestep: 105888 Average reward is -0.0781\n",
      "INFO - Step 105935, loss: 0.54233127832412726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 106042, loss: 0.43478333950042725\n",
      "########## Evaluation ##########\n",
      "Timestep: 106042 Average reward is -0.0613\n",
      "INFO - Step 106195, loss: 0.35938060283660896\n",
      "########## Evaluation ##########\n",
      "Timestep: 106195 Average reward is -0.0743\n",
      "INFO - Step 106200, loss: 0.5744437575340271\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 106360, loss: 0.51105719804763796\n",
      "########## Evaluation ##########\n",
      "Timestep: 106360 Average reward is -0.062\n",
      "INFO - Step 106512, loss: 0.51896047592163095\n",
      "########## Evaluation ##########\n",
      "Timestep: 106512 Average reward is -0.0718\n",
      "INFO - Step 106662, loss: 0.44852042198181153\n",
      "########## Evaluation ##########\n",
      "Timestep: 106662 Average reward is -0.093\n",
      "INFO - Step 106829, loss: 0.55909973382949834\n",
      "########## Evaluation ##########\n",
      "Timestep: 106829 Average reward is -0.0749\n",
      "INFO - Step 106968, loss: 0.23371995985507965\n",
      "########## Evaluation ##########\n",
      "Timestep: 106968 Average reward is -0.0559\n",
      "INFO - Step 107136, loss: 0.57939159870147766\n",
      "########## Evaluation ##########\n",
      "Timestep: 107136 Average reward is -0.0618\n",
      "INFO - Step 107200, loss: 0.50255954265594485\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 107305, loss: 0.53012901544570926\n",
      "########## Evaluation ##########\n",
      "Timestep: 107305 Average reward is -0.0814\n",
      "INFO - Step 107446, loss: 0.38848835229873663\n",
      "########## Evaluation ##########\n",
      "Timestep: 107446 Average reward is -0.0656\n",
      "INFO - Step 107488, loss: 0.41458064317703247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 107606, loss: 0.46085518598556527\n",
      "########## Evaluation ##########\n",
      "Timestep: 107606 Average reward is -0.0604\n",
      "INFO - Step 107750, loss: 0.45894476771354675\n",
      "########## Evaluation ##########\n",
      "Timestep: 107750 Average reward is -0.0594\n",
      "INFO - Step 107903, loss: 0.42227125167846684\n",
      "########## Evaluation ##########\n",
      "Timestep: 107903 Average reward is -0.0561\n",
      "INFO - Step 108060, loss: 0.86716890335083016\n",
      "########## Evaluation ##########\n",
      "Timestep: 108060 Average reward is -0.0676\n",
      "INFO - Step 108200, loss: 0.71887797117233283\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 108211, loss: 0.38999366760253906\n",
      "########## Evaluation ##########\n",
      "Timestep: 108211 Average reward is -0.0574\n",
      "INFO - Step 108361, loss: 0.51949417591094977\n",
      "########## Evaluation ##########\n",
      "Timestep: 108361 Average reward is -0.0609\n",
      "INFO - Step 108514, loss: 0.38415575027465825\n",
      "########## Evaluation ##########\n",
      "Timestep: 108514 Average reward is -0.0767\n",
      "INFO - Step 108673, loss: 0.38672709465026855\n",
      "########## Evaluation ##########\n",
      "Timestep: 108673 Average reward is -0.0658\n",
      "INFO - Step 108826, loss: 0.38920110464096073\n",
      "########## Evaluation ##########\n",
      "Timestep: 108826 Average reward is -0.0726\n",
      "INFO - Step 108984, loss: 0.43830043077468875\n",
      "########## Evaluation ##########\n",
      "Timestep: 108984 Average reward is -0.0698\n",
      "INFO - Step 109031, loss: 0.52507972717285165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 109137, loss: 0.38357141613960266\n",
      "########## Evaluation ##########\n",
      "Timestep: 109137 Average reward is -0.0578\n",
      "INFO - Step 109200, loss: 0.44780027866363525\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 109293, loss: 0.57739639282226565\n",
      "########## Evaluation ##########\n",
      "Timestep: 109293 Average reward is -0.0795\n",
      "INFO - Step 109456, loss: 0.52253341674804694\n",
      "########## Evaluation ##########\n",
      "Timestep: 109456 Average reward is -0.0616\n",
      "INFO - Step 109614, loss: 0.38866862654685974\n",
      "########## Evaluation ##########\n",
      "Timestep: 109614 Average reward is -0.0615\n",
      "INFO - Step 109770, loss: 0.42592817544937134\n",
      "########## Evaluation ##########\n",
      "Timestep: 109770 Average reward is -0.0629\n",
      "INFO - Step 109925, loss: 0.48615795373916626\n",
      "########## Evaluation ##########\n",
      "Timestep: 109925 Average reward is -0.0616\n",
      "INFO - Step 110074, loss: 0.45036277174949646\n",
      "########## Evaluation ##########\n",
      "Timestep: 110074 Average reward is -0.069\n",
      "INFO - Step 110200, loss: 0.47676575183868413\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 110214, loss: 0.45165973901748665\n",
      "########## Evaluation ##########\n",
      "Timestep: 110214 Average reward is -0.065\n",
      "INFO - Step 110369, loss: 0.73343360424041757\n",
      "########## Evaluation ##########\n",
      "Timestep: 110369 Average reward is -0.0638\n",
      "INFO - Step 110520, loss: 0.39899867773056036\n",
      "########## Evaluation ##########\n",
      "Timestep: 110520 Average reward is -0.0754\n",
      "INFO - Step 110552, loss: 0.56198918819427493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 110677, loss: 0.51089203357696534\n",
      "########## Evaluation ##########\n",
      "Timestep: 110677 Average reward is -0.0614\n",
      "INFO - Step 110819, loss: 0.41312187910079956\n",
      "########## Evaluation ##########\n",
      "Timestep: 110819 Average reward is -0.0706\n",
      "INFO - Step 110968, loss: 0.59915643930435186\n",
      "########## Evaluation ##########\n",
      "Timestep: 110968 Average reward is -0.0796\n",
      "INFO - Step 111121, loss: 0.44711196422576904\n",
      "########## Evaluation ##########\n",
      "Timestep: 111121 Average reward is -0.068\n",
      "INFO - Step 111200, loss: 0.53525292873382576\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 111279, loss: 0.43553531169891364\n",
      "########## Evaluation ##########\n",
      "Timestep: 111279 Average reward is -0.0691\n",
      "INFO - Step 111432, loss: 0.52443099021911623\n",
      "########## Evaluation ##########\n",
      "Timestep: 111432 Average reward is -0.0816\n",
      "INFO - Step 111584, loss: 0.43804451823234564\n",
      "########## Evaluation ##########\n",
      "Timestep: 111584 Average reward is -0.0611\n",
      "INFO - Step 111741, loss: 0.58061677217483526\n",
      "########## Evaluation ##########\n",
      "Timestep: 111741 Average reward is -0.0555\n",
      "INFO - Step 111901, loss: 0.56375271081924445\n",
      "########## Evaluation ##########\n",
      "Timestep: 111901 Average reward is -0.0672\n",
      "INFO - Step 112065, loss: 0.52121496200561525\n",
      "########## Evaluation ##########\n",
      "Timestep: 112065 Average reward is -0.0748\n",
      "INFO - Step 112113, loss: 0.42570817470550537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 112200, loss: 0.44514483213424683\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 112221, loss: 0.54909002780914316\n",
      "########## Evaluation ##########\n",
      "Timestep: 112221 Average reward is -0.0536\n",
      "INFO - Step 112365, loss: 0.56103754043579164\n",
      "########## Evaluation ##########\n",
      "Timestep: 112365 Average reward is -0.0563\n",
      "INFO - Step 112525, loss: 0.49185746908187866\n",
      "########## Evaluation ##########\n",
      "Timestep: 112525 Average reward is -0.0785\n",
      "INFO - Step 112683, loss: 0.47295725345611575\n",
      "########## Evaluation ##########\n",
      "Timestep: 112683 Average reward is -0.0734\n",
      "INFO - Step 112834, loss: 0.54254209995269786\n",
      "########## Evaluation ##########\n",
      "Timestep: 112834 Average reward is -0.0602\n",
      "INFO - Step 112978, loss: 0.48008161783218384\n",
      "########## Evaluation ##########\n",
      "Timestep: 112978 Average reward is -0.0859\n",
      "INFO - Step 113130, loss: 0.53497552871704186\n",
      "########## Evaluation ##########\n",
      "Timestep: 113130 Average reward is -0.0681\n",
      "INFO - Step 113200, loss: 0.48216640949249273\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 113276, loss: 0.61118686199188234\n",
      "########## Evaluation ##########\n",
      "Timestep: 113276 Average reward is -0.0571\n",
      "INFO - Step 113424, loss: 0.64764082431793213\n",
      "########## Evaluation ##########\n",
      "Timestep: 113424 Average reward is -0.0365\n",
      "INFO - Step 113584, loss: 0.41949701309204176\n",
      "########## Evaluation ##########\n",
      "Timestep: 113584 Average reward is -0.0585\n",
      "INFO - Step 113635, loss: 0.48807325959205635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 113734, loss: 0.48919147253036573\n",
      "########## Evaluation ##########\n",
      "Timestep: 113734 Average reward is -0.0684\n",
      "INFO - Step 113887, loss: 0.48505076766014185\n",
      "########## Evaluation ##########\n",
      "Timestep: 113887 Average reward is -0.0666\n",
      "INFO - Step 114044, loss: 0.58285504579544073\n",
      "########## Evaluation ##########\n",
      "Timestep: 114044 Average reward is -0.0536\n",
      "INFO - Step 114196, loss: 0.43180578947067265\n",
      "########## Evaluation ##########\n",
      "Timestep: 114196 Average reward is -0.0549\n",
      "INFO - Step 114200, loss: 0.43795740604400635\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 114358, loss: 0.43605694174766546\n",
      "########## Evaluation ##########\n",
      "Timestep: 114358 Average reward is -0.0621\n",
      "INFO - Step 114503, loss: 0.52994024753570564\n",
      "########## Evaluation ##########\n",
      "Timestep: 114503 Average reward is -0.0668\n",
      "INFO - Step 114658, loss: 0.44116857647895813\n",
      "########## Evaluation ##########\n",
      "Timestep: 114658 Average reward is -0.0685\n",
      "INFO - Step 114815, loss: 0.53521692752838134\n",
      "########## Evaluation ##########\n",
      "Timestep: 114815 Average reward is -0.0782\n",
      "INFO - Step 114956, loss: 0.72400236129760744\n",
      "########## Evaluation ##########\n",
      "Timestep: 114956 Average reward is -0.0805\n",
      "INFO - Step 115114, loss: 0.46445459127426156\n",
      "########## Evaluation ##########\n",
      "Timestep: 115114 Average reward is -0.0749\n",
      "INFO - Step 115156, loss: 0.32408919930458075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 115200, loss: 0.35432827472686774\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 115259, loss: 0.49762979149818426\n",
      "########## Evaluation ##########\n",
      "Timestep: 115259 Average reward is -0.0628\n",
      "INFO - Step 115411, loss: 0.43828254938125617\n",
      "########## Evaluation ##########\n",
      "Timestep: 115411 Average reward is -0.0624\n",
      "INFO - Step 115561, loss: 0.50187540054321294\n",
      "########## Evaluation ##########\n",
      "Timestep: 115561 Average reward is -0.0834\n",
      "INFO - Step 115709, loss: 0.70300734043121344\n",
      "########## Evaluation ##########\n",
      "Timestep: 115709 Average reward is -0.0705\n",
      "INFO - Step 115865, loss: 0.39999109506607056\n",
      "########## Evaluation ##########\n",
      "Timestep: 115865 Average reward is -0.0626\n",
      "INFO - Step 116010, loss: 0.34830814599990845\n",
      "########## Evaluation ##########\n",
      "Timestep: 116010 Average reward is -0.0756\n",
      "INFO - Step 116163, loss: 0.33256441354751587\n",
      "########## Evaluation ##########\n",
      "Timestep: 116163 Average reward is -0.0802\n",
      "INFO - Step 116200, loss: 0.40451222658157356\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 116314, loss: 0.56388813257217415\n",
      "########## Evaluation ##########\n",
      "Timestep: 116314 Average reward is -0.0849\n",
      "INFO - Step 116468, loss: 0.50438904762268076\n",
      "########## Evaluation ##########\n",
      "Timestep: 116468 Average reward is -0.061\n",
      "INFO - Step 116608, loss: 0.52752578258514464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Evaluation ##########\n",
      "Timestep: 116608 Average reward is -0.0773\n",
      "INFO - Step 116757, loss: 0.65079391002655033\n",
      "########## Evaluation ##########\n",
      "Timestep: 116757 Average reward is -0.0625\n",
      "INFO - Step 116908, loss: 0.56244534254074154\n",
      "########## Evaluation ##########\n",
      "Timestep: 116908 Average reward is -0.0617\n",
      "INFO - Step 117076, loss: 0.36107361316680914\n",
      "########## Evaluation ##########\n",
      "Timestep: 117076 Average reward is -0.0669\n",
      "INFO - Step 117200, loss: 0.41664358973503113\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 117233, loss: 0.48362904787063633\n",
      "########## Evaluation ##########\n",
      "Timestep: 117233 Average reward is -0.0757\n",
      "INFO - Step 117377, loss: 0.56653404235839846\n",
      "########## Evaluation ##########\n",
      "Timestep: 117377 Average reward is -0.0642\n",
      "INFO - Step 117523, loss: 0.52650660276412967\n",
      "########## Evaluation ##########\n",
      "Timestep: 117523 Average reward is -0.0606\n",
      "INFO - Step 117673, loss: 0.39014303684234626\n",
      "########## Evaluation ##########\n",
      "Timestep: 117673 Average reward is -0.0488\n",
      "INFO - Step 117826, loss: 0.54461205005645753\n",
      "########## Evaluation ##########\n",
      "Timestep: 117826 Average reward is -0.0828\n",
      "INFO - Step 117974, loss: 0.46767386794090275\n",
      "########## Evaluation ##########\n",
      "Timestep: 117974 Average reward is -0.0778\n",
      "INFO - Step 118121, loss: 0.46748325228691173\n",
      "########## Evaluation ##########\n",
      "Timestep: 118121 Average reward is -0.0721\n",
      "INFO - Step 118170, loss: 0.58794486522674563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 118200, loss: 0.33878499269485474\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 118278, loss: 0.68876326084136966\n",
      "########## Evaluation ##########\n",
      "Timestep: 118278 Average reward is -0.0607\n",
      "INFO - Step 118430, loss: 0.47570705413818365\n",
      "########## Evaluation ##########\n",
      "Timestep: 118430 Average reward is -0.0668\n",
      "INFO - Step 118580, loss: 0.56239235401153564\n",
      "########## Evaluation ##########\n",
      "Timestep: 118580 Average reward is -0.0568\n",
      "INFO - Step 118751, loss: 0.44936305284500123\n",
      "########## Evaluation ##########\n",
      "Timestep: 118751 Average reward is -0.0714\n",
      "INFO - Step 118906, loss: 0.61495339870452887\n",
      "########## Evaluation ##########\n",
      "Timestep: 118906 Average reward is -0.0693\n",
      "INFO - Step 119062, loss: 0.44296789169311523\n",
      "########## Evaluation ##########\n",
      "Timestep: 119062 Average reward is -0.085\n",
      "INFO - Step 119200, loss: 0.38169294595718384\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 119224, loss: 0.48126223683357246\n",
      "########## Evaluation ##########\n",
      "Timestep: 119224 Average reward is -0.059\n",
      "INFO - Step 119371, loss: 0.28184074163436895\n",
      "########## Evaluation ##########\n",
      "Timestep: 119371 Average reward is -0.0473\n",
      "INFO - Step 119522, loss: 0.39665049314498987\n",
      "########## Evaluation ##########\n",
      "Timestep: 119522 Average reward is -0.0742\n",
      "INFO - Step 119670, loss: 0.34335792064666756\n",
      "########## Evaluation ##########\n",
      "Timestep: 119670 Average reward is -0.0727\n",
      "INFO - Step 119722, loss: 0.57746732234954835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 119833, loss: 0.59937405586242687\n",
      "########## Evaluation ##########\n",
      "Timestep: 119833 Average reward is -0.0704\n",
      "INFO - Step 119987, loss: 0.39220386743545537\n",
      "########## Evaluation ##########\n",
      "Timestep: 119987 Average reward is -0.07\n",
      "INFO - Step 120137, loss: 0.39947149157524113\n",
      "########## Evaluation ##########\n",
      "Timestep: 120137 Average reward is -0.0611\n",
      "INFO - Step 120200, loss: 0.38719910383224493\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 120302, loss: 0.48215237259864807\n",
      "########## Evaluation ##########\n",
      "Timestep: 120302 Average reward is -0.0836\n",
      "INFO - Step 120453, loss: 0.46841278672218323\n",
      "########## Evaluation ##########\n",
      "Timestep: 120453 Average reward is -0.0542\n",
      "INFO - Step 120604, loss: 0.40136739611625674\n",
      "########## Evaluation ##########\n",
      "Timestep: 120604 Average reward is -0.0638\n",
      "INFO - Step 120755, loss: 0.38844081759452824\n",
      "########## Evaluation ##########\n",
      "Timestep: 120755 Average reward is -0.0664\n",
      "INFO - Step 120907, loss: 0.49618574976921084\n",
      "########## Evaluation ##########\n",
      "Timestep: 120907 Average reward is -0.0796\n",
      "INFO - Step 121060, loss: 0.50926089286804273\n",
      "########## Evaluation ##########\n",
      "Timestep: 121060 Average reward is -0.0927\n",
      "INFO - Step 121200, loss: 0.40522652864456177\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 121209, loss: 0.58154094219207764\n",
      "########## Evaluation ##########\n",
      "Timestep: 121209 Average reward is -0.0663\n",
      "INFO - Step 121254, loss: 0.40876853466033936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 121348, loss: 0.49623614549636846\n",
      "########## Evaluation ##########\n",
      "Timestep: 121348 Average reward is -0.0767\n",
      "INFO - Step 121492, loss: 0.40772151947021484\n",
      "########## Evaluation ##########\n",
      "Timestep: 121492 Average reward is -0.0762\n",
      "INFO - Step 121642, loss: 0.53061544895172123\n",
      "########## Evaluation ##########\n",
      "Timestep: 121642 Average reward is -0.0803\n",
      "INFO - Step 121799, loss: 0.40505635738372856\n",
      "########## Evaluation ##########\n",
      "Timestep: 121799 Average reward is -0.0717\n",
      "INFO - Step 121963, loss: 0.47124019265174866\n",
      "########## Evaluation ##########\n",
      "Timestep: 121963 Average reward is -0.0651\n",
      "INFO - Step 122110, loss: 0.31276518106460575\n",
      "########## Evaluation ##########\n",
      "Timestep: 122110 Average reward is -0.0895\n",
      "INFO - Step 122200, loss: 0.49699580669403076\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 122269, loss: 0.47803923487663275\n",
      "########## Evaluation ##########\n",
      "Timestep: 122269 Average reward is -0.0618\n",
      "INFO - Step 122429, loss: 0.40743955969810486\n",
      "########## Evaluation ##########\n",
      "Timestep: 122429 Average reward is -0.068\n",
      "INFO - Step 122577, loss: 0.56994068622589115\n",
      "########## Evaluation ##########\n",
      "Timestep: 122577 Average reward is -0.066\n",
      "INFO - Step 122724, loss: 0.40288168191909795\n",
      "########## Evaluation ##########\n",
      "Timestep: 122724 Average reward is -0.0707\n",
      "INFO - Step 122781, loss: 0.59071666002273567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 122883, loss: 0.36049929261207587\n",
      "########## Evaluation ##########\n",
      "Timestep: 122883 Average reward is -0.0654\n",
      "INFO - Step 123041, loss: 0.44536340236663823\n",
      "########## Evaluation ##########\n",
      "Timestep: 123041 Average reward is -0.0529\n",
      "INFO - Step 123194, loss: 0.41693204641342163\n",
      "########## Evaluation ##########\n",
      "Timestep: 123194 Average reward is -0.0631\n",
      "INFO - Step 123200, loss: 0.48173597455024727\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 123348, loss: 0.37543982267379765\n",
      "########## Evaluation ##########\n",
      "Timestep: 123348 Average reward is -0.0666\n",
      "INFO - Step 123497, loss: 0.41385534405708313\n",
      "########## Evaluation ##########\n",
      "Timestep: 123497 Average reward is -0.0718\n",
      "INFO - Step 123639, loss: 0.74339556694030766\n",
      "########## Evaluation ##########\n",
      "Timestep: 123639 Average reward is -0.0723\n",
      "INFO - Step 123785, loss: 0.62064325809478767\n",
      "########## Evaluation ##########\n",
      "Timestep: 123785 Average reward is -0.0537\n",
      "INFO - Step 123933, loss: 0.39228525757789617\n",
      "########## Evaluation ##########\n",
      "Timestep: 123933 Average reward is -0.0576\n",
      "INFO - Step 124088, loss: 0.51613676548004156\n",
      "########## Evaluation ##########\n",
      "Timestep: 124088 Average reward is -0.0628\n",
      "INFO - Step 124200, loss: 0.46528235077857974\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 124234, loss: 0.36622652411460876\n",
      "########## Evaluation ##########\n",
      "Timestep: 124234 Average reward is -0.0589\n",
      "INFO - Step 124286, loss: 0.59893238544464116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 124379, loss: 0.37269541621208197\n",
      "########## Evaluation ##########\n",
      "Timestep: 124379 Average reward is -0.0521\n",
      "INFO - Step 124531, loss: 0.30411651730537415\n",
      "########## Evaluation ##########\n",
      "Timestep: 124531 Average reward is -0.0519\n",
      "INFO - Step 124685, loss: 0.41286131739616394\n",
      "########## Evaluation ##########\n",
      "Timestep: 124685 Average reward is -0.0607\n",
      "INFO - Step 124838, loss: 0.35917603969573975\n",
      "########## Evaluation ##########\n",
      "Timestep: 124838 Average reward is -0.0596\n",
      "INFO - Step 125003, loss: 0.39105939865112305\n",
      "########## Evaluation ##########\n",
      "Timestep: 125003 Average reward is -0.0673\n",
      "INFO - Step 125163, loss: 0.39197298884391785\n",
      "########## Evaluation ##########\n",
      "Timestep: 125163 Average reward is -0.0635\n",
      "INFO - Step 125200, loss: 0.49490797519683843\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 125305, loss: 0.75427180528640753\n",
      "########## Evaluation ##########\n",
      "Timestep: 125305 Average reward is -0.0577\n",
      "INFO - Step 125467, loss: 0.41248780488967896\n",
      "########## Evaluation ##########\n",
      "Timestep: 125467 Average reward is -0.0601\n",
      "INFO - Step 125616, loss: 0.35490107536315924\n",
      "########## Evaluation ##########\n",
      "Timestep: 125616 Average reward is -0.0706\n",
      "INFO - Step 125766, loss: 0.45778661966323856\n",
      "########## Evaluation ##########\n",
      "Timestep: 125766 Average reward is -0.0564\n",
      "INFO - Step 125827, loss: 0.40041375160217285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 125927, loss: 0.35672232508659363\n",
      "########## Evaluation ##########\n",
      "Timestep: 125927 Average reward is -0.064\n",
      "INFO - Step 126078, loss: 0.57894027233123787\n",
      "########## Evaluation ##########\n",
      "Timestep: 126078 Average reward is -0.0605\n",
      "INFO - Step 126200, loss: 0.43413582444190984\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 126235, loss: 0.44163188338279724\n",
      "########## Evaluation ##########\n",
      "Timestep: 126235 Average reward is -0.0636\n",
      "INFO - Step 126381, loss: 0.60171800851821977\n",
      "########## Evaluation ##########\n",
      "Timestep: 126381 Average reward is -0.0697\n",
      "INFO - Step 126542, loss: 0.64230430126190196\n",
      "########## Evaluation ##########\n",
      "Timestep: 126542 Average reward is -0.0756\n",
      "INFO - Step 126691, loss: 0.46981376409530645\n",
      "########## Evaluation ##########\n",
      "Timestep: 126691 Average reward is -0.0537\n",
      "INFO - Step 126847, loss: 0.42329850792884827\n",
      "########## Evaluation ##########\n",
      "Timestep: 126847 Average reward is -0.0578\n",
      "INFO - Step 127006, loss: 0.58803629875183164\n",
      "########## Evaluation ##########\n",
      "Timestep: 127006 Average reward is -0.0784\n",
      "INFO - Step 127150, loss: 0.22666668891906738\n",
      "########## Evaluation ##########\n",
      "Timestep: 127150 Average reward is -0.0661\n",
      "INFO - Step 127200, loss: 0.57454252243041993\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 127308, loss: 0.33028852939605713\n",
      "########## Evaluation ##########\n",
      "Timestep: 127308 Average reward is -0.0727\n",
      "INFO - Step 127360, loss: 0.39406549930572517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 127463, loss: 0.54954743385314946\n",
      "########## Evaluation ##########\n",
      "Timestep: 127463 Average reward is -0.0535\n",
      "INFO - Step 127625, loss: 0.37443736195564276\n",
      "########## Evaluation ##########\n",
      "Timestep: 127625 Average reward is -0.0694\n",
      "INFO - Step 127779, loss: 0.35603874921798706\n",
      "########## Evaluation ##########\n",
      "Timestep: 127779 Average reward is -0.0667\n",
      "INFO - Step 127941, loss: 0.52613770961761475\n",
      "########## Evaluation ##########\n",
      "Timestep: 127941 Average reward is -0.0527\n",
      "INFO - Step 128087, loss: 0.41663748025894165\n",
      "########## Evaluation ##########\n",
      "Timestep: 128087 Average reward is -0.0748\n",
      "INFO - Step 128200, loss: 0.51612889766693124\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 128244, loss: 0.49430549144744873\n",
      "########## Evaluation ##########\n",
      "Timestep: 128244 Average reward is -0.0668\n",
      "INFO - Step 128400, loss: 0.43417629599571236\n",
      "########## Evaluation ##########\n",
      "Timestep: 128400 Average reward is -0.0675\n",
      "INFO - Step 128541, loss: 0.49465176463127136\n",
      "########## Evaluation ##########\n",
      "Timestep: 128541 Average reward is -0.0592\n",
      "INFO - Step 128687, loss: 0.54704904556274416\n",
      "########## Evaluation ##########\n",
      "Timestep: 128687 Average reward is -0.0811\n",
      "INFO - Step 128837, loss: 0.51812833547592163\n",
      "########## Evaluation ##########\n",
      "Timestep: 128837 Average reward is -0.0854\n",
      "INFO - Step 128890, loss: 0.62434709072113044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 128985, loss: 0.70098745822906494\n",
      "########## Evaluation ##########\n",
      "Timestep: 128985 Average reward is -0.059\n",
      "INFO - Step 129135, loss: 0.57981163263320926\n",
      "########## Evaluation ##########\n",
      "Timestep: 129135 Average reward is -0.078\n",
      "INFO - Step 129200, loss: 0.54529684782028224\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 129296, loss: 0.41626361012458865\n",
      "########## Evaluation ##########\n",
      "Timestep: 129296 Average reward is -0.0727\n",
      "INFO - Step 129437, loss: 0.42341178655624396\n",
      "########## Evaluation ##########\n",
      "Timestep: 129437 Average reward is -0.0625\n",
      "INFO - Step 129595, loss: 0.42344707250595096\n",
      "########## Evaluation ##########\n",
      "Timestep: 129595 Average reward is -0.0661\n",
      "INFO - Step 129748, loss: 0.40579217672348025\n",
      "########## Evaluation ##########\n",
      "Timestep: 129748 Average reward is -0.0584\n",
      "INFO - Step 129900, loss: 0.50367951393127447\n",
      "########## Evaluation ##########\n",
      "Timestep: 129900 Average reward is -0.0406\n",
      "INFO - Step 130060, loss: 0.33220005035400393\n",
      "########## Evaluation ##########\n",
      "Timestep: 130060 Average reward is -0.0786\n",
      "INFO - Step 130200, loss: 0.55256992578506473\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 130203, loss: 0.4515291452407837\n",
      "########## Evaluation ##########\n",
      "Timestep: 130203 Average reward is -0.0711\n",
      "INFO - Step 130356, loss: 0.43949201703071594\n",
      "########## Evaluation ##########\n",
      "Timestep: 130356 Average reward is -0.0667\n",
      "INFO - Step 130411, loss: 0.55309170484542856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 130513, loss: 0.55558049678802496\n",
      "########## Evaluation ##########\n",
      "Timestep: 130513 Average reward is -0.0593\n",
      "INFO - Step 130653, loss: 0.46155944466590885\n",
      "########## Evaluation ##########\n",
      "Timestep: 130653 Average reward is -0.075\n",
      "INFO - Step 130805, loss: 0.46946910023689276\n",
      "########## Evaluation ##########\n",
      "Timestep: 130805 Average reward is -0.07\n",
      "INFO - Step 130955, loss: 0.37082186341285706\n",
      "########## Evaluation ##########\n",
      "Timestep: 130955 Average reward is -0.0726\n",
      "INFO - Step 131092, loss: 0.57830137014389045\n",
      "########## Evaluation ##########\n",
      "Timestep: 131092 Average reward is -0.0642\n",
      "INFO - Step 131200, loss: 0.60514587163925176\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 131231, loss: 0.70979297161102374\n",
      "########## Evaluation ##########\n",
      "Timestep: 131231 Average reward is -0.0481\n",
      "INFO - Step 131377, loss: 0.53628492355346686\n",
      "########## Evaluation ##########\n",
      "Timestep: 131377 Average reward is -0.073\n",
      "INFO - Step 131512, loss: 0.46082979440689087\n",
      "########## Evaluation ##########\n",
      "Timestep: 131512 Average reward is -0.0814\n",
      "INFO - Step 131667, loss: 0.61211979389190673\n",
      "########## Evaluation ##########\n",
      "Timestep: 131667 Average reward is -0.0734\n",
      "INFO - Step 131807, loss: 0.43860056996345525\n",
      "########## Evaluation ##########\n",
      "Timestep: 131807 Average reward is -0.0698\n",
      "INFO - Step 131856, loss: 0.64123606681823737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 131945, loss: 0.52327960729599826\n",
      "########## Evaluation ##########\n",
      "Timestep: 131945 Average reward is -0.0601\n",
      "INFO - Step 132083, loss: 0.54829645156860355\n",
      "########## Evaluation ##########\n",
      "Timestep: 132083 Average reward is -0.0691\n",
      "INFO - Step 132200, loss: 0.66216534376144414\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 132224, loss: 0.50649785995483455\n",
      "########## Evaluation ##########\n",
      "Timestep: 132224 Average reward is -0.0615\n",
      "INFO - Step 132369, loss: 0.50983351469039925\n",
      "########## Evaluation ##########\n",
      "Timestep: 132369 Average reward is -0.0852\n",
      "INFO - Step 132511, loss: 0.59243482351303135\n",
      "########## Evaluation ##########\n",
      "Timestep: 132511 Average reward is -0.0507\n",
      "INFO - Step 132653, loss: 0.63157236576080326\n",
      "########## Evaluation ##########\n",
      "Timestep: 132653 Average reward is -0.0672\n",
      "INFO - Step 132800, loss: 0.59875822067260745\n",
      "########## Evaluation ##########\n",
      "Timestep: 132800 Average reward is -0.0567\n",
      "INFO - Step 132942, loss: 0.46161460876464844\n",
      "########## Evaluation ##########\n",
      "Timestep: 132942 Average reward is -0.0706\n",
      "INFO - Step 133088, loss: 0.74338763952255257\n",
      "########## Evaluation ##########\n",
      "Timestep: 133088 Average reward is -0.0661\n",
      "INFO - Step 133200, loss: 0.57806646823883064\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 133229, loss: 0.57863259315490727\n",
      "########## Evaluation ##########\n",
      "Timestep: 133229 Average reward is -0.0714\n",
      "INFO - Step 133281, loss: 0.33122530579566956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 133375, loss: 0.49066561460494995\n",
      "########## Evaluation ##########\n",
      "Timestep: 133375 Average reward is -0.0735\n",
      "INFO - Step 133513, loss: 0.66357785463333135\n",
      "########## Evaluation ##########\n",
      "Timestep: 133513 Average reward is -0.0825\n",
      "INFO - Step 133651, loss: 0.76327556371688846\n",
      "########## Evaluation ##########\n",
      "Timestep: 133651 Average reward is -0.0598\n",
      "INFO - Step 133806, loss: 0.47257822751998984\n",
      "########## Evaluation ##########\n",
      "Timestep: 133806 Average reward is -0.091\n",
      "INFO - Step 133946, loss: 0.67900419235229496\n",
      "########## Evaluation ##########\n",
      "Timestep: 133946 Average reward is -0.0752\n",
      "INFO - Step 134094, loss: 0.46965652704238894\n",
      "########## Evaluation ##########\n",
      "Timestep: 134094 Average reward is -0.0801\n",
      "INFO - Step 134200, loss: 0.52505123615264897\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 134248, loss: 0.49214285612106323\n",
      "########## Evaluation ##########\n",
      "Timestep: 134248 Average reward is -0.0746\n",
      "INFO - Step 134386, loss: 0.57818692922592166\n",
      "########## Evaluation ##########\n",
      "Timestep: 134386 Average reward is -0.0887\n",
      "INFO - Step 134528, loss: 0.55998778343200685\n",
      "########## Evaluation ##########\n",
      "Timestep: 134528 Average reward is -0.0653\n",
      "INFO - Step 134672, loss: 0.70900499820709233\n",
      "########## Evaluation ##########\n",
      "Timestep: 134672 Average reward is -0.0608\n",
      "INFO - Step 134724, loss: 0.48100063204765324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 134800, loss: 0.42568057775497437\n",
      "########## Evaluation ##########\n",
      "Timestep: 134800 Average reward is -0.0832\n",
      "INFO - Step 134950, loss: 0.64061272144317637\n",
      "########## Evaluation ##########\n",
      "Timestep: 134950 Average reward is -0.0736\n",
      "INFO - Step 135090, loss: 0.52753096818923957\n",
      "########## Evaluation ##########\n",
      "Timestep: 135090 Average reward is -0.0734\n",
      "INFO - Step 135200, loss: 0.71932172775268557\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 135226, loss: 0.55889117717742924\n",
      "########## Evaluation ##########\n",
      "Timestep: 135226 Average reward is -0.0827\n",
      "INFO - Step 135364, loss: 0.34687554836273193\n",
      "########## Evaluation ##########\n",
      "Timestep: 135364 Average reward is -0.0698\n",
      "INFO - Step 135506, loss: 0.30114924907684326\n",
      "########## Evaluation ##########\n",
      "Timestep: 135506 Average reward is -0.0645\n",
      "INFO - Step 135654, loss: 0.66779845952987676\n",
      "########## Evaluation ##########\n",
      "Timestep: 135654 Average reward is -0.0657\n",
      "INFO - Step 135798, loss: 0.40617409348487854\n",
      "########## Evaluation ##########\n",
      "Timestep: 135798 Average reward is -0.0798\n",
      "INFO - Step 135941, loss: 0.52770006656646735\n",
      "########## Evaluation ##########\n",
      "Timestep: 135941 Average reward is -0.0678\n",
      "INFO - Step 136076, loss: 0.34763610363006597\n",
      "########## Evaluation ##########\n",
      "Timestep: 136076 Average reward is -0.0759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 136200, loss: 0.37009328603744507\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 136229, loss: 0.67435896396636966\n",
      "########## Evaluation ##########\n",
      "Timestep: 136229 Average reward is -0.0752\n",
      "INFO - Step 136375, loss: 0.46438086032867434\n",
      "########## Evaluation ##########\n",
      "Timestep: 136375 Average reward is -0.0518\n",
      "INFO - Step 136530, loss: 0.35936087369918823\n",
      "########## Evaluation ##########\n",
      "Timestep: 136530 Average reward is -0.0712\n",
      "INFO - Step 136674, loss: 0.45948582887649536\n",
      "########## Evaluation ##########\n",
      "Timestep: 136674 Average reward is -0.06\n",
      "INFO - Step 136823, loss: 0.55586063861846925\n",
      "########## Evaluation ##########\n",
      "Timestep: 136823 Average reward is -0.0679\n",
      "INFO - Step 136979, loss: 0.70855218172073365\n",
      "########## Evaluation ##########\n",
      "Timestep: 136979 Average reward is -0.0853\n",
      "INFO - Step 137124, loss: 0.44739627838134766\n",
      "########## Evaluation ##########\n",
      "Timestep: 137124 Average reward is -0.0747\n",
      "INFO - Step 137200, loss: 0.39070099592208864\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 137270, loss: 0.56080150604248053\n",
      "########## Evaluation ##########\n",
      "Timestep: 137270 Average reward is -0.0763\n",
      "INFO - Step 137410, loss: 0.49157986044883735\n",
      "########## Evaluation ##########\n",
      "Timestep: 137410 Average reward is -0.077\n",
      "INFO - Step 137561, loss: 0.64644509553909327\n",
      "########## Evaluation ##########\n",
      "Timestep: 137561 Average reward is -0.0857\n",
      "INFO - Step 137615, loss: 0.58032059669494635"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 137696, loss: 0.49011802673339844\n",
      "########## Evaluation ##########\n",
      "Timestep: 137696 Average reward is -0.0768\n",
      "INFO - Step 137841, loss: 0.62921941280364994\n",
      "########## Evaluation ##########\n",
      "Timestep: 137841 Average reward is -0.083\n",
      "INFO - Step 137978, loss: 0.40309393405914307\n",
      "########## Evaluation ##########\n",
      "Timestep: 137978 Average reward is -0.0757\n",
      "INFO - Step 138118, loss: 0.40022641420364384\n",
      "########## Evaluation ##########\n",
      "Timestep: 138118 Average reward is -0.081\n",
      "INFO - Step 138200, loss: 0.43313392996788025\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 138266, loss: 0.56008732318878174\n",
      "########## Evaluation ##########\n",
      "Timestep: 138266 Average reward is -0.0651\n",
      "INFO - Step 138411, loss: 0.57651472091674875\n",
      "########## Evaluation ##########\n",
      "Timestep: 138411 Average reward is -0.0638\n",
      "INFO - Step 138557, loss: 0.56804370880126954\n",
      "########## Evaluation ##########\n",
      "Timestep: 138557 Average reward is -0.0504\n",
      "INFO - Step 138710, loss: 0.34653538465499884\n",
      "########## Evaluation ##########\n",
      "Timestep: 138710 Average reward is -0.0617\n",
      "INFO - Step 138847, loss: 0.47268649935722356\n",
      "########## Evaluation ##########\n",
      "Timestep: 138847 Average reward is -0.0601\n",
      "INFO - Step 138990, loss: 0.60350012779235846\n",
      "########## Evaluation ##########\n",
      "Timestep: 138990 Average reward is -0.0728\n",
      "INFO - Step 139047, loss: 0.39004430174827576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 139139, loss: 0.46438378095626836\n",
      "########## Evaluation ##########\n",
      "Timestep: 139139 Average reward is -0.0751\n",
      "INFO - Step 139200, loss: 0.66881471872329717\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 139280, loss: 0.53832173347473145\n",
      "########## Evaluation ##########\n",
      "Timestep: 139280 Average reward is -0.0706\n",
      "INFO - Step 139417, loss: 0.37678369879722595\n",
      "########## Evaluation ##########\n",
      "Timestep: 139417 Average reward is -0.067\n",
      "INFO - Step 139561, loss: 0.44346761703491217\n",
      "########## Evaluation ##########\n",
      "Timestep: 139561 Average reward is -0.059\n",
      "INFO - Step 139718, loss: 0.41902551054954533\n",
      "########## Evaluation ##########\n",
      "Timestep: 139718 Average reward is -0.063\n",
      "INFO - Step 139869, loss: 0.45747959613800056\n",
      "########## Evaluation ##########\n",
      "Timestep: 139869 Average reward is -0.0743\n",
      "INFO - Step 140013, loss: 0.67421406507492073\n",
      "########## Evaluation ##########\n",
      "Timestep: 140013 Average reward is -0.0696\n",
      "INFO - Step 140163, loss: 0.48637968301773075\n",
      "########## Evaluation ##########\n",
      "Timestep: 140163 Average reward is -0.0709\n",
      "INFO - Step 140200, loss: 0.40297836065292365\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 140299, loss: 0.43730822205543523\n",
      "########## Evaluation ##########\n",
      "Timestep: 140299 Average reward is -0.0653\n",
      "INFO - Step 140439, loss: 0.45897287130355835\n",
      "########## Evaluation ##########\n",
      "Timestep: 140439 Average reward is -0.07\n",
      "INFO - Step 140484, loss: 0.49506336450576785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 140592, loss: 0.52200055122375497\n",
      "########## Evaluation ##########\n",
      "Timestep: 140592 Average reward is -0.0648\n",
      "INFO - Step 140741, loss: 0.57507282495498666\n",
      "########## Evaluation ##########\n",
      "Timestep: 140741 Average reward is -0.0737\n",
      "INFO - Step 140890, loss: 0.43761169910430918\n",
      "########## Evaluation ##########\n",
      "Timestep: 140890 Average reward is -0.0704\n",
      "INFO - Step 141035, loss: 0.55071508884429936\n",
      "########## Evaluation ##########\n",
      "Timestep: 141035 Average reward is -0.074\n",
      "INFO - Step 141189, loss: 0.53533589839935347\n",
      "########## Evaluation ##########\n",
      "Timestep: 141189 Average reward is -0.0681\n",
      "INFO - Step 141200, loss: 0.30930083990097046\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 141336, loss: 0.65378856658935556\n",
      "########## Evaluation ##########\n",
      "Timestep: 141336 Average reward is -0.0535\n",
      "INFO - Step 141483, loss: 0.34521561861038213\n",
      "########## Evaluation ##########\n",
      "Timestep: 141483 Average reward is -0.0714\n",
      "INFO - Step 141637, loss: 0.51717650890350343\n",
      "########## Evaluation ##########\n",
      "Timestep: 141637 Average reward is -0.0633\n",
      "INFO - Step 141789, loss: 0.80956315994262796\n",
      "########## Evaluation ##########\n",
      "Timestep: 141789 Average reward is -0.0731\n",
      "INFO - Step 141943, loss: 0.49262726306915283\n",
      "########## Evaluation ##########\n",
      "Timestep: 141943 Average reward is -0.0492\n",
      "INFO - Step 141996, loss: 0.58396589756011964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 142097, loss: 0.47329145669937134\n",
      "########## Evaluation ##########\n",
      "Timestep: 142097 Average reward is -0.0629\n",
      "INFO - Step 142200, loss: 0.52395802736282353\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 142240, loss: 0.49721390008926396\n",
      "########## Evaluation ##########\n",
      "Timestep: 142240 Average reward is -0.0819\n",
      "INFO - Step 142388, loss: 0.56284773349761966\n",
      "########## Evaluation ##########\n",
      "Timestep: 142388 Average reward is -0.0481\n",
      "INFO - Step 142535, loss: 0.46432417631149293\n",
      "########## Evaluation ##########\n",
      "Timestep: 142535 Average reward is -0.0623\n",
      "INFO - Step 142681, loss: 0.50723892450332646\n",
      "########## Evaluation ##########\n",
      "Timestep: 142681 Average reward is -0.062\n",
      "INFO - Step 142831, loss: 0.76171475648884707\n",
      "########## Evaluation ##########\n",
      "Timestep: 142831 Average reward is -0.0643\n",
      "INFO - Step 142975, loss: 0.46465560793876656\n",
      "########## Evaluation ##########\n",
      "Timestep: 142975 Average reward is -0.0579\n",
      "INFO - Step 143127, loss: 0.47317129373550415\n",
      "########## Evaluation ##########\n",
      "Timestep: 143127 Average reward is -0.0707\n",
      "INFO - Step 143200, loss: 0.48722112178802496\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 143269, loss: 0.54667675495147763\n",
      "########## Evaluation ##########\n",
      "Timestep: 143269 Average reward is -0.075\n",
      "INFO - Step 143417, loss: 0.56469076871871955\n",
      "########## Evaluation ##########\n",
      "Timestep: 143417 Average reward is -0.0554\n",
      "INFO - Step 143475, loss: 0.43056058883666995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 143564, loss: 0.44408553838729867\n",
      "########## Evaluation ##########\n",
      "Timestep: 143564 Average reward is -0.0587\n",
      "INFO - Step 143714, loss: 0.65062272548675545\n",
      "########## Evaluation ##########\n",
      "Timestep: 143714 Average reward is -0.0601\n",
      "INFO - Step 143864, loss: 0.45213544368743896\n",
      "########## Evaluation ##########\n",
      "Timestep: 143864 Average reward is -0.0641\n",
      "INFO - Step 144010, loss: 0.57094061374664315\n",
      "########## Evaluation ##########\n",
      "Timestep: 144010 Average reward is -0.0657\n",
      "INFO - Step 144159, loss: 0.40791893005371094\n",
      "########## Evaluation ##########\n",
      "Timestep: 144159 Average reward is -0.0439\n",
      "INFO - Step 144200, loss: 0.57232892513275156\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 144307, loss: 0.64516651630401615\n",
      "########## Evaluation ##########\n",
      "Timestep: 144307 Average reward is -0.0513\n",
      "INFO - Step 144447, loss: 0.40230810642242437\n",
      "########## Evaluation ##########\n",
      "Timestep: 144447 Average reward is -0.0541\n",
      "INFO - Step 144598, loss: 0.65745484828948975\n",
      "########## Evaluation ##########\n",
      "Timestep: 144598 Average reward is -0.06\n",
      "INFO - Step 144751, loss: 0.56800818443298343\n",
      "########## Evaluation ##########\n",
      "Timestep: 144751 Average reward is -0.0537\n",
      "INFO - Step 144893, loss: 0.52969586849212656\n",
      "########## Evaluation ##########\n",
      "Timestep: 144893 Average reward is -0.0441\n",
      "INFO - Step 144946, loss: 0.36954510211944584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 145041, loss: 0.46238833665847785\n",
      "########## Evaluation ##########\n",
      "Timestep: 145041 Average reward is -0.0539\n",
      "INFO - Step 145200, loss: 0.49958604574203497\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 145202, loss: 0.48040345311164856\n",
      "########## Evaluation ##########\n",
      "Timestep: 145202 Average reward is -0.0598\n",
      "INFO - Step 145340, loss: 0.66955089569091874\n",
      "########## Evaluation ##########\n",
      "Timestep: 145340 Average reward is -0.0692\n",
      "INFO - Step 145482, loss: 0.52363812923431467\n",
      "########## Evaluation ##########\n",
      "Timestep: 145482 Average reward is -0.0566\n",
      "INFO - Step 145623, loss: 0.70788139104843144\n",
      "########## Evaluation ##########\n",
      "Timestep: 145623 Average reward is -0.0722\n",
      "INFO - Step 145765, loss: 0.78978329896926887\n",
      "########## Evaluation ##########\n",
      "Timestep: 145765 Average reward is -0.0379\n",
      "INFO - Step 145912, loss: 0.53200811147689824\n",
      "########## Evaluation ##########\n",
      "Timestep: 145912 Average reward is -0.05\n",
      "INFO - Step 146064, loss: 0.71295547485351564\n",
      "########## Evaluation ##########\n",
      "Timestep: 146064 Average reward is -0.0461\n",
      "INFO - Step 146200, loss: 0.34039738774299627\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 146217, loss: 0.42791339755058293\n",
      "########## Evaluation ##########\n",
      "Timestep: 146217 Average reward is -0.0553\n",
      "INFO - Step 146355, loss: 0.61110252141952515\n",
      "########## Evaluation ##########\n",
      "Timestep: 146355 Average reward is -0.0634\n",
      "INFO - Step 146414, loss: 0.51418298482894967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 146506, loss: 0.51431256532669074\n",
      "########## Evaluation ##########\n",
      "Timestep: 146506 Average reward is -0.0707\n",
      "INFO - Step 146664, loss: 0.36141109466552734\n",
      "########## Evaluation ##########\n",
      "Timestep: 146664 Average reward is -0.0717\n",
      "INFO - Step 146811, loss: 0.56521242856979375\n",
      "########## Evaluation ##########\n",
      "Timestep: 146811 Average reward is -0.0556\n",
      "INFO - Step 146960, loss: 0.54499763250350956\n",
      "########## Evaluation ##########\n",
      "Timestep: 146960 Average reward is -0.0654\n",
      "INFO - Step 147109, loss: 0.53000694513320925\n",
      "########## Evaluation ##########\n",
      "Timestep: 147109 Average reward is -0.0572\n",
      "INFO - Step 147200, loss: 0.39128875732421875\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 147251, loss: 0.68242931365966877\n",
      "########## Evaluation ##########\n",
      "Timestep: 147251 Average reward is -0.0725\n",
      "INFO - Step 147400, loss: 0.57760906219482427\n",
      "########## Evaluation ##########\n",
      "Timestep: 147400 Average reward is -0.0708\n",
      "INFO - Step 147543, loss: 0.42184376716613775\n",
      "########## Evaluation ##########\n",
      "Timestep: 147543 Average reward is -0.0711\n",
      "INFO - Step 147689, loss: 0.58156549930572514\n",
      "########## Evaluation ##########\n",
      "Timestep: 147689 Average reward is -0.0626\n",
      "INFO - Step 147837, loss: 0.41771316528320315\n",
      "########## Evaluation ##########\n",
      "Timestep: 147837 Average reward is -0.0716\n",
      "INFO - Step 147900, loss: 0.52053952217102056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 147979, loss: 0.47035878896713257\n",
      "########## Evaluation ##########\n",
      "Timestep: 147979 Average reward is -0.0692\n",
      "INFO - Step 148140, loss: 0.42808228731155396\n",
      "########## Evaluation ##########\n",
      "Timestep: 148140 Average reward is -0.0665\n",
      "INFO - Step 148200, loss: 0.54018217325210577\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 148295, loss: 0.53777819871902476\n",
      "########## Evaluation ##########\n",
      "Timestep: 148295 Average reward is -0.0539\n",
      "INFO - Step 148444, loss: 0.27758455276489265\n",
      "########## Evaluation ##########\n",
      "Timestep: 148444 Average reward is -0.0673\n",
      "INFO - Step 148589, loss: 0.49546515941619873\n",
      "########## Evaluation ##########\n",
      "Timestep: 148589 Average reward is -0.0632\n",
      "INFO - Step 148725, loss: 0.42980456352233887\n",
      "########## Evaluation ##########\n",
      "Timestep: 148725 Average reward is -0.0746\n",
      "INFO - Step 148866, loss: 0.46531027555465754\n",
      "########## Evaluation ##########\n",
      "Timestep: 148866 Average reward is -0.0481\n",
      "INFO - Step 149013, loss: 0.55599606037139895\n",
      "########## Evaluation ##########\n",
      "Timestep: 149013 Average reward is -0.0714\n",
      "INFO - Step 149159, loss: 0.49781262874603273\n",
      "########## Evaluation ##########\n",
      "Timestep: 149159 Average reward is -0.0637\n",
      "INFO - Step 149200, loss: 0.55288100242614756\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 149314, loss: 0.44603455066680914\n",
      "########## Evaluation ##########\n",
      "Timestep: 149314 Average reward is -0.0605\n",
      "INFO - Step 149368, loss: 0.63100743293762215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 149459, loss: 0.53756630420684815\n",
      "########## Evaluation ##########\n",
      "Timestep: 149459 Average reward is -0.0513\n",
      "INFO - Step 149607, loss: 0.58255898952484134\n",
      "########## Evaluation ##########\n",
      "Timestep: 149607 Average reward is -0.0534\n",
      "INFO - Step 149752, loss: 0.50732445716857915\n",
      "########## Evaluation ##########\n",
      "Timestep: 149752 Average reward is -0.0625\n",
      "INFO - Step 149894, loss: 0.58972597122192384\n",
      "########## Evaluation ##########\n",
      "Timestep: 149894 Average reward is -0.0733\n",
      "INFO - Step 150039, loss: 0.59409987926483155\n",
      "########## Evaluation ##########\n",
      "Timestep: 150039 Average reward is -0.0545\n",
      "INFO - Step 150181, loss: 0.65509796142578126\n",
      "########## Evaluation ##########\n",
      "Timestep: 150181 Average reward is -0.0723\n",
      "INFO - Step 150200, loss: 0.63263845443725593\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 150331, loss: 0.61679029464721683\n",
      "########## Evaluation ##########\n",
      "Timestep: 150331 Average reward is -0.0526\n",
      "INFO - Step 150475, loss: 0.43826976418495185\n",
      "########## Evaluation ##########\n",
      "Timestep: 150475 Average reward is -0.0814\n",
      "INFO - Step 150614, loss: 0.64106214046478274\n",
      "########## Evaluation ##########\n",
      "Timestep: 150614 Average reward is -0.0661\n",
      "INFO - Step 150764, loss: 0.38131707906723026\n",
      "########## Evaluation ##########\n",
      "Timestep: 150764 Average reward is -0.0664\n",
      "INFO - Step 150817, loss: 0.53303825855255133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 150908, loss: 0.76791036128997834\n",
      "########## Evaluation ##########\n",
      "Timestep: 150908 Average reward is -0.0661\n",
      "INFO - Step 151058, loss: 0.35899001359939575\n",
      "########## Evaluation ##########\n",
      "Timestep: 151058 Average reward is -0.0576\n",
      "INFO - Step 151200, loss: 0.57595258951187137\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 151207, loss: 0.5160151124000549\n",
      "########## Evaluation ##########\n",
      "Timestep: 151207 Average reward is -0.0686\n",
      "INFO - Step 151356, loss: 0.45569089055061346\n",
      "########## Evaluation ##########\n",
      "Timestep: 151356 Average reward is -0.0529\n",
      "INFO - Step 151498, loss: 0.63509863615036013\n",
      "########## Evaluation ##########\n",
      "Timestep: 151498 Average reward is -0.07\n",
      "INFO - Step 151638, loss: 0.36997717618942263\n",
      "########## Evaluation ##########\n",
      "Timestep: 151638 Average reward is -0.0601\n",
      "INFO - Step 151796, loss: 0.37494963407516483\n",
      "########## Evaluation ##########\n",
      "Timestep: 151796 Average reward is -0.0815\n",
      "INFO - Step 151941, loss: 0.48037457466125493\n",
      "########## Evaluation ##########\n",
      "Timestep: 151941 Average reward is -0.0633\n",
      "INFO - Step 152096, loss: 0.35391762852668766\n",
      "########## Evaluation ##########\n",
      "Timestep: 152096 Average reward is -0.035\n",
      "INFO - Step 152200, loss: 0.76010918617248543\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 152240, loss: 0.62636733055114754\n",
      "########## Evaluation ##########\n",
      "Timestep: 152240 Average reward is -0.0677\n",
      "INFO - Step 152285, loss: 0.67451155185699467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 152386, loss: 0.56518197059631355\n",
      "########## Evaluation ##########\n",
      "Timestep: 152386 Average reward is -0.0526\n",
      "INFO - Step 152540, loss: 0.31253355741500854\n",
      "########## Evaluation ##########\n",
      "Timestep: 152540 Average reward is -0.0514\n",
      "INFO - Step 152688, loss: 0.48731714487075806\n",
      "########## Evaluation ##########\n",
      "Timestep: 152688 Average reward is -0.0509\n",
      "INFO - Step 152838, loss: 0.39384818077087474\n",
      "########## Evaluation ##########\n",
      "Timestep: 152838 Average reward is -0.0813\n",
      "INFO - Step 152979, loss: 0.47262632846832275\n",
      "########## Evaluation ##########\n",
      "Timestep: 152979 Average reward is -0.0773\n",
      "INFO - Step 153125, loss: 0.65897142887115483\n",
      "########## Evaluation ##########\n",
      "Timestep: 153125 Average reward is -0.0591\n",
      "INFO - Step 153200, loss: 0.58718991279602057\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 153275, loss: 0.39759731292724617\n",
      "########## Evaluation ##########\n",
      "Timestep: 153275 Average reward is -0.063\n",
      "INFO - Step 153422, loss: 0.49959355592727664\n",
      "########## Evaluation ##########\n",
      "Timestep: 153422 Average reward is -0.0574\n",
      "INFO - Step 153576, loss: 0.47471445798873997\n",
      "########## Evaluation ##########\n",
      "Timestep: 153576 Average reward is -0.0462\n",
      "INFO - Step 153721, loss: 0.57005453109741217\n",
      "########## Evaluation ##########\n",
      "Timestep: 153721 Average reward is -0.0792\n",
      "INFO - Step 153763, loss: 0.51998555660247893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 153871, loss: 0.50641638040542684\n",
      "########## Evaluation ##########\n",
      "Timestep: 153871 Average reward is -0.0646\n",
      "INFO - Step 154025, loss: 0.67287647724151613\n",
      "########## Evaluation ##########\n",
      "Timestep: 154025 Average reward is -0.0515\n",
      "INFO - Step 154172, loss: 0.41248184442520143\n",
      "########## Evaluation ##########\n",
      "Timestep: 154172 Average reward is -0.0671\n",
      "INFO - Step 154200, loss: 0.52751290798187267\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 154325, loss: 0.56167650222778327\n",
      "########## Evaluation ##########\n",
      "Timestep: 154325 Average reward is -0.0531\n",
      "INFO - Step 154475, loss: 0.45680829882621765\n",
      "########## Evaluation ##########\n",
      "Timestep: 154475 Average reward is -0.0672\n",
      "INFO - Step 154625, loss: 0.52573835849761964\n",
      "########## Evaluation ##########\n",
      "Timestep: 154625 Average reward is -0.0519\n",
      "INFO - Step 154775, loss: 0.45115858316421514\n",
      "########## Evaluation ##########\n",
      "Timestep: 154775 Average reward is -0.072\n",
      "INFO - Step 154917, loss: 0.53863924741745657\n",
      "########## Evaluation ##########\n",
      "Timestep: 154917 Average reward is -0.0707\n",
      "INFO - Step 155057, loss: 0.57659792900085457\n",
      "########## Evaluation ##########\n",
      "Timestep: 155057 Average reward is -0.061\n",
      "INFO - Step 155200, loss: 0.48033183813095095\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 155202, loss: 0.5149117112159729\n",
      "########## Evaluation ##########\n",
      "Timestep: 155202 Average reward is -0.0454\n",
      "INFO - Step 155256, loss: 0.50061100721359253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 155353, loss: 0.36417400836944585\n",
      "########## Evaluation ##########\n",
      "Timestep: 155353 Average reward is -0.0802\n",
      "INFO - Step 155493, loss: 0.46801236271858215\n",
      "########## Evaluation ##########\n",
      "Timestep: 155493 Average reward is -0.0676\n",
      "INFO - Step 155641, loss: 0.53305542469024666\n",
      "########## Evaluation ##########\n",
      "Timestep: 155641 Average reward is -0.065\n",
      "INFO - Step 155781, loss: 0.40838611125946045\n",
      "########## Evaluation ##########\n",
      "Timestep: 155781 Average reward is -0.055\n",
      "INFO - Step 155918, loss: 0.49591082334518436\n",
      "########## Evaluation ##########\n",
      "Timestep: 155918 Average reward is -0.0691\n",
      "INFO - Step 156056, loss: 0.46523904800415045\n",
      "########## Evaluation ##########\n",
      "Timestep: 156056 Average reward is -0.0381\n",
      "INFO - Step 156200, loss: 0.64042896032333375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 156203, loss: 0.43583959341049194\n",
      "########## Evaluation ##########\n",
      "Timestep: 156203 Average reward is -0.0631\n",
      "INFO - Step 156364, loss: 0.43105635046958923\n",
      "########## Evaluation ##########\n",
      "Timestep: 156364 Average reward is -0.0463\n",
      "INFO - Step 156516, loss: 0.51993757486343386\n",
      "########## Evaluation ##########\n",
      "Timestep: 156516 Average reward is -0.0657\n",
      "INFO - Step 156669, loss: 0.27457389235496524\n",
      "########## Evaluation ##########\n",
      "Timestep: 156669 Average reward is -0.0638\n",
      "INFO - Step 156725, loss: 0.30351740121841436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 156813, loss: 0.44258779287338257\n",
      "########## Evaluation ##########\n",
      "Timestep: 156813 Average reward is -0.062\n",
      "INFO - Step 156964, loss: 0.65825819969177254\n",
      "########## Evaluation ##########\n",
      "Timestep: 156964 Average reward is -0.0722\n",
      "INFO - Step 157118, loss: 0.50768017768859863\n",
      "########## Evaluation ##########\n",
      "Timestep: 157118 Average reward is -0.0503\n",
      "INFO - Step 157200, loss: 0.41816478967666626\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 157269, loss: 0.66216385364532474\n",
      "########## Evaluation ##########\n",
      "Timestep: 157269 Average reward is -0.0533\n",
      "INFO - Step 157425, loss: 0.59060752391815195\n",
      "########## Evaluation ##########\n",
      "Timestep: 157425 Average reward is -0.0524\n",
      "INFO - Step 157575, loss: 0.42698866128921513\n",
      "########## Evaluation ##########\n",
      "Timestep: 157575 Average reward is -0.0657\n",
      "INFO - Step 157725, loss: 0.53187173604965217\n",
      "########## Evaluation ##########\n",
      "Timestep: 157725 Average reward is -0.0646\n",
      "INFO - Step 157872, loss: 0.39910989999771126\n",
      "########## Evaluation ##########\n",
      "Timestep: 157872 Average reward is -0.0719\n",
      "INFO - Step 158009, loss: 0.33432421088218697\n",
      "########## Evaluation ##########\n",
      "Timestep: 158009 Average reward is -0.0593\n",
      "INFO - Step 158155, loss: 0.47890403866767883\n",
      "########## Evaluation ##########\n",
      "Timestep: 158155 Average reward is -0.0569\n",
      "INFO - Step 158200, loss: 0.47466459870338447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 158297, loss: 0.49646681547164917\n",
      "########## Evaluation ##########\n",
      "Timestep: 158297 Average reward is -0.0434\n",
      "INFO - Step 158435, loss: 0.48127609491348267\n",
      "########## Evaluation ##########\n",
      "Timestep: 158435 Average reward is -0.0444\n",
      "INFO - Step 158586, loss: 0.50642621517181423\n",
      "########## Evaluation ##########\n",
      "Timestep: 158586 Average reward is -0.0733\n",
      "INFO - Step 158745, loss: 0.57888054847717293\n",
      "########## Evaluation ##########\n",
      "Timestep: 158745 Average reward is -0.0613\n",
      "INFO - Step 158899, loss: 0.55024468898773193\n",
      "########## Evaluation ##########\n",
      "Timestep: 158899 Average reward is -0.054\n",
      "INFO - Step 159047, loss: 0.53936815261840825\n",
      "########## Evaluation ##########\n",
      "Timestep: 159047 Average reward is -0.0644\n",
      "INFO - Step 159198, loss: 0.53053319454193126\n",
      "########## Evaluation ##########\n",
      "Timestep: 159198 Average reward is -0.0667\n",
      "INFO - Step 159200, loss: 0.38016289472579956\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 159328, loss: 0.65535378456115723\n",
      "########## Evaluation ##########\n",
      "Timestep: 159328 Average reward is -0.0646\n",
      "INFO - Step 159467, loss: 0.69287616014480594\n",
      "########## Evaluation ##########\n",
      "Timestep: 159467 Average reward is -0.0716\n",
      "INFO - Step 159618, loss: 0.35448718070983887\n",
      "########## Evaluation ##########\n",
      "Timestep: 159618 Average reward is -0.073\n",
      "INFO - Step 159670, loss: 0.44759947061538696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 159758, loss: 0.34375989437103276\n",
      "########## Evaluation ##########\n",
      "Timestep: 159758 Average reward is -0.0715\n",
      "INFO - Step 159911, loss: 0.45554870367050174\n",
      "########## Evaluation ##########\n",
      "Timestep: 159911 Average reward is -0.0493\n",
      "INFO - Step 160048, loss: 0.50078207254409794\n",
      "########## Evaluation ##########\n",
      "Timestep: 160048 Average reward is -0.0639\n",
      "INFO - Step 160196, loss: 0.74214351177215585\n",
      "########## Evaluation ##########\n",
      "Timestep: 160196 Average reward is -0.0699\n",
      "INFO - Step 160200, loss: 0.42994496226310736\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 160337, loss: 0.43091046810150146\n",
      "########## Evaluation ##########\n",
      "Timestep: 160337 Average reward is -0.0748\n",
      "INFO - Step 160493, loss: 0.59643054008483896\n",
      "########## Evaluation ##########\n",
      "Timestep: 160493 Average reward is -0.067\n",
      "INFO - Step 160626, loss: 0.55259305238723754\n",
      "########## Evaluation ##########\n",
      "Timestep: 160626 Average reward is -0.0861\n",
      "INFO - Step 160772, loss: 0.33512321114540164\n",
      "########## Evaluation ##########\n",
      "Timestep: 160772 Average reward is -0.0659\n",
      "INFO - Step 160904, loss: 0.54910677671432534\n",
      "########## Evaluation ##########\n",
      "Timestep: 160904 Average reward is -0.083\n",
      "INFO - Step 161045, loss: 0.37102735042572024\n",
      "########## Evaluation ##########\n",
      "Timestep: 161045 Average reward is -0.0742\n",
      "INFO - Step 161085, loss: 0.51394045352935795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 161189, loss: 0.55613952875137337\n",
      "########## Evaluation ##########\n",
      "Timestep: 161189 Average reward is -0.0712\n",
      "INFO - Step 161200, loss: 0.45534420013427734\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 161327, loss: 0.56281697750091553\n",
      "########## Evaluation ##########\n",
      "Timestep: 161327 Average reward is -0.0828\n",
      "INFO - Step 161465, loss: 0.46022015810012824\n",
      "########## Evaluation ##########\n",
      "Timestep: 161465 Average reward is -0.0547\n",
      "INFO - Step 161613, loss: 0.39802980422973633\n",
      "########## Evaluation ##########\n",
      "Timestep: 161613 Average reward is -0.0811\n",
      "INFO - Step 161758, loss: 0.58430111408233647\n",
      "########## Evaluation ##########\n",
      "Timestep: 161758 Average reward is -0.0794\n",
      "INFO - Step 161896, loss: 0.58853983879089365\n",
      "########## Evaluation ##########\n",
      "Timestep: 161896 Average reward is -0.0769\n",
      "INFO - Step 162048, loss: 0.49803191423416143\n",
      "########## Evaluation ##########\n",
      "Timestep: 162048 Average reward is -0.0715\n",
      "INFO - Step 162191, loss: 0.54577028751373294\n",
      "########## Evaluation ##########\n",
      "Timestep: 162191 Average reward is -0.0561\n",
      "INFO - Step 162200, loss: 0.44859257340431213\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 162334, loss: 0.65791666507720956\n",
      "########## Evaluation ##########\n",
      "Timestep: 162334 Average reward is -0.0709\n",
      "INFO - Step 162471, loss: 0.48403716087341314\n",
      "########## Evaluation ##########\n",
      "Timestep: 162471 Average reward is -0.0755\n",
      "INFO - Step 162526, loss: 0.63318401575088546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 162614, loss: 0.56357538700103766\n",
      "########## Evaluation ##########\n",
      "Timestep: 162614 Average reward is -0.0752\n",
      "INFO - Step 162780, loss: 0.34978640079498294\n",
      "########## Evaluation ##########\n",
      "Timestep: 162780 Average reward is -0.0651\n",
      "INFO - Step 162931, loss: 0.41322541236877445\n",
      "########## Evaluation ##########\n",
      "Timestep: 162931 Average reward is -0.0609\n",
      "INFO - Step 163078, loss: 0.39609330892562866\n",
      "########## Evaluation ##########\n",
      "Timestep: 163078 Average reward is -0.0441\n",
      "INFO - Step 163200, loss: 0.59611451625823975\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 163209, loss: 0.47621375322341924\n",
      "########## Evaluation ##########\n",
      "Timestep: 163209 Average reward is -0.0592\n",
      "INFO - Step 163351, loss: 0.53280240297317553\n",
      "########## Evaluation ##########\n",
      "Timestep: 163351 Average reward is -0.0425\n",
      "INFO - Step 163493, loss: 0.66979247331619265\n",
      "########## Evaluation ##########\n",
      "Timestep: 163493 Average reward is -0.0541\n",
      "INFO - Step 163627, loss: 0.50692820549011236\n",
      "########## Evaluation ##########\n",
      "Timestep: 163627 Average reward is -0.0728\n",
      "INFO - Step 163764, loss: 0.48202088475227356\n",
      "########## Evaluation ##########\n",
      "Timestep: 163764 Average reward is -0.0607\n",
      "INFO - Step 163902, loss: 0.61550319194793757\n",
      "########## Evaluation ##########\n",
      "Timestep: 163902 Average reward is -0.0489\n",
      "INFO - Step 163946, loss: 0.45222234725952157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 164048, loss: 0.33968612551689155\n",
      "########## Evaluation ##########\n",
      "Timestep: 164048 Average reward is -0.0744\n",
      "INFO - Step 164188, loss: 0.46862599253654483\n",
      "########## Evaluation ##########\n",
      "Timestep: 164188 Average reward is -0.0751\n",
      "INFO - Step 164200, loss: 0.42529553174972534\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 164315, loss: 0.36423835158348083\n",
      "########## Evaluation ##########\n",
      "Timestep: 164315 Average reward is -0.0802\n",
      "INFO - Step 164460, loss: 0.79109001159667976\n",
      "########## Evaluation ##########\n",
      "Timestep: 164460 Average reward is -0.0765\n",
      "INFO - Step 164606, loss: 0.58646088838577274\n",
      "########## Evaluation ##########\n",
      "Timestep: 164606 Average reward is -0.0738\n",
      "INFO - Step 164749, loss: 0.53934276103973397\n",
      "########## Evaluation ##########\n",
      "Timestep: 164749 Average reward is -0.0786\n",
      "INFO - Step 164880, loss: 0.37657818198204046\n",
      "########## Evaluation ##########\n",
      "Timestep: 164880 Average reward is -0.0781\n",
      "INFO - Step 165020, loss: 0.49768841266632085\n",
      "########## Evaluation ##########\n",
      "Timestep: 165020 Average reward is -0.0777\n",
      "INFO - Step 165155, loss: 0.58148300647735664\n",
      "########## Evaluation ##########\n",
      "Timestep: 165155 Average reward is -0.0669\n",
      "INFO - Step 165200, loss: 0.58293831348419197\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 165290, loss: 0.60206103324890147\n",
      "########## Evaluation ##########\n",
      "Timestep: 165290 Average reward is -0.0785\n",
      "INFO - Step 165346, loss: 0.56759655475616465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 165437, loss: 0.61436277627944956\n",
      "########## Evaluation ##########\n",
      "Timestep: 165437 Average reward is -0.0741\n",
      "INFO - Step 165584, loss: 0.39011836051940927\n",
      "########## Evaluation ##########\n",
      "Timestep: 165584 Average reward is -0.0608\n",
      "INFO - Step 165732, loss: 0.46268922090530396\n",
      "########## Evaluation ##########\n",
      "Timestep: 165732 Average reward is -0.06\n",
      "INFO - Step 165878, loss: 0.51510888338088993\n",
      "########## Evaluation ##########\n",
      "Timestep: 165878 Average reward is -0.0547\n",
      "INFO - Step 166019, loss: 0.51325994729995735\n",
      "########## Evaluation ##########\n",
      "Timestep: 166019 Average reward is -0.0544\n",
      "INFO - Step 166160, loss: 0.47273159027099616\n",
      "########## Evaluation ##########\n",
      "Timestep: 166160 Average reward is -0.0567\n",
      "INFO - Step 166200, loss: 0.66529196500778297\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 166296, loss: 0.31546336412429815\n",
      "########## Evaluation ##########\n",
      "Timestep: 166296 Average reward is -0.0644\n",
      "INFO - Step 166434, loss: 0.50022661685943627\n",
      "########## Evaluation ##########\n",
      "Timestep: 166434 Average reward is -0.0773\n",
      "INFO - Step 166575, loss: 0.57033550739288336\n",
      "########## Evaluation ##########\n",
      "Timestep: 166575 Average reward is -0.0612\n",
      "INFO - Step 166727, loss: 0.59847044944763185\n",
      "########## Evaluation ##########\n",
      "Timestep: 166727 Average reward is -0.0724\n",
      "INFO - Step 166778, loss: 0.43221908807754517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 166873, loss: 0.48706495761871346\n",
      "########## Evaluation ##########\n",
      "Timestep: 166873 Average reward is -0.0878\n",
      "INFO - Step 167020, loss: 0.53105378150939943\n",
      "########## Evaluation ##########\n",
      "Timestep: 167020 Average reward is -0.066\n",
      "INFO - Step 167170, loss: 0.62259149551391683\n",
      "########## Evaluation ##########\n",
      "Timestep: 167170 Average reward is -0.0533\n",
      "INFO - Step 167200, loss: 0.44086587429046634\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 167318, loss: 0.62817144393920945\n",
      "########## Evaluation ##########\n",
      "Timestep: 167318 Average reward is -0.0667\n",
      "INFO - Step 167460, loss: 0.49573254585266113\n",
      "########## Evaluation ##########\n",
      "Timestep: 167460 Average reward is -0.067\n",
      "INFO - Step 167606, loss: 0.57588237524032594\n",
      "########## Evaluation ##########\n",
      "Timestep: 167606 Average reward is -0.0725\n",
      "INFO - Step 167758, loss: 0.51696264743804933\n",
      "########## Evaluation ##########\n",
      "Timestep: 167758 Average reward is -0.0652\n",
      "INFO - Step 167916, loss: 0.47723507881164554\n",
      "########## Evaluation ##########\n",
      "Timestep: 167916 Average reward is -0.0659\n",
      "INFO - Step 168059, loss: 0.42546844482421875\n",
      "########## Evaluation ##########\n",
      "Timestep: 168059 Average reward is -0.0639\n",
      "INFO - Step 168200, loss: 0.49682354927062996\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 168201, loss: 0.6513303518295288\n",
      "########## Evaluation ##########\n",
      "Timestep: 168201 Average reward is -0.0591\n",
      "INFO - Step 168254, loss: 0.40660214424133354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 168344, loss: 0.50873315334320076\n",
      "########## Evaluation ##########\n",
      "Timestep: 168344 Average reward is -0.0718\n",
      "INFO - Step 168487, loss: 0.56937211751937877\n",
      "########## Evaluation ##########\n",
      "Timestep: 168487 Average reward is -0.0679\n",
      "INFO - Step 168629, loss: 0.64025866985321046\n",
      "########## Evaluation ##########\n",
      "Timestep: 168629 Average reward is -0.0662\n",
      "INFO - Step 168779, loss: 0.48739618062973025\n",
      "########## Evaluation ##########\n",
      "Timestep: 168779 Average reward is -0.0575\n",
      "INFO - Step 168918, loss: 0.57292604446411134\n",
      "########## Evaluation ##########\n",
      "Timestep: 168918 Average reward is -0.0612\n",
      "INFO - Step 169061, loss: 0.68135029077529916\n",
      "########## Evaluation ##########\n",
      "Timestep: 169061 Average reward is -0.0688\n",
      "INFO - Step 169200, loss: 0.46977311372756964\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 169212, loss: 0.72007596492767336\n",
      "########## Evaluation ##########\n",
      "Timestep: 169212 Average reward is -0.0556\n",
      "INFO - Step 169350, loss: 0.49523237347602844\n",
      "########## Evaluation ##########\n",
      "Timestep: 169350 Average reward is -0.0549\n",
      "INFO - Step 169487, loss: 0.50210070610046393\n",
      "########## Evaluation ##########\n",
      "Timestep: 169487 Average reward is -0.068\n",
      "INFO - Step 169624, loss: 0.39221391081812636\n",
      "########## Evaluation ##########\n",
      "Timestep: 169624 Average reward is -0.0648\n",
      "INFO - Step 169679, loss: 0.66213822364807134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 169773, loss: 0.58791410923004155\n",
      "########## Evaluation ##########\n",
      "Timestep: 169773 Average reward is -0.0695\n",
      "INFO - Step 169924, loss: 0.60281002521514897\n",
      "########## Evaluation ##########\n",
      "Timestep: 169924 Average reward is -0.0595\n",
      "INFO - Step 170069, loss: 0.32717663049697876\n",
      "########## Evaluation ##########\n",
      "Timestep: 170069 Average reward is -0.0679\n",
      "INFO - Step 170200, loss: 0.57165253162384035\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 170224, loss: 0.61333215236663825\n",
      "########## Evaluation ##########\n",
      "Timestep: 170224 Average reward is -0.0603\n",
      "INFO - Step 170371, loss: 0.49332919716835024\n",
      "########## Evaluation ##########\n",
      "Timestep: 170371 Average reward is -0.0657\n",
      "INFO - Step 170515, loss: 0.62165498733520517\n",
      "########## Evaluation ##########\n",
      "Timestep: 170515 Average reward is -0.0496\n",
      "INFO - Step 170667, loss: 0.45942676067352295\n",
      "########## Evaluation ##########\n",
      "Timestep: 170667 Average reward is -0.0673\n",
      "INFO - Step 170807, loss: 0.50836253166198734\n",
      "########## Evaluation ##########\n",
      "Timestep: 170807 Average reward is -0.0588\n",
      "INFO - Step 170946, loss: 0.40025550127029425\n",
      "########## Evaluation ##########\n",
      "Timestep: 170946 Average reward is -0.0654\n",
      "INFO - Step 171101, loss: 0.52994143962860114\n",
      "########## Evaluation ##########\n",
      "Timestep: 171101 Average reward is -0.0615\n",
      "INFO - Step 171156, loss: 0.47152820229530334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 171200, loss: 0.45027458667755127\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 171255, loss: 0.59791648387908944\n",
      "########## Evaluation ##########\n",
      "Timestep: 171255 Average reward is -0.0545\n",
      "INFO - Step 171394, loss: 0.56147778034210225\n",
      "########## Evaluation ##########\n",
      "Timestep: 171394 Average reward is -0.0539\n",
      "INFO - Step 171561, loss: 0.57205229997634896\n",
      "########## Evaluation ##########\n",
      "Timestep: 171561 Average reward is -0.0562\n",
      "INFO - Step 171714, loss: 0.46099704504013067\n",
      "########## Evaluation ##########\n",
      "Timestep: 171714 Average reward is -0.0644\n",
      "INFO - Step 171856, loss: 0.39808756113052375\n",
      "########## Evaluation ##########\n",
      "Timestep: 171856 Average reward is -0.0651\n",
      "INFO - Step 172004, loss: 0.45818719267845154\n",
      "########## Evaluation ##########\n",
      "Timestep: 172004 Average reward is -0.0682\n",
      "INFO - Step 172155, loss: 0.54305773973464977\n",
      "########## Evaluation ##########\n",
      "Timestep: 172155 Average reward is -0.0489\n",
      "INFO - Step 172200, loss: 0.61686503887176515\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 172296, loss: 0.46805718541145325\n",
      "########## Evaluation ##########\n",
      "Timestep: 172296 Average reward is -0.0764\n",
      "INFO - Step 172448, loss: 0.58196079730987556\n",
      "########## Evaluation ##########\n",
      "Timestep: 172448 Average reward is -0.0673\n",
      "INFO - Step 172593, loss: 0.48504588007926946\n",
      "########## Evaluation ##########\n",
      "Timestep: 172593 Average reward is -0.0692\n",
      "INFO - Step 172645, loss: 0.35983595252037056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 172748, loss: 0.65860354900360116\n",
      "########## Evaluation ##########\n",
      "Timestep: 172748 Average reward is -0.0422\n",
      "INFO - Step 172889, loss: 0.50607895851135256\n",
      "########## Evaluation ##########\n",
      "Timestep: 172889 Average reward is -0.0654\n",
      "INFO - Step 173033, loss: 0.66015458106994637\n",
      "########## Evaluation ##########\n",
      "Timestep: 173033 Average reward is -0.0538\n",
      "INFO - Step 173181, loss: 0.50200188159942637\n",
      "########## Evaluation ##########\n",
      "Timestep: 173181 Average reward is -0.0634\n",
      "INFO - Step 173200, loss: 0.70843034982681277\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 173342, loss: 0.48517018556594857\n",
      "########## Evaluation ##########\n",
      "Timestep: 173342 Average reward is -0.0734\n",
      "INFO - Step 173481, loss: 0.44734388589859016\n",
      "########## Evaluation ##########\n",
      "Timestep: 173481 Average reward is -0.064\n",
      "INFO - Step 173633, loss: 0.63835722208023077\n",
      "########## Evaluation ##########\n",
      "Timestep: 173633 Average reward is -0.0455\n",
      "INFO - Step 173787, loss: 0.68522012233734135\n",
      "########## Evaluation ##########\n",
      "Timestep: 173787 Average reward is -0.0618\n",
      "INFO - Step 173933, loss: 0.37790477275848396\n",
      "########## Evaluation ##########\n",
      "Timestep: 173933 Average reward is -0.0722\n",
      "INFO - Step 174087, loss: 0.64080464839935383\n",
      "########## Evaluation ##########\n",
      "Timestep: 174087 Average reward is -0.0695\n",
      "INFO - Step 174145, loss: 0.61966860294342043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 174200, loss: 0.66972720623016364\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 174229, loss: 0.51798760890960696\n",
      "########## Evaluation ##########\n",
      "Timestep: 174229 Average reward is -0.0738\n",
      "INFO - Step 174363, loss: 0.44291496276855475\n",
      "########## Evaluation ##########\n",
      "Timestep: 174363 Average reward is -0.0556\n",
      "INFO - Step 174499, loss: 0.50193405151367194\n",
      "########## Evaluation ##########\n",
      "Timestep: 174499 Average reward is -0.0487\n",
      "INFO - Step 174660, loss: 0.45904329419136055\n",
      "########## Evaluation ##########\n",
      "Timestep: 174660 Average reward is -0.0711\n",
      "INFO - Step 174803, loss: 0.56144070625305183\n",
      "########## Evaluation ##########\n",
      "Timestep: 174803 Average reward is -0.0518\n",
      "INFO - Step 174944, loss: 0.33515679836273193\n",
      "########## Evaluation ##########\n",
      "Timestep: 174944 Average reward is -0.0544\n",
      "INFO - Step 175103, loss: 0.53191840648651124\n",
      "########## Evaluation ##########\n",
      "Timestep: 175103 Average reward is -0.0717\n",
      "INFO - Step 175200, loss: 0.45725256204605126\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 175254, loss: 0.51395112276077273\n",
      "########## Evaluation ##########\n",
      "Timestep: 175254 Average reward is -0.0663\n",
      "INFO - Step 175421, loss: 0.54313361644744875\n",
      "########## Evaluation ##########\n",
      "Timestep: 175421 Average reward is -0.0473\n",
      "INFO - Step 175586, loss: 0.38269504904747017\n",
      "########## Evaluation ##########\n",
      "Timestep: 175586 Average reward is -0.0574\n",
      "INFO - Step 175624, loss: 0.37071990966796875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 175743, loss: 0.53092157840728766\n",
      "########## Evaluation ##########\n",
      "Timestep: 175743 Average reward is -0.0698\n",
      "INFO - Step 175909, loss: 0.64929270744323734\n",
      "########## Evaluation ##########\n",
      "Timestep: 175909 Average reward is -0.072\n",
      "INFO - Step 176062, loss: 0.63719242811203685\n",
      "########## Evaluation ##########\n",
      "Timestep: 176062 Average reward is -0.0581\n",
      "INFO - Step 176200, loss: 0.42528009414672853\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 176209, loss: 0.60005575418472295\n",
      "########## Evaluation ##########\n",
      "Timestep: 176209 Average reward is -0.0667\n",
      "INFO - Step 176361, loss: 0.55717909336090095\n",
      "########## Evaluation ##########\n",
      "Timestep: 176361 Average reward is -0.08\n",
      "INFO - Step 176517, loss: 0.59033942222595213\n",
      "########## Evaluation ##########\n",
      "Timestep: 176517 Average reward is -0.0469\n",
      "INFO - Step 176660, loss: 0.48882728815078735\n",
      "########## Evaluation ##########\n",
      "Timestep: 176660 Average reward is -0.0467\n",
      "INFO - Step 176813, loss: 0.44442558288574223\n",
      "########## Evaluation ##########\n",
      "Timestep: 176813 Average reward is -0.0529\n",
      "INFO - Step 176953, loss: 0.43904510140419006\n",
      "########## Evaluation ##########\n",
      "Timestep: 176953 Average reward is -0.0622\n",
      "INFO - Step 177094, loss: 0.55509567260742194\n",
      "########## Evaluation ##########\n",
      "Timestep: 177094 Average reward is -0.075\n",
      "INFO - Step 177138, loss: 0.56637269258499157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 177200, loss: 0.59789967536926277\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 177248, loss: 0.48339557647705086\n",
      "########## Evaluation ##########\n",
      "Timestep: 177248 Average reward is -0.0361\n",
      "INFO - Step 177394, loss: 0.49106502532958984\n",
      "########## Evaluation ##########\n",
      "Timestep: 177394 Average reward is -0.063\n",
      "INFO - Step 177546, loss: 0.43368002772331244\n",
      "########## Evaluation ##########\n",
      "Timestep: 177546 Average reward is -0.068\n",
      "INFO - Step 177695, loss: 0.48388767242431646\n",
      "########## Evaluation ##########\n",
      "Timestep: 177695 Average reward is -0.0649\n",
      "INFO - Step 177846, loss: 0.76933717727661133\n",
      "########## Evaluation ##########\n",
      "Timestep: 177846 Average reward is -0.0646\n",
      "INFO - Step 178004, loss: 0.37690308690071106\n",
      "########## Evaluation ##########\n",
      "Timestep: 178004 Average reward is -0.0846\n",
      "INFO - Step 178144, loss: 0.61156892776489266\n",
      "########## Evaluation ##########\n",
      "Timestep: 178144 Average reward is -0.0546\n",
      "INFO - Step 178200, loss: 0.50049167871475223\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 178289, loss: 0.59237945079803474\n",
      "########## Evaluation ##########\n",
      "Timestep: 178289 Average reward is -0.0566\n",
      "INFO - Step 178429, loss: 0.38494858145713806\n",
      "########## Evaluation ##########\n",
      "Timestep: 178429 Average reward is -0.055\n",
      "INFO - Step 178593, loss: 0.44416761398315434\n",
      "########## Evaluation ##########\n",
      "Timestep: 178593 Average reward is -0.0815\n",
      "INFO - Step 178633, loss: 0.58610570430755627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 178731, loss: 0.49001553654670715\n",
      "########## Evaluation ##########\n",
      "Timestep: 178731 Average reward is -0.0664\n",
      "INFO - Step 178882, loss: 0.49557653069496155\n",
      "########## Evaluation ##########\n",
      "Timestep: 178882 Average reward is -0.0549\n",
      "INFO - Step 179023, loss: 0.52917736768722536\n",
      "########## Evaluation ##########\n",
      "Timestep: 179023 Average reward is -0.0543\n",
      "INFO - Step 179181, loss: 0.59347170591354376\n",
      "########## Evaluation ##########\n",
      "Timestep: 179181 Average reward is -0.0619\n",
      "INFO - Step 179200, loss: 0.51546663045883183\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 179337, loss: 0.54240787029266366\n",
      "########## Evaluation ##########\n",
      "Timestep: 179337 Average reward is -0.0786\n",
      "INFO - Step 179488, loss: 0.56118428707122866\n",
      "########## Evaluation ##########\n",
      "Timestep: 179488 Average reward is -0.0579\n",
      "INFO - Step 179645, loss: 0.45941516757011414\n",
      "########## Evaluation ##########\n",
      "Timestep: 179645 Average reward is -0.072\n",
      "INFO - Step 179798, loss: 0.54810333251953126\n",
      "########## Evaluation ##########\n",
      "Timestep: 179798 Average reward is -0.0509\n",
      "INFO - Step 179955, loss: 0.52608865499496467\n",
      "########## Evaluation ##########\n",
      "Timestep: 179955 Average reward is -0.077\n",
      "INFO - Step 180099, loss: 0.50998020172119143\n",
      "########## Evaluation ##########\n",
      "Timestep: 180099 Average reward is -0.0545\n",
      "INFO - Step 180144, loss: 0.54170060157775886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 180200, loss: 0.45418509840965276\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 180231, loss: 0.41210550069808964\n",
      "########## Evaluation ##########\n",
      "Timestep: 180231 Average reward is -0.0533\n",
      "INFO - Step 180373, loss: 0.52805447578430184\n",
      "########## Evaluation ##########\n",
      "Timestep: 180373 Average reward is -0.07\n",
      "INFO - Step 180533, loss: 0.38503205776214694\n",
      "########## Evaluation ##########\n",
      "Timestep: 180533 Average reward is -0.0577\n",
      "INFO - Step 180679, loss: 0.46607613563537617\n",
      "########## Evaluation ##########\n",
      "Timestep: 180679 Average reward is -0.0579\n",
      "INFO - Step 180831, loss: 0.55239975452423173\n",
      "########## Evaluation ##########\n",
      "Timestep: 180831 Average reward is -0.05\n",
      "INFO - Step 180988, loss: 0.70584225654602056\n",
      "########## Evaluation ##########\n",
      "Timestep: 180988 Average reward is -0.0559\n",
      "INFO - Step 181132, loss: 0.32815361022949224\n",
      "########## Evaluation ##########\n",
      "Timestep: 181132 Average reward is -0.0714\n",
      "INFO - Step 181200, loss: 0.54714637994766244\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 181287, loss: 0.45622465014457733\n",
      "########## Evaluation ##########\n",
      "Timestep: 181287 Average reward is -0.0607\n",
      "INFO - Step 181442, loss: 0.47517275810241754\n",
      "########## Evaluation ##########\n",
      "Timestep: 181442 Average reward is -0.0768\n",
      "INFO - Step 181606, loss: 0.57102572917938233\n",
      "########## Evaluation ##########\n",
      "Timestep: 181606 Average reward is -0.0557\n",
      "INFO - Step 181652, loss: 0.53405725955963134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 181748, loss: 0.51729387044906627\n",
      "########## Evaluation ##########\n",
      "Timestep: 181748 Average reward is -0.043\n",
      "INFO - Step 181899, loss: 0.53722494840621954\n",
      "########## Evaluation ##########\n",
      "Timestep: 181899 Average reward is -0.0538\n",
      "INFO - Step 182052, loss: 0.50098025798797616\n",
      "########## Evaluation ##########\n",
      "Timestep: 182052 Average reward is -0.0698\n",
      "INFO - Step 182200, loss: 0.86061823368072515\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 182202, loss: 0.42424970865249634\n",
      "########## Evaluation ##########\n",
      "Timestep: 182202 Average reward is -0.0667\n",
      "INFO - Step 182355, loss: 0.63017451763153084\n",
      "########## Evaluation ##########\n",
      "Timestep: 182355 Average reward is -0.0652\n",
      "INFO - Step 182504, loss: 0.43576976656913765\n",
      "########## Evaluation ##########\n",
      "Timestep: 182504 Average reward is -0.0688\n",
      "INFO - Step 182651, loss: 0.46249148249626166\n",
      "########## Evaluation ##########\n",
      "Timestep: 182651 Average reward is -0.0543\n",
      "INFO - Step 182803, loss: 0.66590899229049685\n",
      "########## Evaluation ##########\n",
      "Timestep: 182803 Average reward is -0.0613\n",
      "INFO - Step 182955, loss: 0.62693881988525394\n",
      "########## Evaluation ##########\n",
      "Timestep: 182955 Average reward is -0.0758\n",
      "INFO - Step 183107, loss: 0.58710467815399177\n",
      "########## Evaluation ##########\n",
      "Timestep: 183107 Average reward is -0.0646\n",
      "INFO - Step 183150, loss: 0.56910467147827154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 183200, loss: 0.37074366211891174\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 183268, loss: 0.38627013564109883\n",
      "########## Evaluation ##########\n",
      "Timestep: 183268 Average reward is -0.0386\n",
      "INFO - Step 183415, loss: 0.61222046613693246\n",
      "########## Evaluation ##########\n",
      "Timestep: 183415 Average reward is -0.0649\n",
      "INFO - Step 183577, loss: 0.39618161320686344\n",
      "########## Evaluation ##########\n",
      "Timestep: 183577 Average reward is -0.0832\n",
      "INFO - Step 183722, loss: 0.62387490272521974\n",
      "########## Evaluation ##########\n",
      "Timestep: 183722 Average reward is -0.0663\n",
      "INFO - Step 183880, loss: 0.58511567115783696\n",
      "########## Evaluation ##########\n",
      "Timestep: 183880 Average reward is -0.0575\n",
      "INFO - Step 184036, loss: 0.46552929282188416\n",
      "########## Evaluation ##########\n",
      "Timestep: 184036 Average reward is -0.0724\n",
      "INFO - Step 184191, loss: 0.53654307126998993\n",
      "########## Evaluation ##########\n",
      "Timestep: 184191 Average reward is -0.0696\n",
      "INFO - Step 184200, loss: 0.64246052503585827\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 184343, loss: 0.44469875097274784\n",
      "########## Evaluation ##########\n",
      "Timestep: 184343 Average reward is -0.0646\n",
      "INFO - Step 184505, loss: 0.54741573333740237\n",
      "########## Evaluation ##########\n",
      "Timestep: 184505 Average reward is -0.0504\n",
      "INFO - Step 184663, loss: 0.56915545463562016\n",
      "########## Evaluation ##########\n",
      "Timestep: 184663 Average reward is -0.0581\n",
      "INFO - Step 184693, loss: 0.35790795087814335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 184823, loss: 0.53520768880844127\n",
      "########## Evaluation ##########\n",
      "Timestep: 184823 Average reward is -0.0773\n",
      "INFO - Step 184980, loss: 0.59609448909759525\n",
      "########## Evaluation ##########\n",
      "Timestep: 184980 Average reward is -0.0523\n",
      "INFO - Step 185123, loss: 0.58396905660629274\n",
      "########## Evaluation ##########\n",
      "Timestep: 185123 Average reward is -0.0613\n",
      "INFO - Step 185200, loss: 0.50120228528976446\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 185272, loss: 0.37547469139099123\n",
      "########## Evaluation ##########\n",
      "Timestep: 185272 Average reward is -0.0577\n",
      "INFO - Step 185418, loss: 0.52576780319213875\n",
      "########## Evaluation ##########\n",
      "Timestep: 185418 Average reward is -0.0573\n",
      "INFO - Step 185558, loss: 0.47883880138397217\n",
      "########## Evaluation ##########\n",
      "Timestep: 185558 Average reward is -0.0643\n",
      "INFO - Step 185709, loss: 0.38338306546211246\n",
      "########## Evaluation ##########\n",
      "Timestep: 185709 Average reward is -0.0533\n",
      "INFO - Step 185852, loss: 0.70518946647644047\n",
      "########## Evaluation ##########\n",
      "Timestep: 185852 Average reward is -0.0756\n",
      "INFO - Step 186004, loss: 0.55967307090759287\n",
      "########## Evaluation ##########\n",
      "Timestep: 186004 Average reward is -0.0602\n",
      "INFO - Step 186154, loss: 0.40358239412307744\n",
      "########## Evaluation ##########\n",
      "Timestep: 186154 Average reward is -0.0575\n",
      "INFO - Step 186195, loss: 0.59718084335327154"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 186200, loss: 0.47605800628662117\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 186302, loss: 0.68181049823760993\n",
      "########## Evaluation ##########\n",
      "Timestep: 186302 Average reward is -0.0395\n",
      "INFO - Step 186439, loss: 0.33099022507667543\n",
      "########## Evaluation ##########\n",
      "Timestep: 186439 Average reward is -0.0648\n",
      "INFO - Step 186591, loss: 0.45108985900878906\n",
      "########## Evaluation ##########\n",
      "Timestep: 186591 Average reward is -0.0568\n",
      "INFO - Step 186741, loss: 0.62957090139389047\n",
      "########## Evaluation ##########\n",
      "Timestep: 186741 Average reward is -0.0607\n",
      "INFO - Step 186900, loss: 0.21569329500198364\n",
      "########## Evaluation ##########\n",
      "Timestep: 186900 Average reward is -0.0434\n",
      "INFO - Step 187052, loss: 0.79608887434005743\n",
      "########## Evaluation ##########\n",
      "Timestep: 187052 Average reward is -0.0674\n",
      "INFO - Step 187194, loss: 0.67291319370269785\n",
      "########## Evaluation ##########\n",
      "Timestep: 187194 Average reward is -0.0513\n",
      "INFO - Step 187200, loss: 0.39809906482696533\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 187343, loss: 0.55911386013031014\n",
      "########## Evaluation ##########\n",
      "Timestep: 187343 Average reward is -0.058\n",
      "INFO - Step 187487, loss: 0.38239473104476936\n",
      "########## Evaluation ##########\n",
      "Timestep: 187487 Average reward is -0.0645\n",
      "INFO - Step 187627, loss: 0.57745820283889776\n",
      "########## Evaluation ##########\n",
      "Timestep: 187627 Average reward is -0.0666\n",
      "INFO - Step 187667, loss: 0.50714242458343514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 187766, loss: 0.36959999799728394\n",
      "########## Evaluation ##########\n",
      "Timestep: 187766 Average reward is -0.0733\n",
      "INFO - Step 187914, loss: 0.36701589822769165\n",
      "########## Evaluation ##########\n",
      "Timestep: 187914 Average reward is -0.0561\n",
      "INFO - Step 188060, loss: 0.54024040699005133\n",
      "########## Evaluation ##########\n",
      "Timestep: 188060 Average reward is -0.0502\n",
      "INFO - Step 188200, loss: 0.69085001945495633\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 188212, loss: 0.42181885242462167\n",
      "########## Evaluation ##########\n",
      "Timestep: 188212 Average reward is -0.0608\n",
      "INFO - Step 188360, loss: 0.44011032581329346\n",
      "########## Evaluation ##########\n",
      "Timestep: 188360 Average reward is -0.0557\n",
      "INFO - Step 188499, loss: 0.32616531848907477\n",
      "########## Evaluation ##########\n",
      "Timestep: 188499 Average reward is -0.0782\n",
      "INFO - Step 188659, loss: 0.54299736022949227\n",
      "########## Evaluation ##########\n",
      "Timestep: 188659 Average reward is -0.0602\n",
      "INFO - Step 188792, loss: 0.50854831933975227\n",
      "########## Evaluation ##########\n",
      "Timestep: 188792 Average reward is -0.0577\n",
      "INFO - Step 188938, loss: 0.58535724878311163\n",
      "########## Evaluation ##########\n",
      "Timestep: 188938 Average reward is -0.0683\n",
      "INFO - Step 189080, loss: 0.38594052195549015\n",
      "########## Evaluation ##########\n",
      "Timestep: 189080 Average reward is -0.0567\n",
      "INFO - Step 189122, loss: 0.41376873850822455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 189200, loss: 0.43678405880928046\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 189223, loss: 0.49533066153526306\n",
      "########## Evaluation ##########\n",
      "Timestep: 189223 Average reward is -0.0564\n",
      "INFO - Step 189388, loss: 0.46845519542694097\n",
      "########## Evaluation ##########\n",
      "Timestep: 189388 Average reward is -0.0495\n",
      "INFO - Step 189536, loss: 0.34877404570579536\n",
      "########## Evaluation ##########\n",
      "Timestep: 189536 Average reward is -0.062\n",
      "INFO - Step 189695, loss: 0.55163317918777477\n",
      "########## Evaluation ##########\n",
      "Timestep: 189695 Average reward is -0.0565\n",
      "INFO - Step 189854, loss: 0.61131465435028085\n",
      "########## Evaluation ##########\n",
      "Timestep: 189854 Average reward is -0.0495\n",
      "INFO - Step 190009, loss: 0.60381305217742923\n",
      "########## Evaluation ##########\n",
      "Timestep: 190009 Average reward is -0.0849\n",
      "INFO - Step 190162, loss: 0.49967092275619507\n",
      "########## Evaluation ##########\n",
      "Timestep: 190162 Average reward is -0.0598\n",
      "INFO - Step 190200, loss: 0.44814172387123113\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 190308, loss: 0.52868330478668214\n",
      "########## Evaluation ##########\n",
      "Timestep: 190308 Average reward is -0.0683\n",
      "INFO - Step 190462, loss: 0.37728583812713623\n",
      "########## Evaluation ##########\n",
      "Timestep: 190462 Average reward is -0.0625\n",
      "INFO - Step 190611, loss: 0.51901865005493163\n",
      "########## Evaluation ##########\n",
      "Timestep: 190611 Average reward is -0.0627\n",
      "INFO - Step 190650, loss: 0.53150033950805666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 190750, loss: 0.72475093603134164\n",
      "########## Evaluation ##########\n",
      "Timestep: 190750 Average reward is -0.059\n",
      "INFO - Step 190892, loss: 0.54473316669464115\n",
      "########## Evaluation ##########\n",
      "Timestep: 190892 Average reward is -0.052\n",
      "INFO - Step 191052, loss: 0.55238693952560424\n",
      "########## Evaluation ##########\n",
      "Timestep: 191052 Average reward is -0.0518\n",
      "INFO - Step 191197, loss: 0.51471602916717534\n",
      "########## Evaluation ##########\n",
      "Timestep: 191197 Average reward is -0.0506\n",
      "INFO - Step 191200, loss: 0.31665751338005066\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 191351, loss: 0.57491570711135866\n",
      "########## Evaluation ##########\n",
      "Timestep: 191351 Average reward is -0.0643\n",
      "INFO - Step 191501, loss: 0.40689224004745483\n",
      "########## Evaluation ##########\n",
      "Timestep: 191501 Average reward is -0.0761\n",
      "INFO - Step 191644, loss: 0.42768064141273594\n",
      "########## Evaluation ##########\n",
      "Timestep: 191644 Average reward is -0.0447\n",
      "INFO - Step 191785, loss: 0.44350513815879825\n",
      "########## Evaluation ##########\n",
      "Timestep: 191785 Average reward is -0.0515\n",
      "INFO - Step 191929, loss: 0.41978842020034794\n",
      "########## Evaluation ##########\n",
      "Timestep: 191929 Average reward is -0.058\n",
      "INFO - Step 192066, loss: 0.54742681980133065\n",
      "########## Evaluation ##########\n",
      "Timestep: 192066 Average reward is -0.066\n",
      "INFO - Step 192110, loss: 0.49246874451637275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 192200, loss: 0.42594242095947266\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 192222, loss: 0.37326359748840335\n",
      "########## Evaluation ##########\n",
      "Timestep: 192222 Average reward is -0.0409\n",
      "INFO - Step 192359, loss: 0.39251524209976196\n",
      "########## Evaluation ##########\n",
      "Timestep: 192359 Average reward is -0.0417\n",
      "INFO - Step 192508, loss: 0.54706978797912627\n",
      "########## Evaluation ##########\n",
      "Timestep: 192508 Average reward is -0.0457\n",
      "INFO - Step 192654, loss: 0.39154720306396484\n",
      "########## Evaluation ##########\n",
      "Timestep: 192654 Average reward is -0.0481\n",
      "INFO - Step 192800, loss: 0.36273455619812015\n",
      "########## Evaluation ##########\n",
      "Timestep: 192800 Average reward is -0.0409\n",
      "INFO - Step 192946, loss: 0.38562691211700443\n",
      "########## Evaluation ##########\n",
      "Timestep: 192946 Average reward is -0.052\n",
      "INFO - Step 193092, loss: 0.67563140392303476\n",
      "########## Evaluation ##########\n",
      "Timestep: 193092 Average reward is -0.0499\n",
      "INFO - Step 193200, loss: 0.35920977592468267\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 193239, loss: 0.43425399065017786\n",
      "########## Evaluation ##########\n",
      "Timestep: 193239 Average reward is -0.0666\n",
      "INFO - Step 193385, loss: 0.54467368125915537\n",
      "########## Evaluation ##########\n",
      "Timestep: 193385 Average reward is -0.054\n",
      "INFO - Step 193533, loss: 0.68467682600021364\n",
      "########## Evaluation ##########\n",
      "Timestep: 193533 Average reward is -0.0682\n",
      "INFO - Step 193578, loss: 0.39323076605796814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 193677, loss: 0.41239508986473083\n",
      "########## Evaluation ##########\n",
      "Timestep: 193677 Average reward is -0.0812\n",
      "INFO - Step 193826, loss: 0.48404109477996826\n",
      "########## Evaluation ##########\n",
      "Timestep: 193826 Average reward is -0.0569\n",
      "INFO - Step 193975, loss: 0.56518602371215826\n",
      "########## Evaluation ##########\n",
      "Timestep: 193975 Average reward is -0.0529\n",
      "INFO - Step 194116, loss: 0.48612084984779364\n",
      "########## Evaluation ##########\n",
      "Timestep: 194116 Average reward is -0.0353\n",
      "INFO - Step 194200, loss: 0.51960790157318126\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 194273, loss: 0.47170171141624454\n",
      "########## Evaluation ##########\n",
      "Timestep: 194273 Average reward is -0.0573\n",
      "INFO - Step 194418, loss: 0.50223970413208014\n",
      "########## Evaluation ##########\n",
      "Timestep: 194418 Average reward is -0.0603\n",
      "INFO - Step 194588, loss: 0.48899152874946594\n",
      "########## Evaluation ##########\n",
      "Timestep: 194588 Average reward is -0.0668\n",
      "INFO - Step 194724, loss: 0.45035636425018313\n",
      "########## Evaluation ##########\n",
      "Timestep: 194724 Average reward is -0.0594\n",
      "INFO - Step 194875, loss: 0.53446120023727427\n",
      "########## Evaluation ##########\n",
      "Timestep: 194875 Average reward is -0.0453\n",
      "INFO - Step 195009, loss: 0.47867864370346074\n",
      "########## Evaluation ##########\n",
      "Timestep: 195009 Average reward is -0.0699\n",
      "INFO - Step 195053, loss: 0.42862656712532043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 195160, loss: 0.58374118804931647\n",
      "########## Evaluation ##########\n",
      "Timestep: 195160 Average reward is -0.0768\n",
      "INFO - Step 195200, loss: 0.40082001686096194\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 195309, loss: 0.53644359111785896\n",
      "########## Evaluation ##########\n",
      "Timestep: 195309 Average reward is -0.0656\n",
      "INFO - Step 195448, loss: 0.41805177927017216\n",
      "########## Evaluation ##########\n",
      "Timestep: 195448 Average reward is -0.057\n",
      "INFO - Step 195603, loss: 0.63538539409637456\n",
      "########## Evaluation ##########\n",
      "Timestep: 195603 Average reward is -0.0543\n",
      "INFO - Step 195744, loss: 0.51289677619934085\n",
      "########## Evaluation ##########\n",
      "Timestep: 195744 Average reward is -0.0521\n",
      "INFO - Step 195894, loss: 0.62799692153930664\n",
      "########## Evaluation ##########\n",
      "Timestep: 195894 Average reward is -0.0615\n",
      "INFO - Step 196046, loss: 0.47356802225112915\n",
      "########## Evaluation ##########\n",
      "Timestep: 196046 Average reward is -0.0666\n",
      "INFO - Step 196195, loss: 0.64295059442520145\n",
      "########## Evaluation ##########\n",
      "Timestep: 196195 Average reward is -0.0513\n",
      "INFO - Step 196200, loss: 0.4621347188949585\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 196330, loss: 0.62499314546585087\n",
      "########## Evaluation ##########\n",
      "Timestep: 196330 Average reward is -0.0432\n",
      "INFO - Step 196480, loss: 0.44327902793884287\n",
      "########## Evaluation ##########\n",
      "Timestep: 196480 Average reward is -0.0593\n",
      "INFO - Step 196522, loss: 0.61534357070922854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 196630, loss: 0.47119671106338554\n",
      "########## Evaluation ##########\n",
      "Timestep: 196630 Average reward is -0.0516\n",
      "INFO - Step 196771, loss: 0.35827091336250305\n",
      "########## Evaluation ##########\n",
      "Timestep: 196771 Average reward is -0.0519\n",
      "INFO - Step 196914, loss: 0.50807070732116746\n",
      "########## Evaluation ##########\n",
      "Timestep: 196914 Average reward is -0.0615\n",
      "INFO - Step 197057, loss: 0.38233819603919983\n",
      "########## Evaluation ##########\n",
      "Timestep: 197057 Average reward is -0.0501\n",
      "INFO - Step 197200, loss: 0.72041314840316774\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 197206, loss: 0.47888290882110596\n",
      "########## Evaluation ##########\n",
      "Timestep: 197206 Average reward is -0.0648\n",
      "INFO - Step 197367, loss: 0.55585068464279175\n",
      "########## Evaluation ##########\n",
      "Timestep: 197367 Average reward is -0.0473\n",
      "INFO - Step 197511, loss: 0.50022411346435555\n",
      "########## Evaluation ##########\n",
      "Timestep: 197511 Average reward is -0.0534\n",
      "INFO - Step 197669, loss: 0.36652708053588867\n",
      "########## Evaluation ##########\n",
      "Timestep: 197669 Average reward is -0.0659\n",
      "INFO - Step 197811, loss: 0.34207171201705934\n",
      "########## Evaluation ##########\n",
      "Timestep: 197811 Average reward is -0.0507\n",
      "INFO - Step 197967, loss: 0.46663463115692146\n",
      "########## Evaluation ##########\n",
      "Timestep: 197967 Average reward is -0.0762\n",
      "INFO - Step 198026, loss: 0.54331362247467045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 198111, loss: 0.43800279498100285\n",
      "########## Evaluation ##########\n",
      "Timestep: 198111 Average reward is -0.0472\n",
      "INFO - Step 198200, loss: 0.48347562551498413\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 198246, loss: 0.59718102216720586\n",
      "########## Evaluation ##########\n",
      "Timestep: 198246 Average reward is -0.0577\n",
      "INFO - Step 198385, loss: 0.37312692403793335\n",
      "########## Evaluation ##########\n",
      "Timestep: 198385 Average reward is -0.0522\n",
      "INFO - Step 198537, loss: 0.51446068286895756\n",
      "########## Evaluation ##########\n",
      "Timestep: 198537 Average reward is -0.0641\n",
      "INFO - Step 198694, loss: 0.37949973344802856\n",
      "########## Evaluation ##########\n",
      "Timestep: 198694 Average reward is -0.0643\n",
      "INFO - Step 198846, loss: 0.56597089767456055\n",
      "########## Evaluation ##########\n",
      "Timestep: 198846 Average reward is -0.055\n",
      "INFO - Step 198984, loss: 0.44948130846023566\n",
      "########## Evaluation ##########\n",
      "Timestep: 198984 Average reward is -0.0497\n",
      "INFO - Step 199133, loss: 0.54364299774169927\n",
      "########## Evaluation ##########\n",
      "Timestep: 199133 Average reward is -0.0502\n",
      "INFO - Step 199200, loss: 0.44773536920547485\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 199290, loss: 0.29174655675888063\n",
      "########## Evaluation ##########\n",
      "Timestep: 199290 Average reward is -0.0615\n",
      "INFO - Step 199444, loss: 0.53537619113922126\n",
      "########## Evaluation ##########\n",
      "Timestep: 199444 Average reward is -0.0444\n",
      "INFO - Step 199479, loss: 0.61383157968521123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 199587, loss: 0.44689923524856576\n",
      "########## Evaluation ##########\n",
      "Timestep: 199587 Average reward is -0.068\n",
      "INFO - Step 199730, loss: 0.48045086860656746\n",
      "########## Evaluation ##########\n",
      "Timestep: 199730 Average reward is -0.065\n",
      "INFO - Step 199869, loss: 0.52868819236755375\n",
      "########## Evaluation ##########\n",
      "Timestep: 199869 Average reward is -0.0577\n",
      "INFO - Step 200022, loss: 0.36159333586692815\n",
      "########## Evaluation ##########\n",
      "Timestep: 200022 Average reward is -0.0504\n",
      "INFO - Step 200180, loss: 0.38076111674308777\n",
      "########## Evaluation ##########\n",
      "Timestep: 200180 Average reward is -0.0534\n",
      "INFO - Step 200200, loss: 0.45756566524505615\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 200328, loss: 0.50724375247955325\n",
      "########## Evaluation ##########\n",
      "Timestep: 200328 Average reward is -0.0744\n",
      "INFO - Step 200473, loss: 0.31248769164085396\n",
      "########## Evaluation ##########\n",
      "Timestep: 200473 Average reward is -0.0489\n",
      "INFO - Step 200620, loss: 0.48504012823104865\n",
      "########## Evaluation ##########\n",
      "Timestep: 200620 Average reward is -0.0541\n",
      "INFO - Step 200757, loss: 0.67774116992950443\n",
      "########## Evaluation ##########\n",
      "Timestep: 200757 Average reward is -0.0694\n",
      "INFO - Step 200905, loss: 0.38132864236831665\n",
      "########## Evaluation ##########\n",
      "Timestep: 200905 Average reward is -0.0701\n",
      "INFO - Step 200941, loss: 0.39666587114334106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 201037, loss: 0.60532540082931523\n",
      "########## Evaluation ##########\n",
      "Timestep: 201037 Average reward is -0.0541\n",
      "INFO - Step 201181, loss: 0.53679579496383677\n",
      "########## Evaluation ##########\n",
      "Timestep: 201181 Average reward is -0.0573\n",
      "INFO - Step 201200, loss: 0.49758175015449524\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 201330, loss: 0.49616459012031555\n",
      "########## Evaluation ##########\n",
      "Timestep: 201330 Average reward is -0.0479\n",
      "INFO - Step 201472, loss: 0.68035328388214114\n",
      "########## Evaluation ##########\n",
      "Timestep: 201472 Average reward is -0.0699\n",
      "INFO - Step 201614, loss: 0.58511090278625495\n",
      "########## Evaluation ##########\n",
      "Timestep: 201614 Average reward is -0.0692\n",
      "INFO - Step 201761, loss: 0.53102821111679084\n",
      "########## Evaluation ##########\n",
      "Timestep: 201761 Average reward is -0.0799\n",
      "INFO - Step 201911, loss: 0.45748886466026306\n",
      "########## Evaluation ##########\n",
      "Timestep: 201911 Average reward is -0.0564\n",
      "INFO - Step 202060, loss: 0.54346990585327154\n",
      "########## Evaluation ##########\n",
      "Timestep: 202060 Average reward is -0.0702\n",
      "INFO - Step 202200, loss: 0.56046593189239575\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 202205, loss: 0.56377631425857546\n",
      "########## Evaluation ##########\n",
      "Timestep: 202205 Average reward is -0.0603\n",
      "INFO - Step 202351, loss: 0.68022847175598145\n",
      "########## Evaluation ##########\n",
      "Timestep: 202351 Average reward is -0.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 202500, loss: 0.52143418788909916\n",
      "########## Evaluation ##########\n",
      "Timestep: 202500 Average reward is -0.0515\n",
      "INFO - Step 202653, loss: 0.60367518663406374\n",
      "########## Evaluation ##########\n",
      "Timestep: 202653 Average reward is -0.0653\n",
      "INFO - Step 202809, loss: 0.27444306015968324\n",
      "########## Evaluation ##########\n",
      "Timestep: 202809 Average reward is -0.0634\n",
      "INFO - Step 202949, loss: 0.47212651371955874\n",
      "########## Evaluation ##########\n",
      "Timestep: 202949 Average reward is -0.0605\n",
      "INFO - Step 203094, loss: 0.32432925701141366\n",
      "########## Evaluation ##########\n",
      "Timestep: 203094 Average reward is -0.0512\n",
      "INFO - Step 203200, loss: 0.50472581386566163\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 203239, loss: 0.50246375799179086\n",
      "########## Evaluation ##########\n",
      "Timestep: 203239 Average reward is -0.0498\n",
      "INFO - Step 203386, loss: 0.45160028338432314\n",
      "########## Evaluation ##########\n",
      "Timestep: 203386 Average reward is -0.0603\n",
      "INFO - Step 203536, loss: 0.38902670145034796\n",
      "########## Evaluation ##########\n",
      "Timestep: 203536 Average reward is -0.0552\n",
      "INFO - Step 203677, loss: 0.54617917537689213\n",
      "########## Evaluation ##########\n",
      "Timestep: 203677 Average reward is -0.0675\n",
      "INFO - Step 203827, loss: 0.72565257549285895\n",
      "########## Evaluation ##########\n",
      "Timestep: 203827 Average reward is -0.0536\n",
      "INFO - Step 203857, loss: 0.72075611352920534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 203975, loss: 0.44330430030822754\n",
      "########## Evaluation ##########\n",
      "Timestep: 203975 Average reward is -0.075\n",
      "INFO - Step 204117, loss: 0.53046345710754415\n",
      "########## Evaluation ##########\n",
      "Timestep: 204117 Average reward is -0.0603\n",
      "INFO - Step 204200, loss: 0.52265977859497076\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 204259, loss: 0.63663876056671143\n",
      "########## Evaluation ##########\n",
      "Timestep: 204259 Average reward is -0.0462\n",
      "INFO - Step 204411, loss: 0.46094185113906862\n",
      "########## Evaluation ##########\n",
      "Timestep: 204411 Average reward is -0.0526\n",
      "INFO - Step 204577, loss: 0.55488491058349617\n",
      "########## Evaluation ##########\n",
      "Timestep: 204577 Average reward is -0.0601\n",
      "INFO - Step 204717, loss: 0.46728950738906865\n",
      "########## Evaluation ##########\n",
      "Timestep: 204717 Average reward is -0.0694\n",
      "INFO - Step 204869, loss: 0.46539300680160524\n",
      "########## Evaluation ##########\n",
      "Timestep: 204869 Average reward is -0.0613\n",
      "INFO - Step 205020, loss: 0.39641463756561283\n",
      "########## Evaluation ##########\n",
      "Timestep: 205020 Average reward is -0.0614\n",
      "INFO - Step 205164, loss: 0.47715109586715717\n",
      "########## Evaluation ##########\n",
      "Timestep: 205164 Average reward is -0.0386\n",
      "INFO - Step 205200, loss: 0.46889793872833254\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 205306, loss: 0.39819526672363287\n",
      "########## Evaluation ##########\n",
      "Timestep: 205306 Average reward is -0.0441\n",
      "INFO - Step 205339, loss: 0.49965113401412964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 205458, loss: 0.46151965856552124\n",
      "########## Evaluation ##########\n",
      "Timestep: 205458 Average reward is -0.061\n",
      "INFO - Step 205611, loss: 0.44218760728836064\n",
      "########## Evaluation ##########\n",
      "Timestep: 205611 Average reward is -0.0624\n",
      "INFO - Step 205755, loss: 0.56025755405426033\n",
      "########## Evaluation ##########\n",
      "Timestep: 205755 Average reward is -0.0585\n",
      "INFO - Step 205902, loss: 0.51942163705825815\n",
      "########## Evaluation ##########\n",
      "Timestep: 205902 Average reward is -0.0652\n",
      "INFO - Step 206058, loss: 0.54111850261688234\n",
      "########## Evaluation ##########\n",
      "Timestep: 206058 Average reward is -0.0386\n",
      "INFO - Step 206200, loss: 0.59788465499877936\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 206207, loss: 0.50388354063034066\n",
      "########## Evaluation ##########\n",
      "Timestep: 206207 Average reward is -0.0507\n",
      "INFO - Step 206369, loss: 0.43732094764709476\n",
      "########## Evaluation ##########\n",
      "Timestep: 206369 Average reward is -0.0715\n",
      "INFO - Step 206516, loss: 0.39813530445098877\n",
      "########## Evaluation ##########\n",
      "Timestep: 206516 Average reward is -0.0564\n",
      "INFO - Step 206661, loss: 0.41525521874427795\n",
      "########## Evaluation ##########\n",
      "Timestep: 206661 Average reward is -0.0516\n",
      "INFO - Step 206813, loss: 0.58052170276641855\n",
      "########## Evaluation ##########\n",
      "Timestep: 206813 Average reward is -0.0495\n",
      "INFO - Step 206852, loss: 0.51891934871673586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 206951, loss: 0.43360024690628053\n",
      "########## Evaluation ##########\n",
      "Timestep: 206951 Average reward is -0.0572\n",
      "INFO - Step 207103, loss: 0.44924938678741455\n",
      "########## Evaluation ##########\n",
      "Timestep: 207103 Average reward is -0.0535\n",
      "INFO - Step 207200, loss: 0.40468305349349976\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 207245, loss: 0.55139732360839846\n",
      "########## Evaluation ##########\n",
      "Timestep: 207245 Average reward is -0.0457\n",
      "INFO - Step 207393, loss: 0.56045109033584653\n",
      "########## Evaluation ##########\n",
      "Timestep: 207393 Average reward is -0.0641\n",
      "INFO - Step 207532, loss: 0.45770436525344854\n",
      "########## Evaluation ##########\n",
      "Timestep: 207532 Average reward is -0.055\n",
      "INFO - Step 207670, loss: 0.35652810335159387\n",
      "########## Evaluation ##########\n",
      "Timestep: 207670 Average reward is -0.0441\n",
      "INFO - Step 207828, loss: 0.33452183008193974\n",
      "########## Evaluation ##########\n",
      "Timestep: 207828 Average reward is -0.0777\n",
      "INFO - Step 207969, loss: 0.39505150914192274\n",
      "########## Evaluation ##########\n",
      "Timestep: 207969 Average reward is -0.0675\n",
      "INFO - Step 208115, loss: 0.62902230024337776\n",
      "########## Evaluation ##########\n",
      "Timestep: 208115 Average reward is -0.0515\n",
      "INFO - Step 208200, loss: 0.46139487624168396\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 208263, loss: 0.55384910106658944\n",
      "########## Evaluation ##########\n",
      "Timestep: 208263 Average reward is -0.0581\n",
      "INFO - Step 208291, loss: 0.41685974597930917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 208409, loss: 0.59938681125640876\n",
      "########## Evaluation ##########\n",
      "Timestep: 208409 Average reward is -0.0392\n",
      "INFO - Step 208552, loss: 0.41117012500762947\n",
      "########## Evaluation ##########\n",
      "Timestep: 208552 Average reward is -0.0694\n",
      "INFO - Step 208704, loss: 0.38216498494148254\n",
      "########## Evaluation ##########\n",
      "Timestep: 208704 Average reward is -0.0684\n",
      "INFO - Step 208844, loss: 0.32205525040626526\n",
      "########## Evaluation ##########\n",
      "Timestep: 208844 Average reward is -0.0624\n",
      "INFO - Step 208992, loss: 0.53154611587524415\n",
      "########## Evaluation ##########\n",
      "Timestep: 208992 Average reward is -0.0518\n",
      "INFO - Step 209137, loss: 0.46691954135894775\n",
      "########## Evaluation ##########\n",
      "Timestep: 209137 Average reward is -0.0687\n",
      "INFO - Step 209200, loss: 0.64881908893585256\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 209283, loss: 0.46192041039466863\n",
      "########## Evaluation ##########\n",
      "Timestep: 209283 Average reward is -0.047\n",
      "INFO - Step 209433, loss: 0.52284359931945867\n",
      "########## Evaluation ##########\n",
      "Timestep: 209433 Average reward is -0.0574\n",
      "INFO - Step 209576, loss: 0.58887737989425665\n",
      "########## Evaluation ##########\n",
      "Timestep: 209576 Average reward is -0.0621\n",
      "INFO - Step 209721, loss: 0.46617060899734497\n",
      "########## Evaluation ##########\n",
      "Timestep: 209721 Average reward is -0.0653\n",
      "INFO - Step 209754, loss: 0.56768810749053966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 209886, loss: 0.41667729616165167\n",
      "########## Evaluation ##########\n",
      "Timestep: 209886 Average reward is -0.0671\n",
      "INFO - Step 210032, loss: 0.40690851211547857\n",
      "########## Evaluation ##########\n",
      "Timestep: 210032 Average reward is -0.0503\n",
      "INFO - Step 210186, loss: 0.50292223691940315\n",
      "########## Evaluation ##########\n",
      "Timestep: 210186 Average reward is -0.0496\n",
      "INFO - Step 210200, loss: 0.55497920513153086\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 210340, loss: 0.53168463706970215\n",
      "########## Evaluation ##########\n",
      "Timestep: 210340 Average reward is -0.0643\n",
      "INFO - Step 210485, loss: 0.55844163894653325\n",
      "########## Evaluation ##########\n",
      "Timestep: 210485 Average reward is -0.0601\n",
      "INFO - Step 210650, loss: 0.42735916376113894\n",
      "########## Evaluation ##########\n",
      "Timestep: 210650 Average reward is -0.0525\n",
      "INFO - Step 210794, loss: 0.58146548271179254\n",
      "########## Evaluation ##########\n",
      "Timestep: 210794 Average reward is -0.0595\n",
      "INFO - Step 210943, loss: 0.47967290878295926\n",
      "########## Evaluation ##########\n",
      "Timestep: 210943 Average reward is -0.0669\n",
      "INFO - Step 211091, loss: 0.53195881843566984\n",
      "########## Evaluation ##########\n",
      "Timestep: 211091 Average reward is -0.0584\n",
      "INFO - Step 211200, loss: 0.38282129168510437\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 211233, loss: 0.39795660972595215\n",
      "########## Evaluation ##########\n",
      "Timestep: 211233 Average reward is -0.0795\n",
      "INFO - Step 211263, loss: 0.43542337417602545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 211378, loss: 0.45516741275787354\n",
      "########## Evaluation ##########\n",
      "Timestep: 211378 Average reward is -0.0602\n",
      "INFO - Step 211528, loss: 0.52634823322296145\n",
      "########## Evaluation ##########\n",
      "Timestep: 211528 Average reward is -0.0682\n",
      "INFO - Step 211675, loss: 0.39496403932571416\n",
      "########## Evaluation ##########\n",
      "Timestep: 211675 Average reward is -0.0527\n",
      "INFO - Step 211832, loss: 0.49245628714561465\n",
      "########## Evaluation ##########\n",
      "Timestep: 211832 Average reward is -0.0454\n",
      "INFO - Step 211982, loss: 0.39266207814216614\n",
      "########## Evaluation ##########\n",
      "Timestep: 211982 Average reward is -0.0535\n",
      "INFO - Step 212127, loss: 0.60325223207473754\n",
      "########## Evaluation ##########\n",
      "Timestep: 212127 Average reward is -0.0691\n",
      "INFO - Step 212200, loss: 0.56660753488540653\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 212284, loss: 0.39122617244720464\n",
      "########## Evaluation ##########\n",
      "Timestep: 212284 Average reward is -0.0728\n",
      "INFO - Step 212435, loss: 0.58763289451599124\n",
      "########## Evaluation ##########\n",
      "Timestep: 212435 Average reward is -0.066\n",
      "INFO - Step 212585, loss: 0.51686412096023567\n",
      "########## Evaluation ##########\n",
      "Timestep: 212585 Average reward is -0.044\n",
      "INFO - Step 212738, loss: 0.54379338026046753\n",
      "########## Evaluation ##########\n",
      "Timestep: 212738 Average reward is -0.0442\n",
      "INFO - Step 212776, loss: 0.52674722671508795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 212889, loss: 0.79382681846618654\n",
      "########## Evaluation ##########\n",
      "Timestep: 212889 Average reward is -0.0468\n",
      "INFO - Step 213032, loss: 0.48696768283843994\n",
      "########## Evaluation ##########\n",
      "Timestep: 213032 Average reward is -0.0422\n",
      "INFO - Step 213190, loss: 0.57231247425079357\n",
      "########## Evaluation ##########\n",
      "Timestep: 213190 Average reward is -0.0716\n",
      "INFO - Step 213200, loss: 0.43615978956222534\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 213342, loss: 0.45067608356475834\n",
      "########## Evaluation ##########\n",
      "Timestep: 213342 Average reward is -0.0538\n",
      "INFO - Step 213491, loss: 0.35078954696655273\n",
      "########## Evaluation ##########\n",
      "Timestep: 213491 Average reward is -0.0629\n",
      "INFO - Step 213634, loss: 0.51853013038635254\n",
      "########## Evaluation ##########\n",
      "Timestep: 213634 Average reward is -0.063\n",
      "INFO - Step 213776, loss: 0.42930656671524055\n",
      "########## Evaluation ##########\n",
      "Timestep: 213776 Average reward is -0.068\n",
      "INFO - Step 213930, loss: 0.56195014715194746\n",
      "########## Evaluation ##########\n",
      "Timestep: 213930 Average reward is -0.0494\n",
      "INFO - Step 214069, loss: 0.64361548423767094\n",
      "########## Evaluation ##########\n",
      "Timestep: 214069 Average reward is -0.0601\n",
      "INFO - Step 214200, loss: 0.46450972557067874\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 214202, loss: 0.45975810289382935\n",
      "########## Evaluation ##########\n",
      "Timestep: 214202 Average reward is -0.0615\n",
      "INFO - Step 214244, loss: 0.36164861917495736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 214349, loss: 0.41852989792823797\n",
      "########## Evaluation ##########\n",
      "Timestep: 214349 Average reward is -0.0634\n",
      "INFO - Step 214492, loss: 0.60519373416900636\n",
      "########## Evaluation ##########\n",
      "Timestep: 214492 Average reward is -0.0647\n",
      "INFO - Step 214622, loss: 0.71757692098617556\n",
      "########## Evaluation ##########\n",
      "Timestep: 214622 Average reward is -0.0737\n",
      "INFO - Step 214760, loss: 0.37380227446556095\n",
      "########## Evaluation ##########\n",
      "Timestep: 214760 Average reward is -0.0667\n",
      "INFO - Step 214912, loss: 0.53063160181045535\n",
      "########## Evaluation ##########\n",
      "Timestep: 214912 Average reward is -0.0574\n",
      "INFO - Step 215049, loss: 0.51171600818634035\n",
      "########## Evaluation ##########\n",
      "Timestep: 215049 Average reward is -0.0502\n",
      "INFO - Step 215192, loss: 0.52473706007003786\n",
      "########## Evaluation ##########\n",
      "Timestep: 215192 Average reward is -0.0707\n",
      "INFO - Step 215200, loss: 0.64793002605438237\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 215345, loss: 0.55917274951934817\n",
      "########## Evaluation ##########\n",
      "Timestep: 215345 Average reward is -0.0442\n",
      "INFO - Step 215486, loss: 0.52221345901489266\n",
      "########## Evaluation ##########\n",
      "Timestep: 215486 Average reward is -0.0624\n",
      "INFO - Step 215625, loss: 0.50504654645919897\n",
      "########## Evaluation ##########\n",
      "Timestep: 215625 Average reward is -0.0654\n",
      "INFO - Step 215664, loss: 0.51353234052658087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 215769, loss: 0.32929909229278564\n",
      "########## Evaluation ##########\n",
      "Timestep: 215769 Average reward is -0.0691\n",
      "INFO - Step 215911, loss: 0.39219456911087036\n",
      "########## Evaluation ##########\n",
      "Timestep: 215911 Average reward is -0.0784\n",
      "INFO - Step 216066, loss: 0.43662211298942566\n",
      "########## Evaluation ##########\n",
      "Timestep: 216066 Average reward is -0.0636\n",
      "INFO - Step 216200, loss: 0.42193830013275146\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 216213, loss: 0.45797491073608497\n",
      "########## Evaluation ##########\n",
      "Timestep: 216213 Average reward is -0.0488\n",
      "INFO - Step 216361, loss: 0.47685796022415165\n",
      "########## Evaluation ##########\n",
      "Timestep: 216361 Average reward is -0.0449\n",
      "INFO - Step 216510, loss: 0.43247008323669434\n",
      "########## Evaluation ##########\n",
      "Timestep: 216510 Average reward is -0.0496\n",
      "INFO - Step 216654, loss: 0.51943933963775633\n",
      "########## Evaluation ##########\n",
      "Timestep: 216654 Average reward is -0.0451\n",
      "INFO - Step 216799, loss: 0.61096501350402834\n",
      "########## Evaluation ##########\n",
      "Timestep: 216799 Average reward is -0.082\n",
      "INFO - Step 216945, loss: 0.52881169319152834\n",
      "########## Evaluation ##########\n",
      "Timestep: 216945 Average reward is -0.0497\n",
      "INFO - Step 217106, loss: 0.51389020681381236\n",
      "########## Evaluation ##########\n",
      "Timestep: 217106 Average reward is -0.0614\n",
      "INFO - Step 217142, loss: 0.63653004169464114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 217200, loss: 0.43677657842636114\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 217247, loss: 0.41926604509353644\n",
      "########## Evaluation ##########\n",
      "Timestep: 217247 Average reward is -0.0854\n",
      "INFO - Step 217397, loss: 0.45487374067306526\n",
      "########## Evaluation ##########\n",
      "Timestep: 217397 Average reward is -0.0671\n",
      "INFO - Step 217543, loss: 0.44939896464347845\n",
      "########## Evaluation ##########\n",
      "Timestep: 217543 Average reward is -0.0568\n",
      "INFO - Step 217686, loss: 0.58556580543518075\n",
      "########## Evaluation ##########\n",
      "Timestep: 217686 Average reward is -0.0588\n",
      "INFO - Step 217833, loss: 0.45118603110313416\n",
      "########## Evaluation ##########\n",
      "Timestep: 217833 Average reward is -0.0567\n",
      "INFO - Step 217972, loss: 0.44534963369369507\n",
      "########## Evaluation ##########\n",
      "Timestep: 217972 Average reward is -0.0464\n",
      "INFO - Step 218128, loss: 0.42801156640052795\n",
      "########## Evaluation ##########\n",
      "Timestep: 218128 Average reward is -0.0746\n",
      "INFO - Step 218200, loss: 0.54303699731826787\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 218284, loss: 0.48069232702255254\n",
      "########## Evaluation ##########\n",
      "Timestep: 218284 Average reward is -0.0652\n",
      "INFO - Step 218429, loss: 0.34750384092330934\n",
      "########## Evaluation ##########\n",
      "Timestep: 218429 Average reward is -0.0501\n",
      "INFO - Step 218572, loss: 0.37462320923805237\n",
      "########## Evaluation ##########\n",
      "Timestep: 218572 Average reward is -0.0484\n",
      "INFO - Step 218604, loss: 0.58495211601257324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 218723, loss: 0.53954529762268077\n",
      "########## Evaluation ##########\n",
      "Timestep: 218723 Average reward is -0.0627\n",
      "INFO - Step 218868, loss: 0.41802448034286594\n",
      "########## Evaluation ##########\n",
      "Timestep: 218868 Average reward is -0.0601\n",
      "INFO - Step 219015, loss: 0.33092945814132695\n",
      "########## Evaluation ##########\n",
      "Timestep: 219015 Average reward is -0.0548\n",
      "INFO - Step 219161, loss: 0.48075360059738163\n",
      "########## Evaluation ##########\n",
      "Timestep: 219161 Average reward is -0.0558\n",
      "INFO - Step 219200, loss: 0.37676471471786554\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 219300, loss: 0.42637446522712715\n",
      "########## Evaluation ##########\n",
      "Timestep: 219300 Average reward is -0.0578\n",
      "INFO - Step 219454, loss: 0.49137428402900696\n",
      "########## Evaluation ##########\n",
      "Timestep: 219454 Average reward is -0.0574\n",
      "INFO - Step 219613, loss: 0.58852875232696533\n",
      "########## Evaluation ##########\n",
      "Timestep: 219613 Average reward is -0.0572\n",
      "INFO - Step 219756, loss: 0.50046861171722416\n",
      "########## Evaluation ##########\n",
      "Timestep: 219756 Average reward is -0.0435\n",
      "INFO - Step 219910, loss: 0.57648837566375737\n",
      "########## Evaluation ##########\n",
      "Timestep: 219910 Average reward is -0.0532\n",
      "INFO - Step 220054, loss: 0.41922748088836676\n",
      "########## Evaluation ##########\n",
      "Timestep: 220054 Average reward is -0.0645\n",
      "INFO - Step 220086, loss: 0.67015886306762754"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 220200, loss: 0.54192441701889047\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 220210, loss: 0.62934148311614996\n",
      "########## Evaluation ##########\n",
      "Timestep: 220210 Average reward is -0.0504\n",
      "INFO - Step 220359, loss: 0.61931222677230836\n",
      "########## Evaluation ##########\n",
      "Timestep: 220359 Average reward is -0.0602\n",
      "INFO - Step 220502, loss: 0.53845053911209116\n",
      "########## Evaluation ##########\n",
      "Timestep: 220502 Average reward is -0.0451\n",
      "INFO - Step 220646, loss: 0.50780820846557626\n",
      "########## Evaluation ##########\n",
      "Timestep: 220646 Average reward is -0.0457\n",
      "INFO - Step 220796, loss: 0.42334926128387456\n",
      "########## Evaluation ##########\n",
      "Timestep: 220796 Average reward is -0.0695\n",
      "INFO - Step 220948, loss: 0.57410162687301645\n",
      "########## Evaluation ##########\n",
      "Timestep: 220948 Average reward is -0.0636\n",
      "INFO - Step 221096, loss: 0.55512940883636475\n",
      "########## Evaluation ##########\n",
      "Timestep: 221096 Average reward is -0.0662\n",
      "INFO - Step 221200, loss: 0.43280598521232605\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 221242, loss: 0.47929251194000244\n",
      "########## Evaluation ##########\n",
      "Timestep: 221242 Average reward is -0.0491\n",
      "INFO - Step 221399, loss: 0.50750517845153814\n",
      "########## Evaluation ##########\n",
      "Timestep: 221399 Average reward is -0.0449\n",
      "INFO - Step 221553, loss: 0.59962809085845954\n",
      "########## Evaluation ##########\n",
      "Timestep: 221553 Average reward is -0.0602\n",
      "INFO - Step 221586, loss: 0.55354934930801397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 221710, loss: 0.48899394273757935\n",
      "########## Evaluation ##########\n",
      "Timestep: 221710 Average reward is -0.054\n",
      "INFO - Step 221852, loss: 0.62481510639190674\n",
      "########## Evaluation ##########\n",
      "Timestep: 221852 Average reward is -0.0527\n",
      "INFO - Step 222005, loss: 0.46495050191879274\n",
      "########## Evaluation ##########\n",
      "Timestep: 222005 Average reward is -0.0606\n",
      "INFO - Step 222148, loss: 0.39639329910278326\n",
      "########## Evaluation ##########\n",
      "Timestep: 222148 Average reward is -0.0593\n",
      "INFO - Step 222200, loss: 0.37002253532409673\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 222294, loss: 0.55408734083175666\n",
      "########## Evaluation ##########\n",
      "Timestep: 222294 Average reward is -0.0626\n",
      "INFO - Step 222453, loss: 0.61671614646911624\n",
      "########## Evaluation ##########\n",
      "Timestep: 222453 Average reward is -0.0556\n",
      "INFO - Step 222616, loss: 0.46118712425231934\n",
      "########## Evaluation ##########\n",
      "Timestep: 222616 Average reward is -0.0323\n",
      "INFO - Step 222756, loss: 0.33132904767990113\n",
      "########## Evaluation ##########\n",
      "Timestep: 222756 Average reward is -0.0623\n",
      "INFO - Step 222912, loss: 0.49783149361610417\n",
      "########## Evaluation ##########\n",
      "Timestep: 222912 Average reward is -0.0641\n",
      "INFO - Step 223066, loss: 0.53855806589126596\n",
      "########## Evaluation ##########\n",
      "Timestep: 223066 Average reward is -0.0717\n",
      "INFO - Step 223105, loss: 0.50365477800369267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 223200, loss: 0.59157854318618777\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 223220, loss: 0.56225723028182984\n",
      "########## Evaluation ##########\n",
      "Timestep: 223220 Average reward is -0.059\n",
      "INFO - Step 223363, loss: 0.61160087585449224\n",
      "########## Evaluation ##########\n",
      "Timestep: 223363 Average reward is -0.0609\n",
      "INFO - Step 223515, loss: 0.65188664197921756\n",
      "########## Evaluation ##########\n",
      "Timestep: 223515 Average reward is -0.0384\n",
      "INFO - Step 223654, loss: 0.35507422685623175\n",
      "########## Evaluation ##########\n",
      "Timestep: 223654 Average reward is -0.0507\n",
      "INFO - Step 223795, loss: 0.42126461863517763\n",
      "########## Evaluation ##########\n",
      "Timestep: 223795 Average reward is -0.0562\n",
      "INFO - Step 223943, loss: 0.64539408683776863\n",
      "########## Evaluation ##########\n",
      "Timestep: 223943 Average reward is -0.0506\n",
      "INFO - Step 224096, loss: 0.50789088010787965\n",
      "########## Evaluation ##########\n",
      "Timestep: 224096 Average reward is -0.0522\n",
      "INFO - Step 224200, loss: 0.55781841278076173\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 224249, loss: 0.56974816322326663\n",
      "########## Evaluation ##########\n",
      "Timestep: 224249 Average reward is -0.0636\n",
      "INFO - Step 224401, loss: 0.39243006706237793\n",
      "########## Evaluation ##########\n",
      "Timestep: 224401 Average reward is -0.0686\n",
      "INFO - Step 224543, loss: 0.51977527141571046\n",
      "########## Evaluation ##########\n",
      "Timestep: 224543 Average reward is -0.0751\n",
      "INFO - Step 224580, loss: 0.51655238866806037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 224694, loss: 0.52089834213256845\n",
      "########## Evaluation ##########\n",
      "Timestep: 224694 Average reward is -0.0582\n",
      "INFO - Step 224836, loss: 0.60245645046234134\n",
      "########## Evaluation ##########\n",
      "Timestep: 224836 Average reward is -0.071\n",
      "INFO - Step 224973, loss: 0.56953638792037964\n",
      "########## Evaluation ##########\n",
      "Timestep: 224973 Average reward is -0.0671\n",
      "INFO - Step 225110, loss: 0.61358797550201424\n",
      "########## Evaluation ##########\n",
      "Timestep: 225110 Average reward is -0.0557\n",
      "INFO - Step 225200, loss: 0.56455612182617196\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 225258, loss: 0.54318171739578257\n",
      "########## Evaluation ##########\n",
      "Timestep: 225258 Average reward is -0.0536\n",
      "INFO - Step 225404, loss: 0.42639222741127014\n",
      "########## Evaluation ##########\n",
      "Timestep: 225404 Average reward is -0.0522\n",
      "INFO - Step 225560, loss: 0.47635129094123845\n",
      "########## Evaluation ##########\n",
      "Timestep: 225560 Average reward is -0.0583\n",
      "INFO - Step 225707, loss: 0.61589431762695313\n",
      "########## Evaluation ##########\n",
      "Timestep: 225707 Average reward is -0.0645\n",
      "INFO - Step 225847, loss: 0.59064185619354255\n",
      "########## Evaluation ##########\n",
      "Timestep: 225847 Average reward is -0.0528\n",
      "INFO - Step 226002, loss: 0.41514986753463745\n",
      "########## Evaluation ##########\n",
      "Timestep: 226002 Average reward is -0.0647\n",
      "INFO - Step 226030, loss: 0.36340159177780153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 226149, loss: 0.42352497577667236\n",
      "########## Evaluation ##########\n",
      "Timestep: 226149 Average reward is -0.0474\n",
      "INFO - Step 226200, loss: 0.32500100135803227\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 226305, loss: 0.36016729474067694\n",
      "########## Evaluation ##########\n",
      "Timestep: 226305 Average reward is -0.0581\n",
      "INFO - Step 226451, loss: 0.42896398901939395\n",
      "########## Evaluation ##########\n",
      "Timestep: 226451 Average reward is -0.042\n",
      "INFO - Step 226604, loss: 0.52636384963989267\n",
      "########## Evaluation ##########\n",
      "Timestep: 226604 Average reward is -0.0524\n",
      "INFO - Step 226760, loss: 0.43815553188323975\n",
      "########## Evaluation ##########\n",
      "Timestep: 226760 Average reward is -0.0581\n",
      "INFO - Step 226910, loss: 0.56689816713333134\n",
      "########## Evaluation ##########\n",
      "Timestep: 226910 Average reward is -0.0653\n",
      "INFO - Step 227062, loss: 0.34604060649871826\n",
      "########## Evaluation ##########\n",
      "Timestep: 227062 Average reward is -0.0643\n",
      "INFO - Step 227200, loss: 0.41545397043228154\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 227211, loss: 0.29476165771484375\n",
      "########## Evaluation ##########\n",
      "Timestep: 227211 Average reward is -0.0688\n",
      "INFO - Step 227368, loss: 0.59184253215789845\n",
      "########## Evaluation ##########\n",
      "Timestep: 227368 Average reward is -0.0398\n",
      "INFO - Step 227506, loss: 0.47364681959152223\n",
      "########## Evaluation ##########\n",
      "Timestep: 227506 Average reward is -0.0578\n",
      "INFO - Step 227531, loss: 0.58465445041656496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 227653, loss: 0.47312682867050175\n",
      "########## Evaluation ##########\n",
      "Timestep: 227653 Average reward is -0.0493\n",
      "INFO - Step 227792, loss: 0.61866021156311043\n",
      "########## Evaluation ##########\n",
      "Timestep: 227792 Average reward is -0.0693\n",
      "INFO - Step 227935, loss: 0.46946004033088684\n",
      "########## Evaluation ##########\n",
      "Timestep: 227935 Average reward is -0.0698\n",
      "INFO - Step 228070, loss: 0.51104271411895756\n",
      "########## Evaluation ##########\n",
      "Timestep: 228070 Average reward is -0.0674\n",
      "INFO - Step 228200, loss: 0.47077387571334845\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 228224, loss: 0.38785749673843384\n",
      "########## Evaluation ##########\n",
      "Timestep: 228224 Average reward is -0.0523\n",
      "INFO - Step 228380, loss: 0.53660309314727784\n",
      "########## Evaluation ##########\n",
      "Timestep: 228380 Average reward is -0.0533\n",
      "INFO - Step 228529, loss: 0.50705415010452275\n",
      "########## Evaluation ##########\n",
      "Timestep: 228529 Average reward is -0.0544\n",
      "INFO - Step 228670, loss: 0.47194084525108343\n",
      "########## Evaluation ##########\n",
      "Timestep: 228670 Average reward is -0.0582\n",
      "INFO - Step 228825, loss: 0.30497586727142334\n",
      "########## Evaluation ##########\n",
      "Timestep: 228825 Average reward is -0.0567\n",
      "INFO - Step 228984, loss: 0.47923886775970463\n",
      "########## Evaluation ##########\n",
      "Timestep: 228984 Average reward is -0.048\n",
      "INFO - Step 229008, loss: 0.56660979986190833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 229135, loss: 0.65304261445999153\n",
      "########## Evaluation ##########\n",
      "Timestep: 229135 Average reward is -0.0545\n",
      "INFO - Step 229200, loss: 0.63568323850631716\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 229284, loss: 0.40646135807037354\n",
      "########## Evaluation ##########\n",
      "Timestep: 229284 Average reward is -0.0638\n",
      "INFO - Step 229436, loss: 0.59294193983078074\n",
      "########## Evaluation ##########\n",
      "Timestep: 229436 Average reward is -0.0558\n",
      "INFO - Step 229596, loss: 0.53612446784973146\n",
      "########## Evaluation ##########\n",
      "Timestep: 229596 Average reward is -0.065\n",
      "INFO - Step 229750, loss: 0.66412985324859627\n",
      "########## Evaluation ##########\n",
      "Timestep: 229750 Average reward is -0.063\n",
      "INFO - Step 229898, loss: 0.35218974947929385\n",
      "########## Evaluation ##########\n",
      "Timestep: 229898 Average reward is -0.0475\n",
      "INFO - Step 230053, loss: 0.33708047866821296\n",
      "########## Evaluation ##########\n",
      "Timestep: 230053 Average reward is -0.0518\n",
      "INFO - Step 230189, loss: 0.43051636219024667\n",
      "########## Evaluation ##########\n",
      "Timestep: 230189 Average reward is -0.0608\n",
      "INFO - Step 230200, loss: 0.31224268674850464\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 230325, loss: 0.61106085777282717\n",
      "########## Evaluation ##########\n",
      "Timestep: 230325 Average reward is -0.0514\n",
      "INFO - Step 230482, loss: 0.55125916004180915\n",
      "########## Evaluation ##########\n",
      "Timestep: 230482 Average reward is -0.0694\n",
      "INFO - Step 230511, loss: 0.41364109516143885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 230638, loss: 0.43829342722892767\n",
      "########## Evaluation ##########\n",
      "Timestep: 230638 Average reward is -0.0664\n",
      "INFO - Step 230790, loss: 0.52084761857986455\n",
      "########## Evaluation ##########\n",
      "Timestep: 230790 Average reward is -0.0551\n",
      "INFO - Step 230940, loss: 0.54654824733734135\n",
      "########## Evaluation ##########\n",
      "Timestep: 230940 Average reward is -0.0445\n",
      "INFO - Step 231084, loss: 0.43301981687545776\n",
      "########## Evaluation ##########\n",
      "Timestep: 231084 Average reward is -0.0671\n",
      "INFO - Step 231200, loss: 0.67262881994247445\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 231235, loss: 0.59025281667709355\n",
      "########## Evaluation ##########\n",
      "Timestep: 231235 Average reward is -0.0604\n",
      "INFO - Step 231377, loss: 0.47072988748550415\n",
      "########## Evaluation ##########\n",
      "Timestep: 231377 Average reward is -0.0479\n",
      "INFO - Step 231527, loss: 0.39064255356788635\n",
      "########## Evaluation ##########\n",
      "Timestep: 231527 Average reward is -0.0602\n",
      "INFO - Step 231672, loss: 0.58208394050598142\n",
      "########## Evaluation ##########\n",
      "Timestep: 231672 Average reward is -0.0564\n",
      "INFO - Step 231810, loss: 0.65171396732330325\n",
      "########## Evaluation ##########\n",
      "Timestep: 231810 Average reward is -0.058\n",
      "INFO - Step 231959, loss: 0.28553843498229985\n",
      "########## Evaluation ##########\n",
      "Timestep: 231959 Average reward is -0.0425\n",
      "INFO - Step 231987, loss: 0.71081626415252694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 232115, loss: 0.73126631975173954\n",
      "########## Evaluation ##########\n",
      "Timestep: 232115 Average reward is -0.0519\n",
      "INFO - Step 232200, loss: 0.40828216075897217\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 232269, loss: 0.38345274329185486\n",
      "########## Evaluation ##########\n",
      "Timestep: 232269 Average reward is -0.0542\n",
      "INFO - Step 232415, loss: 0.48720732331275944\n",
      "########## Evaluation ##########\n",
      "Timestep: 232415 Average reward is -0.064\n",
      "INFO - Step 232561, loss: 0.41754460334777834\n",
      "########## Evaluation ##########\n",
      "Timestep: 232561 Average reward is -0.0567\n",
      "INFO - Step 232704, loss: 0.69426685571670535\n",
      "########## Evaluation ##########\n",
      "Timestep: 232704 Average reward is -0.0552\n",
      "INFO - Step 232860, loss: 0.53475141525268555\n",
      "########## Evaluation ##########\n",
      "Timestep: 232860 Average reward is -0.063\n",
      "INFO - Step 233008, loss: 0.43079286813735967\n",
      "########## Evaluation ##########\n",
      "Timestep: 233008 Average reward is -0.0605\n",
      "INFO - Step 233155, loss: 0.57781499624252323\n",
      "########## Evaluation ##########\n",
      "Timestep: 233155 Average reward is -0.0558\n",
      "INFO - Step 233200, loss: 0.55662143230438236\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 233300, loss: 0.38126185536384585\n",
      "########## Evaluation ##########\n",
      "Timestep: 233300 Average reward is -0.0742\n",
      "INFO - Step 233444, loss: 0.48754245042800903\n",
      "########## Evaluation ##########\n",
      "Timestep: 233444 Average reward is -0.0605\n",
      "INFO - Step 233475, loss: 0.57440614700317383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 233596, loss: 0.62388753890991213\n",
      "########## Evaluation ##########\n",
      "Timestep: 233596 Average reward is -0.0544\n",
      "INFO - Step 233741, loss: 0.62527537345886235\n",
      "########## Evaluation ##########\n",
      "Timestep: 233741 Average reward is -0.0597\n",
      "INFO - Step 233881, loss: 0.34021726250648574\n",
      "########## Evaluation ##########\n",
      "Timestep: 233881 Average reward is -0.0541\n",
      "INFO - Step 234041, loss: 0.37325859069824223\n",
      "########## Evaluation ##########\n",
      "Timestep: 234041 Average reward is -0.055\n",
      "INFO - Step 234191, loss: 0.52659279108047496\n",
      "########## Evaluation ##########\n",
      "Timestep: 234191 Average reward is -0.0705\n",
      "INFO - Step 234200, loss: 0.46208333969116217\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 234344, loss: 0.54215955734252937\n",
      "########## Evaluation ##########\n",
      "Timestep: 234344 Average reward is -0.0563\n",
      "INFO - Step 234493, loss: 0.61853098869323733\n",
      "########## Evaluation ##########\n",
      "Timestep: 234493 Average reward is -0.0628\n",
      "INFO - Step 234649, loss: 0.62639838457107545\n",
      "########## Evaluation ##########\n",
      "Timestep: 234649 Average reward is -0.0617\n",
      "INFO - Step 234791, loss: 0.56004095077514654\n",
      "########## Evaluation ##########\n",
      "Timestep: 234791 Average reward is -0.075\n",
      "INFO - Step 234940, loss: 0.43526470661163337\n",
      "########## Evaluation ##########\n",
      "Timestep: 234940 Average reward is -0.0578\n",
      "INFO - Step 234977, loss: 0.78224420547485354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 235080, loss: 0.78928983211517335\n",
      "########## Evaluation ##########\n",
      "Timestep: 235080 Average reward is -0.0564\n",
      "INFO - Step 235200, loss: 0.49943202733993535\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 235227, loss: 0.69314444065093996\n",
      "########## Evaluation ##########\n",
      "Timestep: 235227 Average reward is -0.0491\n",
      "INFO - Step 235379, loss: 0.44642522931098947\n",
      "########## Evaluation ##########\n",
      "Timestep: 235379 Average reward is -0.0591\n",
      "INFO - Step 235526, loss: 0.57795912027359015\n",
      "########## Evaluation ##########\n",
      "Timestep: 235526 Average reward is -0.0731\n",
      "INFO - Step 235667, loss: 0.46616333723068244\n",
      "########## Evaluation ##########\n",
      "Timestep: 235667 Average reward is -0.0643\n",
      "INFO - Step 235803, loss: 0.50217616558074956\n",
      "########## Evaluation ##########\n",
      "Timestep: 235803 Average reward is -0.0568\n",
      "INFO - Step 235949, loss: 0.41900503635406494\n",
      "########## Evaluation ##########\n",
      "Timestep: 235949 Average reward is -0.0713\n",
      "INFO - Step 236101, loss: 0.53541088104248053\n",
      "########## Evaluation ##########\n",
      "Timestep: 236101 Average reward is -0.0634\n",
      "INFO - Step 236200, loss: 0.43095907568931587\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 236248, loss: 0.35138103365898135\n",
      "########## Evaluation ##########\n",
      "Timestep: 236248 Average reward is -0.0668\n",
      "INFO - Step 236390, loss: 0.68537974357604987\n",
      "########## Evaluation ##########\n",
      "Timestep: 236390 Average reward is -0.0665\n",
      "INFO - Step 236419, loss: 0.49210047721862793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 236537, loss: 0.34395360946655273\n",
      "########## Evaluation ##########\n",
      "Timestep: 236537 Average reward is -0.0747\n",
      "INFO - Step 236699, loss: 0.56945395469665535\n",
      "########## Evaluation ##########\n",
      "Timestep: 236699 Average reward is -0.0445\n",
      "INFO - Step 236851, loss: 0.30481436848640444\n",
      "########## Evaluation ##########\n",
      "Timestep: 236851 Average reward is -0.0551\n",
      "INFO - Step 237000, loss: 0.55340850353240974\n",
      "########## Evaluation ##########\n",
      "Timestep: 237000 Average reward is -0.0778\n",
      "INFO - Step 237141, loss: 0.76714134216308594\n",
      "########## Evaluation ##########\n",
      "Timestep: 237141 Average reward is -0.0441\n",
      "INFO - Step 237200, loss: 0.57270610332489017\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 237287, loss: 0.47908258438110354\n",
      "########## Evaluation ##########\n",
      "Timestep: 237287 Average reward is -0.0518\n",
      "INFO - Step 237417, loss: 0.55989938974380496\n",
      "########## Evaluation ##########\n",
      "Timestep: 237417 Average reward is -0.0497\n",
      "INFO - Step 237564, loss: 0.37406527996063233\n",
      "########## Evaluation ##########\n",
      "Timestep: 237564 Average reward is -0.0623\n",
      "INFO - Step 237716, loss: 0.63924348354339626\n",
      "########## Evaluation ##########\n",
      "Timestep: 237716 Average reward is -0.0584\n",
      "INFO - Step 237875, loss: 0.60021841526031495\n",
      "########## Evaluation ##########\n",
      "Timestep: 237875 Average reward is -0.0598\n",
      "INFO - Step 237909, loss: 0.70590543746948244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 238020, loss: 0.56047576665878364\n",
      "########## Evaluation ##########\n",
      "Timestep: 238020 Average reward is -0.0578\n",
      "INFO - Step 238165, loss: 0.60393989086151127\n",
      "########## Evaluation ##########\n",
      "Timestep: 238165 Average reward is -0.0678\n",
      "INFO - Step 238200, loss: 0.48178234696388245\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 238307, loss: 0.46475782990455635\n",
      "########## Evaluation ##########\n",
      "Timestep: 238307 Average reward is -0.0798\n",
      "INFO - Step 238445, loss: 0.56718140840530476\n",
      "########## Evaluation ##########\n",
      "Timestep: 238445 Average reward is -0.0624\n",
      "INFO - Step 238595, loss: 0.38485813140869143\n",
      "########## Evaluation ##########\n",
      "Timestep: 238595 Average reward is -0.0497\n",
      "INFO - Step 238741, loss: 0.64435839653015146\n",
      "########## Evaluation ##########\n",
      "Timestep: 238741 Average reward is -0.0698\n",
      "INFO - Step 238890, loss: 0.74714899063110355\n",
      "########## Evaluation ##########\n",
      "Timestep: 238890 Average reward is -0.0623\n",
      "INFO - Step 239030, loss: 0.49538475275039673\n",
      "########## Evaluation ##########\n",
      "Timestep: 239030 Average reward is -0.0596\n",
      "INFO - Step 239173, loss: 0.46641728281974795\n",
      "########## Evaluation ##########\n",
      "Timestep: 239173 Average reward is -0.0509\n",
      "INFO - Step 239200, loss: 0.57404792308807377\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 239316, loss: 0.45549547672271734\n",
      "########## Evaluation ##########\n",
      "Timestep: 239316 Average reward is -0.0496\n",
      "INFO - Step 239350, loss: 0.40349224209785466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 239451, loss: 0.44707351922988893\n",
      "########## Evaluation ##########\n",
      "Timestep: 239451 Average reward is -0.06\n",
      "INFO - Step 239604, loss: 0.50939130783081054\n",
      "########## Evaluation ##########\n",
      "Timestep: 239604 Average reward is -0.0365\n",
      "INFO - Step 239758, loss: 0.49658650159835815\n",
      "########## Evaluation ##########\n",
      "Timestep: 239758 Average reward is -0.0482\n",
      "INFO - Step 239903, loss: 0.53559839725494385\n",
      "########## Evaluation ##########\n",
      "Timestep: 239903 Average reward is -0.0414\n",
      "INFO - Step 240046, loss: 0.61019456386566163\n",
      "########## Evaluation ##########\n",
      "Timestep: 240046 Average reward is -0.0662\n",
      "INFO - Step 240200, loss: 0.47659766674041756\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 240202, loss: 0.72474575042724617\n",
      "########## Evaluation ##########\n",
      "Timestep: 240202 Average reward is -0.0657\n",
      "INFO - Step 240347, loss: 0.52256202697753915\n",
      "########## Evaluation ##########\n",
      "Timestep: 240347 Average reward is -0.0457\n",
      "INFO - Step 240504, loss: 0.59451121091842656\n",
      "########## Evaluation ##########\n",
      "Timestep: 240504 Average reward is -0.0496\n",
      "INFO - Step 240656, loss: 0.53490060567855834\n",
      "########## Evaluation ##########\n",
      "Timestep: 240656 Average reward is -0.0712\n",
      "INFO - Step 240790, loss: 0.70129066705703744\n",
      "########## Evaluation ##########\n",
      "Timestep: 240790 Average reward is -0.0567\n",
      "INFO - Step 240829, loss: 0.41712653636932373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 240943, loss: 0.42853152751922617\n",
      "########## Evaluation ##########\n",
      "Timestep: 240943 Average reward is -0.0849\n",
      "INFO - Step 241100, loss: 0.52024006843566987\n",
      "########## Evaluation ##########\n",
      "Timestep: 241100 Average reward is -0.0586\n",
      "INFO - Step 241200, loss: 0.58679056167602544\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 241254, loss: 0.64932036399841317\n",
      "########## Evaluation ##########\n",
      "Timestep: 241254 Average reward is -0.0677\n",
      "INFO - Step 241409, loss: 0.65359914302825935\n",
      "########## Evaluation ##########\n",
      "Timestep: 241409 Average reward is -0.0664\n",
      "INFO - Step 241555, loss: 0.43881541490554814\n",
      "########## Evaluation ##########\n",
      "Timestep: 241555 Average reward is -0.0414\n",
      "INFO - Step 241703, loss: 0.59031236171722415\n",
      "########## Evaluation ##########\n",
      "Timestep: 241703 Average reward is -0.069\n",
      "INFO - Step 241847, loss: 0.54501444101333624\n",
      "########## Evaluation ##########\n",
      "Timestep: 241847 Average reward is -0.0693\n",
      "INFO - Step 241992, loss: 0.48418229818344116\n",
      "########## Evaluation ##########\n",
      "Timestep: 241992 Average reward is -0.0773\n",
      "INFO - Step 242140, loss: 0.47655880451202395\n",
      "########## Evaluation ##########\n",
      "Timestep: 242140 Average reward is -0.0633\n",
      "INFO - Step 242200, loss: 0.61817800998687745\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 242295, loss: 0.41653019189834595\n",
      "########## Evaluation ##########\n",
      "Timestep: 242295 Average reward is -0.0603\n",
      "INFO - Step 242330, loss: 0.78657406568527224"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 242444, loss: 0.55400145053863534\n",
      "########## Evaluation ##########\n",
      "Timestep: 242444 Average reward is -0.0516\n",
      "INFO - Step 242590, loss: 0.44635772705078125\n",
      "########## Evaluation ##########\n",
      "Timestep: 242590 Average reward is -0.0723\n",
      "INFO - Step 242741, loss: 0.73618638515472417\n",
      "########## Evaluation ##########\n",
      "Timestep: 242741 Average reward is -0.062\n",
      "INFO - Step 242895, loss: 0.35807877779006965\n",
      "########## Evaluation ##########\n",
      "Timestep: 242895 Average reward is -0.064\n",
      "INFO - Step 243049, loss: 0.43989545106887825\n",
      "########## Evaluation ##########\n",
      "Timestep: 243049 Average reward is -0.0638\n",
      "INFO - Step 243200, loss: 0.47409567236900335\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 243201, loss: 0.43082648515701294\n",
      "########## Evaluation ##########\n",
      "Timestep: 243201 Average reward is -0.0769\n",
      "INFO - Step 243352, loss: 0.39252063632011414\n",
      "########## Evaluation ##########\n",
      "Timestep: 243352 Average reward is -0.0544\n",
      "INFO - Step 243493, loss: 0.64929866790771487\n",
      "########## Evaluation ##########\n",
      "Timestep: 243493 Average reward is -0.0742\n",
      "INFO - Step 243632, loss: 0.55310428142547613\n",
      "########## Evaluation ##########\n",
      "Timestep: 243632 Average reward is -0.0768\n",
      "INFO - Step 243781, loss: 0.51002824306488044\n",
      "########## Evaluation ##########\n",
      "Timestep: 243781 Average reward is -0.0529\n",
      "INFO - Step 243811, loss: 0.48720896244049076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 243931, loss: 0.38736754655838016\n",
      "########## Evaluation ##########\n",
      "Timestep: 243931 Average reward is -0.047\n",
      "INFO - Step 244078, loss: 0.36041548848152165\n",
      "########## Evaluation ##########\n",
      "Timestep: 244078 Average reward is -0.074\n",
      "INFO - Step 244200, loss: 0.70809197425842294\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 244226, loss: 0.42048242688179016\n",
      "########## Evaluation ##########\n",
      "Timestep: 244226 Average reward is -0.04\n",
      "INFO - Step 244370, loss: 0.46917828917503357\n",
      "########## Evaluation ##########\n",
      "Timestep: 244370 Average reward is -0.0713\n",
      "INFO - Step 244516, loss: 0.47673201560974123\n",
      "########## Evaluation ##########\n",
      "Timestep: 244516 Average reward is -0.0707\n",
      "INFO - Step 244670, loss: 0.31821700930595446\n",
      "########## Evaluation ##########\n",
      "Timestep: 244670 Average reward is -0.0617\n",
      "INFO - Step 244818, loss: 0.52745580673217776\n",
      "########## Evaluation ##########\n",
      "Timestep: 244818 Average reward is -0.0617\n",
      "INFO - Step 244968, loss: 0.43660733103752136\n",
      "########## Evaluation ##########\n",
      "Timestep: 244968 Average reward is -0.0597\n",
      "INFO - Step 245120, loss: 0.55319166183471686\n",
      "########## Evaluation ##########\n",
      "Timestep: 245120 Average reward is -0.0478\n",
      "INFO - Step 245200, loss: 0.38551872968673706\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 245261, loss: 0.47127467393875125\n",
      "########## Evaluation ##########\n",
      "Timestep: 245261 Average reward is -0.0562\n",
      "INFO - Step 245293, loss: 0.50774633884429936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 245409, loss: 0.46171608567237854\n",
      "########## Evaluation ##########\n",
      "Timestep: 245409 Average reward is -0.0739\n",
      "INFO - Step 245564, loss: 0.52430540323257456\n",
      "########## Evaluation ##########\n",
      "Timestep: 245564 Average reward is -0.0557\n",
      "INFO - Step 245715, loss: 0.37454473972320557\n",
      "########## Evaluation ##########\n",
      "Timestep: 245715 Average reward is -0.0495\n",
      "INFO - Step 245865, loss: 0.42587500810623175\n",
      "########## Evaluation ##########\n",
      "Timestep: 245865 Average reward is -0.0636\n",
      "INFO - Step 246028, loss: 0.52546703815460223\n",
      "########## Evaluation ##########\n",
      "Timestep: 246028 Average reward is -0.0524\n",
      "INFO - Step 246167, loss: 0.66174411773681645\n",
      "########## Evaluation ##########\n",
      "Timestep: 246167 Average reward is -0.0659\n",
      "INFO - Step 246200, loss: 0.48000335693359375\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 246314, loss: 0.49467355012893677\n",
      "########## Evaluation ##########\n",
      "Timestep: 246314 Average reward is -0.0482\n",
      "INFO - Step 246460, loss: 0.54584830999374394\n",
      "########## Evaluation ##########\n",
      "Timestep: 246460 Average reward is -0.048\n",
      "INFO - Step 246608, loss: 0.56649523973464977\n",
      "########## Evaluation ##########\n",
      "Timestep: 246608 Average reward is -0.0555\n",
      "INFO - Step 246757, loss: 0.41943159699445465\n",
      "########## Evaluation ##########\n",
      "Timestep: 246757 Average reward is -0.0641\n",
      "INFO - Step 246790, loss: 0.49934431910514836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 246894, loss: 0.49232780933380127\n",
      "########## Evaluation ##########\n",
      "Timestep: 246894 Average reward is -0.0649\n",
      "INFO - Step 247044, loss: 0.58265155553817755\n",
      "########## Evaluation ##########\n",
      "Timestep: 247044 Average reward is -0.0789\n",
      "INFO - Step 247197, loss: 0.65929192304611217\n",
      "########## Evaluation ##########\n",
      "Timestep: 247197 Average reward is -0.0514\n",
      "INFO - Step 247200, loss: 0.6268198490142822\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 247341, loss: 0.51353389024734555\n",
      "########## Evaluation ##########\n",
      "Timestep: 247341 Average reward is -0.0768\n",
      "INFO - Step 247488, loss: 0.40689641237258916\n",
      "########## Evaluation ##########\n",
      "Timestep: 247488 Average reward is -0.0696\n",
      "INFO - Step 247642, loss: 0.50078916549682623\n",
      "########## Evaluation ##########\n",
      "Timestep: 247642 Average reward is -0.0685\n",
      "INFO - Step 247779, loss: 0.49757012724876404\n",
      "########## Evaluation ##########\n",
      "Timestep: 247779 Average reward is -0.0646\n",
      "INFO - Step 247926, loss: 0.72384983301162727\n",
      "########## Evaluation ##########\n",
      "Timestep: 247926 Average reward is -0.0622\n",
      "INFO - Step 248085, loss: 0.43236255645751953\n",
      "########## Evaluation ##########\n",
      "Timestep: 248085 Average reward is -0.0675\n",
      "INFO - Step 248200, loss: 0.57316839694976813\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 248231, loss: 0.68973046541213997\n",
      "########## Evaluation ##########\n",
      "Timestep: 248231 Average reward is -0.054\n",
      "INFO - Step 248269, loss: 0.59424871206283576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 248386, loss: 0.35528710484504736\n",
      "########## Evaluation ##########\n",
      "Timestep: 248386 Average reward is -0.0451\n",
      "INFO - Step 248531, loss: 0.43851208686828613\n",
      "########## Evaluation ##########\n",
      "Timestep: 248531 Average reward is -0.0474\n",
      "INFO - Step 248687, loss: 0.64208626747131353\n",
      "########## Evaluation ##########\n",
      "Timestep: 248687 Average reward is -0.0585\n",
      "INFO - Step 248836, loss: 0.49381875991821296\n",
      "########## Evaluation ##########\n",
      "Timestep: 248836 Average reward is -0.0508\n",
      "INFO - Step 248982, loss: 0.46859472990036015\n",
      "########## Evaluation ##########\n",
      "Timestep: 248982 Average reward is -0.0685\n",
      "INFO - Step 249112, loss: 0.60016125440597533\n",
      "########## Evaluation ##########\n",
      "Timestep: 249112 Average reward is -0.073\n",
      "INFO - Step 249200, loss: 0.45721855759620667\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 249260, loss: 0.49954921007156376\n",
      "########## Evaluation ##########\n",
      "Timestep: 249260 Average reward is -0.0695\n",
      "INFO - Step 249409, loss: 0.47513163089752243\n",
      "########## Evaluation ##########\n",
      "Timestep: 249409 Average reward is -0.0642\n",
      "INFO - Step 249553, loss: 0.45437142252922067\n",
      "########## Evaluation ##########\n",
      "Timestep: 249553 Average reward is -0.0871\n",
      "INFO - Step 249704, loss: 0.50103867053985675\n",
      "########## Evaluation ##########\n",
      "Timestep: 249704 Average reward is -0.0516\n",
      "INFO - Step 249735, loss: 0.33958154916763306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 249850, loss: 0.56172180175781255\n",
      "########## Evaluation ##########\n",
      "Timestep: 249850 Average reward is -0.0572\n",
      "INFO - Step 249996, loss: 0.42762249708175665\n",
      "########## Evaluation ##########\n",
      "Timestep: 249996 Average reward is -0.0567\n",
      "INFO - Step 250138, loss: 0.42878556251525884\n",
      "########## Evaluation ##########\n",
      "Timestep: 250138 Average reward is -0.0687\n",
      "INFO - Step 250200, loss: 0.47996681928634644\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 250292, loss: 0.46805569529533386\n",
      "########## Evaluation ##########\n",
      "Timestep: 250292 Average reward is -0.0676\n",
      "INFO - Step 250449, loss: 0.49655431509017944\n",
      "########## Evaluation ##########\n",
      "Timestep: 250449 Average reward is -0.048\n",
      "INFO - Step 250600, loss: 0.47574001550674445\n",
      "########## Evaluation ##########\n",
      "Timestep: 250600 Average reward is -0.0416\n",
      "INFO - Step 250755, loss: 0.69848406314849854\n",
      "########## Evaluation ##########\n",
      "Timestep: 250755 Average reward is -0.0661\n",
      "INFO - Step 250902, loss: 0.45766210556030273\n",
      "########## Evaluation ##########\n",
      "Timestep: 250902 Average reward is -0.0744\n",
      "INFO - Step 251039, loss: 0.38807415962219246\n",
      "########## Evaluation ##########\n",
      "Timestep: 251039 Average reward is -0.0527\n",
      "INFO - Step 251184, loss: 0.71672582626342773\n",
      "########## Evaluation ##########\n",
      "Timestep: 251184 Average reward is -0.06\n",
      "INFO - Step 251200, loss: 0.40014484524726877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 251324, loss: 0.43616968393325806\n",
      "########## Evaluation ##########\n",
      "Timestep: 251324 Average reward is -0.0611\n",
      "INFO - Step 251465, loss: 0.52205276489257815\n",
      "########## Evaluation ##########\n",
      "Timestep: 251465 Average reward is -0.0767\n",
      "INFO - Step 251619, loss: 0.38358882069587717\n",
      "########## Evaluation ##########\n",
      "Timestep: 251619 Average reward is -0.0522\n",
      "INFO - Step 251763, loss: 0.50435173511505134\n",
      "########## Evaluation ##########\n",
      "Timestep: 251763 Average reward is -0.0636\n",
      "INFO - Step 251904, loss: 0.49627876281738286\n",
      "########## Evaluation ##########\n",
      "Timestep: 251904 Average reward is -0.0512\n",
      "INFO - Step 252051, loss: 0.61211776733398444\n",
      "########## Evaluation ##########\n",
      "Timestep: 252051 Average reward is -0.0696\n",
      "INFO - Step 252191, loss: 0.51758491992950446\n",
      "########## Evaluation ##########\n",
      "Timestep: 252191 Average reward is -0.05\n",
      "INFO - Step 252200, loss: 0.61449307203292856\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 252328, loss: 0.47864475846290596\n",
      "########## Evaluation ##########\n",
      "Timestep: 252328 Average reward is -0.0548\n",
      "INFO - Step 252464, loss: 0.48402521014213564\n",
      "########## Evaluation ##########\n",
      "Timestep: 252464 Average reward is -0.0761\n",
      "INFO - Step 252611, loss: 0.42249751091003424\n",
      "########## Evaluation ##########\n",
      "Timestep: 252611 Average reward is -0.058\n",
      "INFO - Step 252639, loss: 0.37326413393020637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 252750, loss: 0.44191038608551025\n",
      "########## Evaluation ##########\n",
      "Timestep: 252750 Average reward is -0.0693\n",
      "INFO - Step 252890, loss: 0.58231151103973393\n",
      "########## Evaluation ##########\n",
      "Timestep: 252890 Average reward is -0.0714\n",
      "INFO - Step 253036, loss: 0.42869502305984497\n",
      "########## Evaluation ##########\n",
      "Timestep: 253036 Average reward is -0.0465\n",
      "INFO - Step 253173, loss: 0.61850953102111825\n",
      "########## Evaluation ##########\n",
      "Timestep: 253173 Average reward is -0.0454\n",
      "INFO - Step 253200, loss: 0.41419300436973576\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 253312, loss: 0.53310805559158336\n",
      "########## Evaluation ##########\n",
      "Timestep: 253312 Average reward is -0.0373\n",
      "INFO - Step 253459, loss: 0.49468550086021423\n",
      "########## Evaluation ##########\n",
      "Timestep: 253459 Average reward is -0.0579\n",
      "INFO - Step 253606, loss: 0.79630672931671143\n",
      "########## Evaluation ##########\n",
      "Timestep: 253606 Average reward is -0.0544\n",
      "INFO - Step 253756, loss: 0.50645899772644047\n",
      "########## Evaluation ##########\n",
      "Timestep: 253756 Average reward is -0.0568\n",
      "INFO - Step 253901, loss: 0.62347459793090827\n",
      "########## Evaluation ##########\n",
      "Timestep: 253901 Average reward is -0.0648\n",
      "INFO - Step 254049, loss: 0.43631505966186523\n",
      "########## Evaluation ##########\n",
      "Timestep: 254049 Average reward is -0.0499\n",
      "INFO - Step 254089, loss: 0.56413370370864874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 254197, loss: 0.51634907722473147\n",
      "########## Evaluation ##########\n",
      "Timestep: 254197 Average reward is -0.0646\n",
      "INFO - Step 254200, loss: 0.63514548540115365\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 254346, loss: 0.48422265052795413\n",
      "########## Evaluation ##########\n",
      "Timestep: 254346 Average reward is -0.0577\n",
      "INFO - Step 254487, loss: 0.49472558498382573\n",
      "########## Evaluation ##########\n",
      "Timestep: 254487 Average reward is -0.0554\n",
      "INFO - Step 254627, loss: 0.69482719898223883\n",
      "########## Evaluation ##########\n",
      "Timestep: 254627 Average reward is -0.0529\n",
      "INFO - Step 254769, loss: 0.54008078575134283\n",
      "########## Evaluation ##########\n",
      "Timestep: 254769 Average reward is -0.0504\n",
      "INFO - Step 254912, loss: 0.49400132894515994\n",
      "########## Evaluation ##########\n",
      "Timestep: 254912 Average reward is -0.069\n",
      "INFO - Step 255053, loss: 0.88246995210647583\n",
      "########## Evaluation ##########\n",
      "Timestep: 255053 Average reward is -0.0569\n",
      "INFO - Step 255194, loss: 0.60439175367355354\n",
      "########## Evaluation ##########\n",
      "Timestep: 255194 Average reward is -0.0611\n",
      "INFO - Step 255200, loss: 0.3911322355270386\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 255341, loss: 0.49560818076133735\n",
      "########## Evaluation ##########\n",
      "Timestep: 255341 Average reward is -0.0512\n",
      "INFO - Step 255483, loss: 0.48274493217468264\n",
      "########## Evaluation ##########\n",
      "Timestep: 255483 Average reward is -0.0612\n",
      "INFO - Step 255511, loss: 0.40906113386154175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 255617, loss: 0.47358316183090215\n",
      "########## Evaluation ##########\n",
      "Timestep: 255617 Average reward is -0.0476\n",
      "INFO - Step 255763, loss: 0.52957713603973396\n",
      "########## Evaluation ##########\n",
      "Timestep: 255763 Average reward is -0.0684\n",
      "INFO - Step 255913, loss: 0.43359893560409546\n",
      "########## Evaluation ##########\n",
      "Timestep: 255913 Average reward is -0.0478\n",
      "INFO - Step 256069, loss: 0.53206431865692147\n",
      "########## Evaluation ##########\n",
      "Timestep: 256069 Average reward is -0.0685\n",
      "INFO - Step 256200, loss: 0.58277451992034915\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 256218, loss: 0.50521349906921396\n",
      "########## Evaluation ##########\n",
      "Timestep: 256218 Average reward is -0.0643\n",
      "INFO - Step 256383, loss: 0.35499888658523567\n",
      "########## Evaluation ##########\n",
      "Timestep: 256383 Average reward is -0.0653\n",
      "INFO - Step 256532, loss: 0.42994469404220583\n",
      "########## Evaluation ##########\n",
      "Timestep: 256532 Average reward is -0.0625\n",
      "INFO - Step 256684, loss: 0.64005756378173834\n",
      "########## Evaluation ##########\n",
      "Timestep: 256684 Average reward is -0.0604\n",
      "INFO - Step 256819, loss: 0.50950324535369874\n",
      "########## Evaluation ##########\n",
      "Timestep: 256819 Average reward is -0.0636\n",
      "INFO - Step 256968, loss: 0.50963330268859867\n",
      "########## Evaluation ##########\n",
      "Timestep: 256968 Average reward is -0.0616\n",
      "INFO - Step 256984, loss: 0.54674530029296883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 257116, loss: 0.43796718120574954\n",
      "########## Evaluation ##########\n",
      "Timestep: 257116 Average reward is -0.0689\n",
      "INFO - Step 257200, loss: 0.46166598796844485\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 257269, loss: 0.41056299209594727\n",
      "########## Evaluation ##########\n",
      "Timestep: 257269 Average reward is -0.0476\n",
      "INFO - Step 257407, loss: 0.40184608101844797\n",
      "########## Evaluation ##########\n",
      "Timestep: 257407 Average reward is -0.0471\n",
      "INFO - Step 257564, loss: 0.56384271383285526\n",
      "########## Evaluation ##########\n",
      "Timestep: 257564 Average reward is -0.0636\n",
      "INFO - Step 257711, loss: 0.69984340667724616\n",
      "########## Evaluation ##########\n",
      "Timestep: 257711 Average reward is -0.0571\n",
      "INFO - Step 257863, loss: 0.58298552036285436\n",
      "########## Evaluation ##########\n",
      "Timestep: 257863 Average reward is -0.056\n",
      "INFO - Step 258008, loss: 0.75285220146179294\n",
      "########## Evaluation ##########\n",
      "Timestep: 258008 Average reward is -0.0729\n",
      "INFO - Step 258151, loss: 0.45130696892738346\n",
      "########## Evaluation ##########\n",
      "Timestep: 258151 Average reward is -0.0628\n",
      "INFO - Step 258200, loss: 0.45019257068634033\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 258305, loss: 0.41889843344688416\n",
      "########## Evaluation ##########\n",
      "Timestep: 258305 Average reward is -0.0647\n",
      "INFO - Step 258453, loss: 0.44761371612548834\n",
      "########## Evaluation ##########\n",
      "Timestep: 258453 Average reward is -0.0539\n",
      "INFO - Step 258481, loss: 0.48766010999679565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 258607, loss: 0.43704426288604736\n",
      "########## Evaluation ##########\n",
      "Timestep: 258607 Average reward is -0.0776\n",
      "INFO - Step 258746, loss: 0.43591484427452094\n",
      "########## Evaluation ##########\n",
      "Timestep: 258746 Average reward is -0.0375\n",
      "INFO - Step 258901, loss: 0.30026602745056153\n",
      "########## Evaluation ##########\n",
      "Timestep: 258901 Average reward is -0.0637\n",
      "INFO - Step 259044, loss: 0.38962239027023315\n",
      "########## Evaluation ##########\n",
      "Timestep: 259044 Average reward is -0.0557\n",
      "INFO - Step 259187, loss: 0.63445603847503666\n",
      "########## Evaluation ##########\n",
      "Timestep: 259187 Average reward is -0.0755\n",
      "INFO - Step 259200, loss: 0.47748127579689026\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 259345, loss: 0.65705895423889163\n",
      "########## Evaluation ##########\n",
      "Timestep: 259345 Average reward is -0.0514\n",
      "INFO - Step 259481, loss: 0.43739068508148193\n",
      "########## Evaluation ##########\n",
      "Timestep: 259481 Average reward is -0.0659\n",
      "INFO - Step 259642, loss: 0.44982707500457764\n",
      "########## Evaluation ##########\n",
      "Timestep: 259642 Average reward is -0.057\n",
      "INFO - Step 259785, loss: 0.60442101955413824\n",
      "########## Evaluation ##########\n",
      "Timestep: 259785 Average reward is -0.0532\n",
      "INFO - Step 259939, loss: 0.62932634353637766\n",
      "########## Evaluation ##########\n",
      "Timestep: 259939 Average reward is -0.06\n",
      "INFO - Step 259968, loss: 0.62353181838989264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 260087, loss: 0.42515137791633606\n",
      "########## Evaluation ##########\n",
      "Timestep: 260087 Average reward is -0.0465\n",
      "INFO - Step 260200, loss: 0.82706153392791754\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 260239, loss: 0.67931807041168215\n",
      "########## Evaluation ##########\n",
      "Timestep: 260239 Average reward is -0.064\n",
      "INFO - Step 260384, loss: 0.68193471431732183\n",
      "########## Evaluation ##########\n",
      "Timestep: 260384 Average reward is -0.066\n",
      "INFO - Step 260539, loss: 0.70853769779205326\n",
      "########## Evaluation ##########\n",
      "Timestep: 260539 Average reward is -0.0764\n",
      "INFO - Step 260690, loss: 0.55218350887298584\n",
      "########## Evaluation ##########\n",
      "Timestep: 260690 Average reward is -0.0726\n",
      "INFO - Step 260838, loss: 0.49849399924278266\n",
      "########## Evaluation ##########\n",
      "Timestep: 260838 Average reward is -0.0538\n",
      "INFO - Step 260997, loss: 0.47026872634887695\n",
      "########## Evaluation ##########\n",
      "Timestep: 260997 Average reward is -0.0489\n",
      "INFO - Step 261150, loss: 0.41161197423934937\n",
      "########## Evaluation ##########\n",
      "Timestep: 261150 Average reward is -0.0483\n",
      "INFO - Step 261200, loss: 0.68124079704284676\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 261311, loss: 0.40218657255172736\n",
      "########## Evaluation ##########\n",
      "Timestep: 261311 Average reward is -0.0624\n",
      "INFO - Step 261458, loss: 0.48958653211593634\n",
      "########## Evaluation ##########\n",
      "Timestep: 261458 Average reward is -0.0682\n",
      "INFO - Step 261495, loss: 0.67589426040649415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 261602, loss: 0.44596388936042786\n",
      "########## Evaluation ##########\n",
      "Timestep: 261602 Average reward is -0.0561\n",
      "INFO - Step 261750, loss: 0.58932518959045415\n",
      "########## Evaluation ##########\n",
      "Timestep: 261750 Average reward is -0.0451\n",
      "INFO - Step 261885, loss: 0.34586730599403386\n",
      "########## Evaluation ##########\n",
      "Timestep: 261885 Average reward is -0.0458\n",
      "INFO - Step 262033, loss: 0.54672539234161387\n",
      "########## Evaluation ##########\n",
      "Timestep: 262033 Average reward is -0.0471\n",
      "INFO - Step 262191, loss: 0.45292428135871887\n",
      "########## Evaluation ##########\n",
      "Timestep: 262191 Average reward is -0.052\n",
      "INFO - Step 262200, loss: 0.35209190845489566\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 262349, loss: 0.58715814352035524\n",
      "########## Evaluation ##########\n",
      "Timestep: 262349 Average reward is -0.0643\n",
      "INFO - Step 262492, loss: 0.50067603588104254\n",
      "########## Evaluation ##########\n",
      "Timestep: 262492 Average reward is -0.0472\n",
      "INFO - Step 262638, loss: 0.37385529279708866\n",
      "########## Evaluation ##########\n",
      "Timestep: 262638 Average reward is -0.0687\n",
      "INFO - Step 262789, loss: 0.46176701784133915\n",
      "########## Evaluation ##########\n",
      "Timestep: 262789 Average reward is -0.0749\n",
      "INFO - Step 262923, loss: 0.51795673370361334\n",
      "########## Evaluation ##########\n",
      "Timestep: 262923 Average reward is -0.0548\n",
      "INFO - Step 262955, loss: 0.38525649905204773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 263071, loss: 0.43479251861572266\n",
      "########## Evaluation ##########\n",
      "Timestep: 263071 Average reward is -0.0696\n",
      "INFO - Step 263200, loss: 0.53853559494018553\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 263229, loss: 0.49380379915237427\n",
      "########## Evaluation ##########\n",
      "Timestep: 263229 Average reward is -0.0666\n",
      "INFO - Step 263388, loss: 0.57788109779357914\n",
      "########## Evaluation ##########\n",
      "Timestep: 263388 Average reward is -0.0564\n",
      "INFO - Step 263537, loss: 0.49405315518379216\n",
      "########## Evaluation ##########\n",
      "Timestep: 263537 Average reward is -0.0487\n",
      "INFO - Step 263689, loss: 0.78693491220474243\n",
      "########## Evaluation ##########\n",
      "Timestep: 263689 Average reward is -0.0476\n",
      "INFO - Step 263840, loss: 0.44214749336242676\n",
      "########## Evaluation ##########\n",
      "Timestep: 263840 Average reward is -0.0438\n",
      "INFO - Step 263995, loss: 0.48931166529655457\n",
      "########## Evaluation ##########\n",
      "Timestep: 263995 Average reward is -0.0619\n",
      "INFO - Step 264152, loss: 0.40267875790596014\n",
      "########## Evaluation ##########\n",
      "Timestep: 264152 Average reward is -0.0464\n",
      "INFO - Step 264200, loss: 0.50870335102081393\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 264288, loss: 0.60504418611526496\n",
      "########## Evaluation ##########\n",
      "Timestep: 264288 Average reward is -0.0638\n",
      "INFO - Step 264440, loss: 0.56683242321014477\n",
      "########## Evaluation ##########\n",
      "Timestep: 264440 Average reward is -0.0548\n",
      "INFO - Step 264475, loss: 0.60591173171997076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 264587, loss: 0.56826037168502813\n",
      "########## Evaluation ##########\n",
      "Timestep: 264587 Average reward is -0.0518\n",
      "INFO - Step 264729, loss: 0.56539344787597664\n",
      "########## Evaluation ##########\n",
      "Timestep: 264729 Average reward is -0.0629\n",
      "INFO - Step 264887, loss: 0.49231812357902527\n",
      "########## Evaluation ##########\n",
      "Timestep: 264887 Average reward is -0.0663\n",
      "INFO - Step 265047, loss: 0.43842253088951114\n",
      "########## Evaluation ##########\n",
      "Timestep: 265047 Average reward is -0.0691\n",
      "INFO - Step 265186, loss: 0.36169326305389404\n",
      "########## Evaluation ##########\n",
      "Timestep: 265186 Average reward is -0.0458\n",
      "INFO - Step 265200, loss: 0.55116796493530274\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 265344, loss: 0.45266598463058474\n",
      "########## Evaluation ##########\n",
      "Timestep: 265344 Average reward is -0.066\n",
      "INFO - Step 265494, loss: 0.41340368986129766\n",
      "########## Evaluation ##########\n",
      "Timestep: 265494 Average reward is -0.0665\n",
      "INFO - Step 265651, loss: 0.63567084074020396\n",
      "########## Evaluation ##########\n",
      "Timestep: 265651 Average reward is -0.0504\n",
      "INFO - Step 265796, loss: 0.39425337314605713\n",
      "########## Evaluation ##########\n",
      "Timestep: 265796 Average reward is -0.0598\n",
      "INFO - Step 265942, loss: 0.62383699417114263\n",
      "########## Evaluation ##########\n",
      "Timestep: 265942 Average reward is -0.0538\n",
      "INFO - Step 265967, loss: 0.38279867172241217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 266095, loss: 0.72810822725296024\n",
      "########## Evaluation ##########\n",
      "Timestep: 266095 Average reward is -0.0727\n",
      "INFO - Step 266200, loss: 0.41505494713783264\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 266239, loss: 0.46314740180969245\n",
      "########## Evaluation ##########\n",
      "Timestep: 266239 Average reward is -0.0487\n",
      "INFO - Step 266383, loss: 0.65456998348236087\n",
      "########## Evaluation ##########\n",
      "Timestep: 266383 Average reward is -0.0449\n",
      "INFO - Step 266536, loss: 0.44557952880859375\n",
      "########## Evaluation ##########\n",
      "Timestep: 266536 Average reward is -0.0625\n",
      "INFO - Step 266695, loss: 0.59012520313262945\n",
      "########## Evaluation ##########\n",
      "Timestep: 266695 Average reward is -0.0618\n",
      "INFO - Step 266856, loss: 0.53772389888763436\n",
      "########## Evaluation ##########\n",
      "Timestep: 266856 Average reward is -0.0567\n",
      "INFO - Step 266998, loss: 0.53958237171173177\n",
      "########## Evaluation ##########\n",
      "Timestep: 266998 Average reward is -0.0363\n",
      "INFO - Step 267142, loss: 0.37347877025604257\n",
      "########## Evaluation ##########\n",
      "Timestep: 267142 Average reward is -0.051\n",
      "INFO - Step 267200, loss: 0.49095720052719116\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 267289, loss: 0.35621839761734016\n",
      "########## Evaluation ##########\n",
      "Timestep: 267289 Average reward is -0.046\n",
      "INFO - Step 267426, loss: 0.58075559139251717\n",
      "########## Evaluation ##########\n",
      "Timestep: 267426 Average reward is -0.0472\n",
      "INFO - Step 267464, loss: 0.51829165220260627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 267575, loss: 0.60450243949890143\n",
      "########## Evaluation ##########\n",
      "Timestep: 267575 Average reward is -0.0685\n",
      "INFO - Step 267726, loss: 0.60750770568847667\n",
      "########## Evaluation ##########\n",
      "Timestep: 267726 Average reward is -0.0648\n",
      "INFO - Step 267878, loss: 0.39137282967567444\n",
      "########## Evaluation ##########\n",
      "Timestep: 267878 Average reward is -0.0706\n",
      "INFO - Step 268023, loss: 0.51648038625717166\n",
      "########## Evaluation ##########\n",
      "Timestep: 268023 Average reward is -0.0715\n",
      "INFO - Step 268168, loss: 0.51846170425415044\n",
      "########## Evaluation ##########\n",
      "Timestep: 268168 Average reward is -0.0515\n",
      "INFO - Step 268200, loss: 0.71759319305419926\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 268333, loss: 0.51899075508117687\n",
      "########## Evaluation ##########\n",
      "Timestep: 268333 Average reward is -0.0499\n",
      "INFO - Step 268489, loss: 0.40102893114089966\n",
      "########## Evaluation ##########\n",
      "Timestep: 268489 Average reward is -0.0464\n",
      "INFO - Step 268638, loss: 0.59915798902511656\n",
      "########## Evaluation ##########\n",
      "Timestep: 268638 Average reward is -0.0431\n",
      "INFO - Step 268782, loss: 0.51728016138076784\n",
      "########## Evaluation ##########\n",
      "Timestep: 268782 Average reward is -0.0541\n",
      "INFO - Step 268933, loss: 0.46462672948837286\n",
      "########## Evaluation ##########\n",
      "Timestep: 268933 Average reward is -0.064\n",
      "INFO - Step 268965, loss: 0.53225731849670417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\rlcard\\rlcard\\utils\\logger.py:78: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Step 269088, loss: 0.63039261102676397\n",
      "########## Evaluation ##########\n",
      "Timestep: 269088 Average reward is -0.0475\n",
      "INFO - Step 269200, loss: 0.54884356260299685\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 269238, loss: 0.57845270633697513\n",
      "########## Evaluation ##########\n",
      "Timestep: 269238 Average reward is -0.0528\n",
      "INFO - Step 269390, loss: 0.59907841682434083\n",
      "########## Evaluation ##########\n",
      "Timestep: 269390 Average reward is -0.0564\n",
      "INFO - Step 269534, loss: 0.30311793088912964\n",
      "########## Evaluation ##########\n",
      "Timestep: 269534 Average reward is -0.0467\n",
      "INFO - Step 269678, loss: 0.40893119573593143\n",
      "########## Evaluation ##########\n",
      "Timestep: 269678 Average reward is -0.0513\n",
      "INFO - Step 269825, loss: 0.35319650173187256\n",
      "########## Evaluation ##########\n",
      "Timestep: 269825 Average reward is -0.0373\n",
      "INFO - Step 269982, loss: 0.67842215299606327\n",
      "########## Evaluation ##########\n",
      "Timestep: 269982 Average reward is -0.0641\n",
      "INFO - Step 270131, loss: 0.55333650112152174\n",
      "########## Evaluation ##########\n",
      "Timestep: 270131 Average reward is -0.0657\n",
      "INFO - Step 270200, loss: 0.56819021701812746\n",
      "INFO - Copied model parameters to target network.\n",
      "INFO - Step 270270, loss: 0.50821506977081376"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import rlcard\n",
    "from rlcard.agents.dqn_agent import DQNAgent\n",
    "from rlcard.utils.utils import set_global_seed\n",
    "from rlcard.utils.logger import Logger\n",
    "\n",
    "# Make environment\n",
    "env = rlcard.make('blackjack')\n",
    "eval_env = rlcard.make('blackjack')\n",
    "\n",
    "# Set the iterations numbers and how frequently we evaluate/save plot\n",
    "evaluate_every = 100\n",
    "save_plot_every = 1000\n",
    "evaluate_num = 10000\n",
    "episode_num = 1000000\n",
    "\n",
    "# Set the the number of steps for collecting normalization statistics\n",
    "# and intial memory size\n",
    "memory_init_size = 100\n",
    "norm_step = 100\n",
    "\n",
    "# The paths for saving the logs and learning curves\n",
    "root_path = './experiments/blackjack_dqn_result/'\n",
    "log_path = root_path + 'log.txt'\n",
    "csv_path = root_path + 'performance.csv'\n",
    "figure_path = root_path + 'figures/'\n",
    "\n",
    "# Set a global seed\n",
    "set_global_seed(0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Set agents\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    agent = DQNAgent(sess,\n",
    "                     scope='dqn',\n",
    "                     action_num=env.action_num,\n",
    "                     replay_memory_init_size=memory_init_size,\n",
    "                     norm_step=norm_step,\n",
    "                     state_shape=env.state_shape,\n",
    "                     mlp_layers=[10,10])\n",
    "    env.set_agents([agent])\n",
    "    eval_env.set_agents([agent])\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Count the number of steps\n",
    "    step_counter = 0\n",
    "\n",
    "    # Init a Logger to plot the learning curve\n",
    "    logger = Logger(xlabel='timestep', ylabel='reward', legend='DQN on Blackjack', log_path=log_path, csv_path=csv_path)\n",
    "\n",
    "    for episode in range(episode_num):\n",
    "\n",
    "        # Generate data from the environment\n",
    "        trajectories, _ = env.run(is_training=True)\n",
    "\n",
    "        # Feed transitions into agent memory, and train\n",
    "        for ts in trajectories[0]:\n",
    "            agent.feed(ts)\n",
    "            step_counter += 1\n",
    "\n",
    "            # Train the agent\n",
    "            if step_counter > memory_init_size + norm_step:\n",
    "                loss = agent.train()\n",
    "                print('\\rINFO - Step {}, loss: {}'.format(step_counter, loss), end='')\n",
    "\n",
    "        # Evaluate the performance\n",
    "        if episode % evaluate_every == 0:\n",
    "            reward = 0\n",
    "            for eval_episode in range(evaluate_num):\n",
    "                _, payoffs = eval_env.run(is_training=False)\n",
    "                reward += payoffs[0]\n",
    "\n",
    "            logger.log('\\n########## Evaluation ##########')\n",
    "            logger.log('Timestep: {} Average reward is {}'.format(env.timestep, float(reward)/evaluate_num))\n",
    "\n",
    "            # Add point to logger\n",
    "            logger.add_point(x=env.timestep, y=float(reward)/evaluate_num)\n",
    "\n",
    "        # Make plot\n",
    "        if episode % save_plot_every == 0 and episode > 0:\n",
    "            logger.make_plot(save_path=figure_path+str(episode)+'.png')\n",
    "\n",
    "    # Make the final plot\n",
    "    logger.make_plot(save_path=figure_path+'final_'+str(episode)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
